{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "\n",
    "from statsmodels.tsa.tsatools import lagmat\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn import random_projection\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from dimod import BinaryQuadraticModel\n",
    "from dwave.samplers import SimulatedAnnealingSampler\n",
    "\n",
    "# import pyreadr\n",
    "# \n",
    "# from dwave.preprocessing import roof_duality\n",
    "# from dimod import ExactSolver\n",
    "from dwave.samplers import SteepestDescentSolver\n",
    "# from dwave.samplers import TabuSampler\n",
    "# from dwave.samplers import TreeDecompositionSolver\n",
    "# import neal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Path\n",
    "path  =  os.getcwd() # os.path.dirname(os.getcwd()) #r'/Users/slehmann/Library/CloudStorage/Dropbox/QUBO'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Fred-MD-Data stationary\n",
    "def transform_tcode(data):\n",
    "    \n",
    "    # Get Transformation-Code\n",
    "    tcode = data[0]\n",
    "    \n",
    "    # Get Data\n",
    "    data = data[1:]\n",
    "\n",
    "    if tcode == 1:\n",
    "        output = data\n",
    "    elif tcode == 2:\n",
    "        output = data - np.roll(data, 1)\n",
    "    elif tcode == 3:\n",
    "        output = (data - np.roll(data, 1)) - (np.roll(data, 1) - np.roll(data, 2))\n",
    "    elif tcode == 4:\n",
    "        output = np.log(data)\n",
    "    elif tcode == 5:\n",
    "        output = np.log(data) - np.roll(np.log(data), 1)\n",
    "    elif tcode == 6:\n",
    "        output = (np.log(data) - np.roll(np.log(data), 1)) - (np.roll(np.log(data), 1) - np.roll(np.log(data), 2))\n",
    "    else:\n",
    "        output = (data / np.roll(data, 1) - 1) - (np.roll(data, 1) / np.roll(data, 2) - 1)\n",
    "\n",
    "    return np.concatenate(([tcode], output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create Lags\n",
    "def create_lags(y, X, mlags):\n",
    "    \n",
    "    # Create all lags from zero to maxlag\n",
    "    data_lagged  =  lagmat(y, maxlag = mlags, use_pandas = True)\n",
    "    \n",
    "    # Add to Feature Matrix\n",
    "    X = data_lagged.join(X)\n",
    "    \n",
    "    # Return\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Pre-Process Data\n",
    "def prepro(y, X, t):\n",
    "    \n",
    "    # Train Data\n",
    "    y_train  =  y.iloc[:t, :].copy()\n",
    "    X_train  =  X.iloc[:t, :].copy()\n",
    "\n",
    "    # Predict Data\n",
    "    y_pred  =  y.iloc[[t]].copy()\n",
    "    X_pred  =  X.iloc[[t]].copy()\n",
    "    \n",
    "    # Standardize Data\n",
    "    scaler  =  StandardScaler()   \n",
    "    X_train[X_train.columns] =  scaler.fit_transform(X_train[X_train.columns])\n",
    "    X_pred[X_pred.columns]   =  scaler.transform(X_pred[X_pred.columns])\n",
    "    \n",
    "    # Add Constant\n",
    "    X_train =  sm.add_constant(X_train)\n",
    "    X_pred  =  sm.add_constant(X_pred, has_constant = 'add')\n",
    "    \n",
    "    return y_train, X_train, y_pred, X_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Complete) Subset Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return array of all subsets of length k\n",
    "def complete_sub(arr, k):\n",
    "    \n",
    "    ### Elements are treated as unique based on their position, not on their value.\n",
    "    ### So if the input elements are unique, there will be no repeated values in each combination.\n",
    "    \n",
    "    # Get all subsets of size k\n",
    "    subset  =  list(combinations(arr, k)) \n",
    "    \n",
    "    # Return \n",
    "    return subset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate number of models\n",
    "def n_models(K, k):\n",
    "    return math.factorial(K) / (math.factorial(k) * math.factorial(K-k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to randomly select n_max items from array\n",
    "def random_select(arr, n_max, random_state):\n",
    "    \n",
    "    # Set random state\n",
    "    random.seed(random_state)\n",
    "    \n",
    "    # Set upper Boundary\n",
    "    upper_bound  =  len(arr) if len(arr) < n_max else n_max\n",
    "    \n",
    "    # Randomly select items without repetition\n",
    "    rand_arr  =  random.sample(arr, k = upper_bound)\n",
    "    \n",
    "    # Return \n",
    "    return rand_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to produce Subset Regression Forecasts\n",
    "def ssf(y_train, X_train, X_pred, feature, mlags):\n",
    "    \n",
    "    # Subset Feature Space (incl. constant)\n",
    "    X_train_subset = X_train.iloc[:, list(range(0, mlags+1)) + list(feature)]\n",
    "    X_pred_subset  = X_pred.iloc[:, list(range(0, mlags+1)) + list(feature)]\n",
    "    \n",
    "    # Fit Model\n",
    "    model = sm.OLS(y_train, X_train_subset)\n",
    "    regr = model.fit()\n",
    "    \n",
    "    # Predict\n",
    "    pred = regr.predict(X_pred_subset)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressed Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compressed Regression (Gaussian random projection)\n",
    "def cr_reg(y_train, X_train, X_pred, n_comp, mlags, ran_st):\n",
    "    \n",
    "    # Set up Random-Projection-Matrix\n",
    "    transformer = random_projection.GaussianRandomProjection(n_components = n_comp, random_state = ran_st)\n",
    "    \n",
    "    # Transform\n",
    "    tmp_train  =  transformer.fit_transform(X_train.iloc[:, (mlags+1):])\n",
    "    tmp_pred   =  transformer.fit_transform(X_pred.iloc[:, (mlags+1):])\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    tmp_train  =  pd.DataFrame(tmp_train, index = X_train.index)\n",
    "    tmp_pred   =  pd.DataFrame(tmp_pred,  index = X_pred.index)\n",
    "\n",
    "    # Add Constant + Lags\n",
    "    comp_matrix_train =  pd.concat([X_train.iloc[:, :(mlags+1)], tmp_train], axis = 1)\n",
    "    comp_matrix_pred  =  pd.concat([X_pred.iloc[:, :(mlags+1)],  tmp_pred],  axis = 1)\n",
    "\n",
    "    # Fit Model\n",
    "    model  =  sm.OLS(y_train, comp_matrix_train)\n",
    "    regr   =  model.fit()\n",
    "    \n",
    "    # Predict\n",
    "    pred = regr.predict(comp_matrix_pred)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regression\n",
    "def dt_reg(y_train, X_train, X_pred, ran_st):\n",
    "    \n",
    "    # Set up Regressor Object \n",
    "    model  =  DecisionTreeRegressor(criterion = \"squared_error\",\n",
    "                                    max_depth = 20,\n",
    "                                    splitter  = \"random\",\n",
    "                                    random_state = ran_st)\n",
    "    \n",
    "    # Fit model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    pred = model.predict(X_pred)\n",
    "\n",
    "    # Return Prediction\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AR-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoregressive Model\n",
    "def ar_mod(y_train, lags):\n",
    "\n",
    "    # Fit AR-Model\n",
    "    model = AutoReg(y_train, lags=lags).fit()\n",
    "    \n",
    "    # Prediction\n",
    "    pred = model.forecast(steps=1)\n",
    "\n",
    "    # Return Prediction\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Selection of Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Selection of Forecasts\n",
    "def bssf(Y_train, X_train, X_pred, alpha, n_sub, n_times):\n",
    "    \n",
    "    # Adapt X-Matrix\n",
    "    X_train  =  X_train / n_sub\n",
    "    \n",
    "    # Generate Q-Matrix\n",
    "    ivec      =  np.mat(np.ones(X_train.shape[1])).transpose()\n",
    "    aux_mat   =  np.array(Y_train.transpose() @ X_train + alpha * n_sub)\n",
    "    diag_mat  =  np.diag(aux_mat[0])\n",
    "    Q         =  - 2 * diag_mat + X_train.transpose() @ X_train + alpha * ivec @ ivec.transpose()\n",
    "\n",
    "    # Initialize BQM\n",
    "    bqm  =  BinaryQuadraticModel('BINARY')\n",
    "    bqm  =  bqm.from_qubo(Q)\n",
    "    \n",
    "    # Solve\n",
    "    #solver     =  SimulatedAnnealingSampler()\n",
    "    solver     =  SteepestDescentSolver()\n",
    "    #solver     =  TabuSampler()\n",
    "    #solver     =  TreeDecompositionSolver()\n",
    "\n",
    "    sampleset  =  solver.sample(bqm, num_reads = n_times)\n",
    "    solution   =  list(sampleset.first[0].values())\n",
    "    \n",
    "    # Prediction \n",
    "    pred       = solution @ X_pred\n",
    "    \n",
    "    # Return \n",
    "    return(pred, solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "x_dataset  =  pd.read_csv(path + r'/fred_md_202306.csv')\n",
    "\n",
    "# Drop Variables with too many missing values\n",
    "x_dataset  =  x_dataset.drop([\"PERMIT\", \"PERMITNE\", \"PERMITMW\", \"PERMITS\",\n",
    "                              \"PERMITW\", \"ACOGNO\", \"ANDENOx\", \"CP3Mx\",\n",
    "                              \"COMPAPFFx\", \"TWEXAFEGSMTHx\", \"UMCSENTx\", \"VIXCLSx\"],\n",
    "                              axis=1)\n",
    "\n",
    "# Transform remaining Columns\n",
    "x_dataset.iloc[:, 1:]  =  x_dataset.iloc[:,1:].apply(lambda x: transform_tcode(x))\n",
    "\n",
    "# Drop First Row with Transformation-Code\n",
    "x_dataset  =  x_dataset.iloc[1:,:]\n",
    "\n",
    "# Lag Data\n",
    "x_dataset.iloc[:,1:]  =  x_dataset.iloc[:,1:].shift(1)\n",
    "\n",
    "# Convert Date\n",
    "x_dataset['sasdate']  =  pd.to_datetime(x_dataset['sasdate'])\n",
    "\n",
    "# Filter Data\n",
    "x_dataset  =  x_dataset[(x_dataset['sasdate'] >= '1959-04-01') & (x_dataset['sasdate'] <= '2023-03-01')]\n",
    "\n",
    "# Resetting the index\n",
    "x_dataset.set_index('sasdate', inplace=True)\n",
    "x_dataset.index = x_dataset.index.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "y_dataset  =  pd.read_csv(path + r'/fred_md_202306.csv')\n",
    "\n",
    "# Select and Rename Variables\n",
    "y_dataset  =  y_dataset.loc[:, [\"sasdate\", \"CPIAUCSL\", \"INDPRO\", \"UNRATE\"]]\n",
    "y_dataset  =  y_dataset.rename(columns={'CPIAUCSL': 'CPIAUCSL_h1', 'INDPRO': 'INDPRO_h1', 'UNRATE': 'UNRATE_h1'})\n",
    "\n",
    "# Transform Variables\n",
    "y_dataset[[\"CPIAUCSL_h1\"]]  =  y_dataset[[\"CPIAUCSL_h1\"]].apply(lambda x: 4 * 100 * (np.log(x) - np.roll(np.log(x), 1)))\n",
    "y_dataset[[\"INDPRO_h1\"]]    =  y_dataset[[\"INDPRO_h1\"]].apply(lambda x: 4 * 100 * (np.log(x) - np.roll(np.log(x), 1)))\n",
    "y_dataset[[\"UNRATE_h1\"]]    =  y_dataset[[\"UNRATE_h1\"]]\n",
    "\n",
    "# Drop First Row with Transformation-Code\n",
    "y_dataset  =  y_dataset.iloc[1:,:]\n",
    "\n",
    "# Convert Date\n",
    "y_dataset['sasdate']  =  pd.to_datetime(y_dataset['sasdate'])\n",
    "\n",
    "# Filter Data\n",
    "y_dataset  =  y_dataset[(y_dataset['sasdate'] >= '1959-04-01') & (y_dataset['sasdate'] <= '2023-03-01')]\n",
    "\n",
    "# Resetting the index\n",
    "y_dataset.set_index('sasdate', inplace=True)\n",
    "y_dataset.index = y_dataset.index.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 524/524 [08:21<00:00,  1.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9948131648115085"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Set Seed ######\n",
    "#random.seed(123)\n",
    "\n",
    "###### Data ######\n",
    "# Set Target Variable\n",
    "y  =  y_dataset.loc[:, [\"CPIAUCSL_h1\"]]\n",
    "X  =  x_dataset.drop(\"CPIAUCSL\", axis = 1)\n",
    "\n",
    "# Number of AR-Terms to include\n",
    "mlags =  4\n",
    "\n",
    "# Create Lags\n",
    "X  =  create_lags(y, X, mlags)\n",
    "\n",
    "# Drop Missing Values\n",
    "y  =  y[mlags:]\n",
    "X  =  X[mlags:]\n",
    "\n",
    "###### Parameter Subset Forecasts\n",
    "# Subset Lengths\n",
    "k_range = [1, 2, 3] # [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "\n",
    "# Upper Bound for Subset-Sizes\n",
    "n_max = 200  # 20000\n",
    "\n",
    "# Number of Subset-Forecasts\n",
    "n_sub  =  int(sum([min(n_models((X.shape[1]-mlags), k), n_max) for k in k_range]))\n",
    "\n",
    "###### Parameter Compressed Regressions ######\n",
    "# Number of Components for Compressed Regression\n",
    "cr_range  =  [1, 2, 3] # [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100]\n",
    "\n",
    "# Number of runs for each random projection\n",
    "rep_range  =  range(0, 5) # 10000\n",
    "\n",
    "# Number of Compressed-Regression-Forecasts\n",
    "n_cr  =  len(cr_range) * len(rep_range)\n",
    "\n",
    "###### Parameter Decision Tree ######\n",
    "dt_range  =  range(0, 5) # 300000\n",
    "\n",
    "# Number of Decision Trees\n",
    "n_dt  =  len(dt_range)\n",
    "\n",
    "###### Parameter BSSF ######\n",
    "alpha       =  1\n",
    "n_times     =  100\n",
    "bssf_range  =  range(1, 3)\n",
    "n_bssf      =  len(bssf_range)\n",
    "\n",
    "### General Parameter ######\n",
    "# Initial Training-Period\n",
    "init       =  12 * 20\n",
    "\n",
    "# Total Length\n",
    "total =  len(y) \n",
    "\n",
    "# Set up Matrices for Results\n",
    "cand_forecasts  =  np.full((total, (n_sub + n_cr + n_dt)), np.nan)\n",
    "benchmark       =  np.full(total, np.nan)\n",
    "bssf_opt        =  np.full(total, np.nan)\n",
    "sse_bssf        =  np.zeros(n_bssf)\n",
    "\n",
    "###### Start ######\n",
    "# Loop over Time\n",
    "for t in tqdm(range(init, total)):\n",
    "        \n",
    "    # Pre-Process Data\n",
    "    y_train, X_train, y_pred, X_pred = prepro(y, X, t)\n",
    "    \n",
    "    ### Benchmark: AR(4)\n",
    "    pred          =  ar_mod(y_train, lags = mlags)\n",
    "    benchmark[t]  =  pred.iloc[0]\n",
    "    \n",
    "    ### Subset Forecasts\n",
    "    # Set up List to store Subset-Forecasts\n",
    "    preds_ss  =  np.full(n_sub, np.nan)\n",
    "    idx_sub   =  0\n",
    "    \n",
    "    # Loop over Subset Size \n",
    "    for k in k_range:\n",
    "    \n",
    "        # Get all possible Subset of length k\n",
    "        col_idx   =  list(range(mlags+1, X_train.shape[1]))\n",
    "        subs_idx  =  complete_sub(col_idx, k)\n",
    "\n",
    "        # Randomly select n_upper Subsets\n",
    "        feature_set  =  random_select(subs_idx, n_max, random_state = 123)\n",
    "\n",
    "        # Loop over Subsets\n",
    "        for feature in feature_set:\n",
    "\n",
    "            # Compute Subset-Regression-Forecast\n",
    "            pred  =  ssf(y_train, X_train, X_pred, feature, mlags)\n",
    "            preds_ss[idx_sub] = pred.iloc[0]\n",
    "            idx_sub += 1\n",
    "            \n",
    "    ### Compressed Regressions\n",
    "    # Set up List to store Compressed-Regression-Forecasts\n",
    "    preds_cr   = np.full(n_cr, np.nan)\n",
    "    idx_cr     = 0\n",
    "    \n",
    "    # Loop over number of Components\n",
    "    for n_comp in cr_range:\n",
    "\n",
    "        # Loop over n repetitions\n",
    "        for r in rep_range:\n",
    "        \n",
    "            # Compute Compressed-Regression-Forecasts\n",
    "            pred  =  cr_reg(y_train, X_train, X_pred, n_comp, mlags, r)\n",
    "            preds_cr[idx_cr] = pred.iloc[0]\n",
    "            idx_cr += 1\n",
    "            \n",
    "    ### Decision Tree Regressions\n",
    "    # Set up Matrix to store Decision-Tree-Forecasts\n",
    "    preds_dt   = np.full(n_dt, np.nan)\n",
    "    \n",
    "    # Loop over number of Components\n",
    "    for idx_dt, r in enumerate(dt_range):\n",
    "        \n",
    "        # Compute Decision-Tree-Forecasts\n",
    "        pred  =  dt_reg(y_train, X_train, X_pred, r)\n",
    "        preds_dt[idx_dt] = pred[0]\n",
    "\n",
    "    # Append Results\n",
    "    cand_forecasts[t][:n_sub]             =  preds_ss \n",
    "    cand_forecasts[t][n_sub:(n_sub+n_cr)] =  preds_cr\n",
    "    cand_forecasts[t][(n_sub+n_cr):]      =  preds_dt\n",
    "\n",
    "    ### Best Selection of Forecast\n",
    "    if t > init:\n",
    "    \n",
    "        # Set up Matrix to store Forecasts\n",
    "        bssf_forecasts  =  np.full(n_bssf, np.nan)\n",
    "    \n",
    "        # Get \"best\" Subset-Size until now (lowest Sum of Squared Errors)\n",
    "        s_opt  =  np.argmin(sse_bssf)\n",
    "    \n",
    "        # Loop over Subset Sizes\n",
    "        for idx_bssf, s in enumerate(bssf_range):\n",
    "    \n",
    "            # Compute Best-Subset-Selection-of-Forecasts\n",
    "            pred  =  bssf(y_train[init:], cand_forecasts[init:t], cand_forecasts[t], alpha, s, n_times)\n",
    "            bssf_forecasts[idx_bssf]  =  pred[0]\n",
    "    \n",
    "            # Compute Sum of Squared Errors\n",
    "            sse_bssf[idx_bssf] =  sse_bssf[idx_bssf] + (y_pred.iloc[0,0] - pred[0]) ** 2\n",
    "    \n",
    "        # Select Forecast \n",
    "        bssf_opt[t] =  bssf_forecasts[s_opt]\n",
    "    \n",
    "# Convert Results to DataFrame\n",
    "cand_forecasts  =  pd.DataFrame(cand_forecasts, index = y.index)\n",
    "benchmark       =  pd.DataFrame(benchmark, index = y.index)\n",
    "bssf_opt        =  pd.DataFrame(bssf_opt,  index = y.index)\n",
    "\n",
    "# Cut off initial Training-Period\n",
    "sub_y              =  y.iloc[init:]\n",
    "sub_cand_forecasts =  cand_forecasts.iloc[init:]\n",
    "sub_benchmark      =  benchmark.iloc[init:]\n",
    "sub_bssf_opt       =  bssf_opt.iloc[init:]\n",
    "\n",
    "# OOS-Period\n",
    "oos_start  =  \"1990-01\"\n",
    "oos_end    =  \"2022-12\" \n",
    "oos_y             =  sub_y.loc[oos_start:oos_end]\n",
    "oos_cand_forecast =  sub_cand_forecasts.loc[oos_start:oos_end]\n",
    "oos_benchmark     =  sub_benchmark.loc[oos_start:oos_end]\n",
    "oos_bssf_opt      =  sub_bssf_opt.loc[oos_start:oos_end]\n",
    "\n",
    "# Evaluation\n",
    "np.sum((oos_y.iloc[:,0] - oos_bssf_opt.iloc[:,0]) ** 2) / np.sum((oos_y.iloc[:,0] - oos_benchmark.iloc[:,0]) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Selection of Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Selection of Forecasts\n",
    "def bssf(Y_train, X_train, X_pred, alpha, n_sub, n_times):\n",
    "    \n",
    "    # Adapt X-Matrix\n",
    "    X_train  =  X_train / n_sub\n",
    "    \n",
    "    # Generate Q-Matrix\n",
    "    ivec      =  np.mat(np.ones(X_train.shape[1])).transpose()\n",
    "    aux_mat   =  np.array(Y_train.transpose() @ X_train + alpha * n_sub)\n",
    "    diag_mat  =  np.diag(aux_mat[0])\n",
    "    Q         =  - 2 * diag_mat + X_train.transpose() @ X_train + alpha * ivec @ ivec.transpose()\n",
    "\n",
    "    # Initialize BQM\n",
    "    bqm  =  BinaryQuadraticModel('BINARY')\n",
    "    bqm  =  bqm.from_qubo(Q)\n",
    "    \n",
    "    # Solve\n",
    "    solver     =  SimulatedAnnealingSampler()\n",
    "    #solver     =  SteepestDescentSolver()\n",
    "    #solver     =  TabuSampler()\n",
    "    #solver     =  TreeDecompositionSolver()\n",
    "\n",
    "    sampleset  =  solver.sample(bqm, num_reads = n_times)\n",
    "    solution   =  list(sampleset.first[0].values())\n",
    "    \n",
    "    # Prediction \n",
    "    pred       = solution @ X_pred\n",
    "    \n",
    "    # Return \n",
    "    return(pred, solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Series-Cross-Validation to Tune Parameter k\n",
    "def cv_ts(Y, X, splits, k_seq, alpha, n_times):\n",
    "\n",
    "    # Set up TS-Split\n",
    "    tscv    =  TimeSeriesSplit(n_splits = splits)\n",
    "    \n",
    "    # Set up Result-Matrix\n",
    "    cv_res  =  np.zeros((splits, len(k_seq)))\n",
    "\n",
    "    # Loop over Train-Test-Splits\n",
    "    for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "\n",
    "        # Split Data\n",
    "        X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "        Y_train, Y_test = Y.iloc[train_index],   Y.iloc[test_index]\n",
    "\n",
    "        # Cross-Validation k\n",
    "        for k in k_seq:\n",
    "\n",
    "            # Selected Predictors\n",
    "            solution    =  bssf(Y_train, X_train, X_pred, alpha, k, n_times)[1]\n",
    "\n",
    "            # Prediction\n",
    "            prediction  =  solution @ X_test.transpose()\n",
    "\n",
    "            # MSE\n",
    "            cv_res[i, k-1]  =  np.mean((Y_test.squeeze() - prediction) ** 2)\n",
    "\n",
    "            # Select k with smalltest average MSE\n",
    "            k  =  cv_res.mean(axis=0).argmin() + 1\n",
    "            \n",
    "    # Return \n",
    "    return(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate Forecasts\n",
    "cand_forecasts  =  results\n",
    "\n",
    "# Target Variable\n",
    "target_var  =  y_dataset.loc[:, [\"CPIAUCSL_h1\"]]\n",
    "\n",
    "# Get Dates\n",
    "dates  =  cand_forecasts.index.values\n",
    "\n",
    "# Match Time Frames\n",
    "target_var  =  target_var.loc[dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameter\n",
    "alpha    =  1\n",
    "n_mods   =  cand_forecasts.shape[1]\n",
    "\n",
    "# Set Vector & Matrices\n",
    "X     =  cand_forecasts.copy()\n",
    "Y     =  target_var.copy()\n",
    "\n",
    "# Set Time Parameter\n",
    "init    =  int(12 * 5)\n",
    "final   =  len(Y)\n",
    "\n",
    "# Set up Empty Array\n",
    "predictions  =  np.zeros(final)\n",
    "predictions.fill(np.nan)\n",
    "\n",
    "# Loop\n",
    "for t in tqdm(range(init, final)):\n",
    "    \n",
    "    # Train Data\n",
    "    X_train  =  X.iloc[:t, ]\n",
    "    Y_train  =  Y.iloc[:t, ]\n",
    "    \n",
    "    # Prediction Data\n",
    "    X_pred   =  X.iloc[t, ]\n",
    "    \n",
    "    # Cross-Validation\n",
    "    splits   =  5\n",
    "    n_times  =  500\n",
    "    k_seq    =  [1, 2, 3, 4, 5]\n",
    "    k_opt    =  cv_ts(Y_train, X_train, splits, k_seq, alpha, n_times)\n",
    "    \n",
    "    # Prediction \n",
    "    n_times  =  500\n",
    "    predictions[t]  =  bssf(Y_train, X_train, X_pred, alpha, k_opt, n_times)[0]\n",
    "\n",
    "# Convert to Pandas Series\n",
    "predictions  =  pd.Series(predictions, name = \"qubo\", index = Y.index).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Target Variable\n",
    "target_var      =  pyreadr.read_r(path + '/Data/Results/Target_Var/target_var.RDS')[None]\n",
    "\n",
    "# Load all Candidate Forecasts\n",
    "cand_forecasts  =  pd.DataFrame()\n",
    "files           =  os.scandir(path + '/Data/Results/Candidate_Forecasts')\n",
    "\n",
    "# Loop\n",
    "for file in files:\n",
    "    if (file.path.endswith(\".RDS\")):\n",
    "        aux  =  pyreadr.read_r(file)[None]\n",
    "        cand_forecasts  =  pd.concat([cand_forecasts, aux], axis = 1)\n",
    "        \n",
    "# Drop Na\n",
    "cand_forecasts  =  cand_forecasts.dropna()\n",
    "\n",
    "# Get Dates\n",
    "dates           =  cand_forecasts.index.values\n",
    "\n",
    "# Match Time Frames\n",
    "target_var      =  target_var.loc[dates]\n",
    "\n",
    "# Dimensions\n",
    "print(cand_forecasts.shape)\n",
    "print(target_var.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Q-Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Selection of Forecasts\n",
    "def bssf(Y_train, X_train, X_pred, alpha, n_sub, n_times):\n",
    "    \n",
    "    # Adapt X-Matrix\n",
    "    X_train  =  X_train / n_sub\n",
    "    \n",
    "    # Generate Q-Matrix\n",
    "    ivec      =  np.mat(np.ones(X_train.shape[1])).transpose()\n",
    "    aux_mat   =  np.array(Y_train.transpose() @ X_train + alpha * n_sub)\n",
    "    diag_mat  =  np.diag(aux_mat[0])\n",
    "    Q         =  - 2 * diag_mat + X_train.transpose() @ X_train + alpha * ivec @ ivec.transpose()\n",
    "\n",
    "    # Initialize BQM\n",
    "    bqm  =  BinaryQuadraticModel('BINARY')\n",
    "    bqm  =  bqm.from_qubo(Q)\n",
    "    \n",
    "    # Solve\n",
    "    solver     =  SimulatedAnnealingSampler()\n",
    "    #solver     =  SteepestDescentSolver()\n",
    "    #solver     =  TabuSampler()\n",
    "    #solver     =  TreeDecompositionSolver()\n",
    "\n",
    "    sampleset  =  solver.sample(bqm, num_reads = n_times)\n",
    "    solution   =  list(sampleset.first[0].values())\n",
    "    \n",
    "    # Prediction \n",
    "    pred       = solution @ X_pred\n",
    "    \n",
    "    # Return \n",
    "    return(pred, solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Series-Cross-Validation to Tune Parameter k\n",
    "def cv_ts(Y, X, splits, k_seq, alpha, n_times):\n",
    "\n",
    "    # Set up TS-Split\n",
    "    tscv    =  TimeSeriesSplit(n_splits = splits)\n",
    "    \n",
    "    # Set up Result-Matrix\n",
    "    cv_res  =  np.zeros((splits, len(k_seq)))\n",
    "\n",
    "    # Loop over Train-Test-Splits\n",
    "    for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "\n",
    "        # Split Data\n",
    "        X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "        Y_train, Y_test = Y.iloc[train_index],   Y.iloc[test_index]\n",
    "\n",
    "        # Cross-Validation k\n",
    "        for k in k_seq:\n",
    "\n",
    "            # Selected Predictors\n",
    "            solution    =  bssf(Y_train, X_train, X_pred, alpha, k, n_times)[1]\n",
    "\n",
    "            # Prediction\n",
    "            prediction  =  solution @ X_test.transpose()\n",
    "\n",
    "            # MSE\n",
    "            cv_res[i, k-1]  =  np.mean((Y_test.squeeze() - prediction) ** 2)\n",
    "\n",
    "            # Select k with smalltest average MSE\n",
    "            k  =  cv_res.mean(axis=0).argmin() + 1\n",
    "            \n",
    "    # Return \n",
    "    return(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameter\n",
    "alpha    =  1\n",
    "n_mods   =  cand_forecasts.shape[1]\n",
    "\n",
    "# Set Vector & Matrices\n",
    "X     =  cand_forecasts.copy()\n",
    "Y     =  target_var.copy()\n",
    "\n",
    "# Set Time Parameter\n",
    "init    =  int(12 * 5)\n",
    "final   =  len(Y)\n",
    "\n",
    "# Set up Empty Array\n",
    "predictions  =  np.zeros(final)\n",
    "predictions.fill(np.nan)\n",
    "\n",
    "# Loop\n",
    "for t in range(init, final):\n",
    "    \n",
    "    # Train Data\n",
    "    X_train  =  X.iloc[:t, ]\n",
    "    Y_train  =  Y.iloc[:t, ]\n",
    "    \n",
    "    # Prediction Data\n",
    "    X_pred   =  X.iloc[t, ]\n",
    "    \n",
    "    # Cross-Validation\n",
    "    splits   =  5\n",
    "    n_times  =  500\n",
    "    k_seq    =  [1, 2, 3, 4, 5]\n",
    "    k        =  cv_ts(Y_train, X_train, splits, k_seq, alpha, n_times)\n",
    "    \n",
    "    # Prediction \n",
    "    n_times  =  500\n",
    "    predictions[t]  =  bssf(Y_train, X_train, X_pred, alpha, k, n_times)[0]\n",
    "\n",
    "# Convert to Pandas Series\n",
    "predictions  =  pd.Series(predictions, name = \"qubo\", index = Y.index).to_frame()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Eval-Function (OOS-R2)\n",
    "def oos_r2(observation, prediction, benchmark):\n",
    "    \n",
    "    # Squared Error Model\n",
    "    se1  =  (observation - prediction) ** 2\n",
    "    \n",
    "    # Squared Error Benchmark\n",
    "    se2  =  (observation - benchmark) ** 2\n",
    "    \n",
    "    # Out-of-Sample R2\n",
    "    oos_r2  =  (1 - sum(se1) / sum(se2)) * 100\n",
    "    \n",
    "    # Return \n",
    "    return(oos_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set OOS-Period\n",
    "eval_start  =  \"1974-12-01\"\n",
    "eval_end    =  \"2020-12-01\"\n",
    "\n",
    "# Keep only OOS-Period\n",
    "oos_target_var      =  target_var.loc[eval_start:eval_end].squeeze()\n",
    "oos_benchmark       =  cand_forecasts[eval_start:eval_end][\"pred_hist_mean\"]\n",
    "oos_bssf            =  predictions.loc[eval_start:eval_end].squeeze()\n",
    "oos_cand_forecasts  =  cand_forecasts[eval_start:eval_end]\n",
    "\n",
    "# Evaluate Best Subset Selection of Forecasts\n",
    "oos_r2(oos_target_var, oos_bssf, oos_benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Candidate Models\n",
    "eval_cand_mods  =  oos_cand_forecasts.apply(lambda x: oos_r2(oos_target_var, x, oos_benchmark), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_cand_mods.sort_values(ascending = False).to_frame(\"OOS-R2\").head(n = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set OOS-Period\n",
    "eval_start  =  \"1974-12-01\"\n",
    "eval_end    =  \"2020-12-01\"\n",
    "\n",
    "# Keep only OOS-Period\n",
    "oos_target_var      =  target_var.loc[eval_start:eval_end].squeeze()\n",
    "oos_benchmark       =  cand_forecasts[eval_start:eval_end][\"pred_hist_mean\"]\n",
    "oos_cand_forecasts  =  cand_forecasts[eval_start:eval_end]\n",
    "\n",
    "# Evaluate Candidate Models\n",
    "eval_cand_mods  =  oos_cand_forecasts.apply(lambda x: oos_r2(oos_target_var, x, oos_benchmark), axis = 0)\n",
    "\n",
    "# Show Results\n",
    "print(eval_cand_mods.filter(like = \"XGB\"))\n",
    "print(eval_cand_mods.filter(like = \"GBM\"))\n",
    "print(eval_cand_mods.filter(like = \"pcr\"))\n",
    "print(eval_cand_mods.filter(like = \"glm\"), n =)\n",
    "#eval_cand_mods.sort_values(ascending = False).to_frame(\"OOS-R2\").head(n = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BQM\n",
    "qubo  =  { (i,j) : Q.iloc[i,j] for i in range(0, 11) for j in range(0, 11) }\n",
    "bqm   =  BinaryQuadraticModel('BINARY')\n",
    "bqm   =  bqm.from_qubo(Q)\n",
    "\n",
    "# Initialize BQM\n",
    "bqm = BinaryQuadraticModel('BINARY')\n",
    "\n",
    "# Add Linear Coefficients\n",
    "for i in range(0,11):\n",
    "    lin_coef  =  Q.iloc[i,i]\n",
    "    bqm.add_linear(i, lin_coef)\n",
    "    \n",
    "# Add Quadratic Coefficients\n",
    "for i in range(0,11):\n",
    "    for j in range(0,11):\n",
    "        if i != j:\n",
    "            quad_coef  =  Q.iloc[i,j]\n",
    "            bqm.add_quadratic(i, j, quad_coef)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
