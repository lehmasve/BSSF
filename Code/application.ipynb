{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-06-10\n"
     ]
    }
   ],
   "source": [
    "### Load Libraries and Functions\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from _cm import lambda_path, eln, bss, crr, dtr, candidate_models, candidate_models_kf\n",
    "from _fm import bssf_cv, fss_cv, lasso_cv, csr_cv, avg_best_cv, pelasso_cv, psgd_cv\n",
    "from _helpers import relevant_predictor, run_results\n",
    "from _visualization import plot_subsetsize, plot_cm, plot_preds\n",
    "\n",
    "import gurobipy as gp\n",
    "gp.setParam('OutputFlag', 0)\n",
    "\n",
    "if os.name == 'nt':\n",
    "    import dill\n",
    "    dill.settings['recurse'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Path\n",
    "path  =  os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application: Eye-Gene-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameter\n",
    "# Setting\n",
    "N = 5\n",
    "train = 60\n",
    "ran_st = 123\n",
    "timeout = 10\n",
    "alpha = 1e0\n",
    "\n",
    "# Candidate Models\n",
    "cm_params = [\n",
    "    (\"bss\", {\"k_vec\": np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]), \"n_jobs\": 1}),\n",
    "    #(\"eln\", {\"n_lambda\": 20, \"alpha_vec\": np.array([0.0, 0.25, 0.50, 0.75, 1.00]), \"n_jobs\": 1}),\n",
    "    #(\"crr\", {\"comp_vec\": np.array([1, 2, 3, 4, 5]), \"rep_range\": np.arange(1, 501), \"n_jobs\": 1}),\n",
    "    (\"dtr\", {\"vec_depth\": np.array([2, 3, 4, 5]), \"n_jobs\": 1}),\n",
    "    #(\"dtrst\", {\"n_jobs\": 1}),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Eye Data\n",
    "X = pd.read_csv(path + '/data/eye_x.csv')\n",
    "y = pd.read_csv(path + '/data/eye_y.csv')\n",
    "\n",
    "# Convert to Numpy\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n"
     ]
    }
   ],
   "source": [
    "# Run Results\n",
    "results = run_results(N, X, y, train, cm_params, timeout, alpha, ran_st)\n",
    "\n",
    "# Save Results\n",
    "filename = f\"{path}/Results/Application/eye_results.pkl\"\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting: N=5, Type=Application, CM=14, alpha=1.0, timeout=10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PHM': 1.5887,\n",
       " 'LASSO': 0.8745,\n",
       " 'PELASSO': 0.9849,\n",
       " 'AVG_BEST': 1.0128,\n",
       " 'CSR': 0.9475,\n",
       " 'PSGD': 1.1527,\n",
       " 'BSSF': 1.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Results\n",
    "filename = f\"{path}/Results/Application/eye_results.pkl\"\n",
    "with open(filename, 'rb') as file:\n",
    "    results = pickle.load(file)\n",
    "\n",
    "# Assign Results\n",
    "preds = results['predictions']\n",
    "scores = results['mse']\n",
    "best_k = results['best_k']\n",
    "bssf_weights = results['bssf_weights']\n",
    "cf_models = results['cf_models']\n",
    "cf_descriptions = results['cf_descriptions']\n",
    "model_names = results['fmodel_names']\n",
    "bssf_timeout = results['bssf_timeout']\n",
    "bssf_alpha = results['bssf_alpha']\n",
    "runs = len(results['predictions'])\n",
    "numb_cm = len(cf_models[0])\n",
    "\n",
    "# Relative to BSSF\n",
    "relative_scores = np.round(np.mean(scores, axis = 0) / np.mean(scores, axis = 0)[6], 4)\n",
    "\n",
    "# \n",
    "print(f\"Setting: N={runs}, Type=Application, CM={numb_cm}, alpha={bssf_alpha}, timeout={bssf_timeout}s\")\n",
    "\n",
    "# Show\n",
    "model_scores = {model: score for model, score in zip(model_names, relative_scores)}\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Setting: N=3, Type=Application, CM=14, alpha=1000000.0, timeout=10s\n",
    "{'PHM': 1.5702,\n",
    " 'LASSO': 0.8477,\n",
    " 'PELASSO': 0.989,\n",
    " 'AVG_BEST': 1.0019,\n",
    " 'CSR': 0.924,\n",
    " 'PSGD': 1.1381,\n",
    " 'BSSF': 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Subset-Size\n",
    "plot_subsetsize(best_k, 5, runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Selected Candidate Models\n",
    "plot_cm(bssf_weights, cf_descriptions, runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Selected Predictiors\n",
    "plot_preds(cf_models, bssf_weights, 200, runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Application: Eye Data\n",
    "def application(N, x, y, train, cm_params, ran_st):\n",
    "    \"\"\"\n",
    "    Function for real data analysis simulation.\n",
    "    \n",
    "    Parameters:\n",
    "    - N: Number of simulations.\n",
    "    - x: DataFrame of predictors.\n",
    "    - y: Series or array of response variable.\n",
    "    - train: Number of observations to include in the training set.\n",
    "    - cm_params: List of tuples with the candidate models and their parameters.\n",
    "    - ran_st: Seed for random number generator \n",
    "    \n",
    "    Returns:\n",
    "    - output_pred: List of predictions for each model.\n",
    "    - output_mse: List of mean squared errors for each model.\n",
    "    - output_bestk: List of best k values for each model.\n",
    "    - output_weights: List of weights for BSSF model.\n",
    "    - output_cfmodels: List of candidate models.\n",
    "    - ...\n",
    "    - fmodel_names: List of model names.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Forecasting Model Names\n",
    "    fmodel_names = [\"PHM\", \"LASSO\", \"PELASSO\", \"AVG_BEST\", \"CSR\", \"PSGD\", \"BSSF\"]\n",
    "    \n",
    "    # Set seed for reproducibility\n",
    "    np.random.seed(ran_st)\n",
    "    \n",
    "    # Full Index \n",
    "    indices = np.arange(0, x.shape[0])\n",
    "    \n",
    "    # Train Indices\n",
    "    full_train_indices = [np.random.choice(indices, train, replace = False) for _ in range(N)]\n",
    "        \n",
    "    # Output list\n",
    "    output_pred = []\n",
    "    output_mse = []\n",
    "    output_bestk = []\n",
    "    output_weights = []\n",
    "    output_cfmodels = []\n",
    "    \n",
    "    # Simulation replications\n",
    "    for rep_ind, train_indices in enumerate(full_train_indices, start=1):\n",
    "        \n",
    "        # Iteration printing\n",
    "        print(f\"Iteration: {rep_ind}\")\n",
    "        \n",
    "        # Test indices\n",
    "        test_indices = np.setdiff1d(indices, train_indices)\n",
    "        \n",
    "        # Train-Test-Split\n",
    "        x_train = x[train_indices].copy()\n",
    "        y_train = y[train_indices].copy()\n",
    "        x_test = x[test_indices].copy()\n",
    "        y_test = y[test_indices].copy()\n",
    "        \n",
    "        # Check\n",
    "        assert x_train.shape[0] == y_train.shape[0]\n",
    "        assert x_test.shape[0] == y_test.shape[0]\n",
    "        assert x_train.shape[0] == train\n",
    "        \n",
    "        ## Candidate Models\n",
    "        lambda_vec = None\n",
    "        kfolds = train ### kfolds = train denotes LOOCV\n",
    "        \n",
    "        # Candidate models -- Train\n",
    "        target_train, cf_train, lambda_vec = candidate_models_kf(y_train, x_train, kfolds, cm_params, ran_st = rep_ind, n_jobs = 5)\n",
    "        \n",
    "        # Candidate models -- Test\n",
    "        cf_models, cf_test, cf_descriptions = candidate_models(y_train, x_train, x_test, cm_params, lambda_vec)\n",
    "        \n",
    "        # Check\n",
    "        assert cf_train.shape[0] == x_train.shape[0]\n",
    "        assert cf_test.shape[0] == x_test.shape[0]\n",
    "        assert cf_train.shape[0] == train\n",
    "        \n",
    "        ### Benchmark Methods\n",
    "        kfolds = 5\n",
    "        \n",
    "        # PHM\n",
    "        pred_phm = np.full(y_test.shape[0], target_train.mean())\n",
    "        \n",
    "        ## Forward Stepwise Regression\n",
    "        #pred_fss, fss_k = fss_cv(y_train, x_train, x_test, kfolds, n_jobs = 4)\n",
    "        \n",
    "        # Lasso\n",
    "        pred_lasso, lasso_coef, lasso_k = lasso_cv(y_train, x_train, x_test, kfolds, n_jobs = 4)\n",
    "        \n",
    "        # peLasso\n",
    "        pred_pelasso, pelasso_coef, pelasso_k = pelasso_cv(target_train, cf_train, cf_test, kfolds, n_jobs = 4)\n",
    "        \n",
    "        # Best Average\n",
    "        vec_k = np.array([1, 2, 3, 4, 5])\n",
    "        pred_avg_best, avg_best_k = avg_best_cv(target_train, cf_train, cf_test, vec_k, kfolds, ran_st = rep_ind, n_jobs = 1)\n",
    "        \n",
    "        # Complete Subset Regression\n",
    "        vec_k = np.arange(1, 10)\n",
    "        sampling = True\n",
    "        pred_csr, csr_k = csr_cv(y_train, x_train, x_test, vec_k, sampling, kfolds, ran_st = rep_ind, n_jobs = 4)\n",
    "                \n",
    "        # Fast-Best-Split-Selection - Simple Signals\n",
    "        n_models = 5\n",
    "        split_grid = np.array([1, 2, 3, 4, 5])\n",
    "        size_grid = np.array([9, 12, 15]) # np.floor(np.array([0.3 * x_train.shape[0], 0.4 * x_train.shape[0], 0.5 * x_train.shape[0]]))\n",
    "        pred_psgd, psgd_coef, psgd_k = psgd_cv(y_train, x_train, x_test, n_models, split_grid, size_grid, kfolds, n_jobs = 4)\n",
    "                \n",
    "        # BSSF\n",
    "        alpha = 1e6\n",
    "        vec_k = np.array([1, 2, 3, 4, 5])\n",
    "        timeout = 5.0\n",
    "        method = \"gurobi\"\n",
    "        pred_bssf, bssf_weights, bssf_k = bssf_cv(target_train, cf_train, cf_test, alpha, vec_k, timeout, method, kfolds, ran_st = rep_ind)\n",
    "        \n",
    "        ### Evaluation\n",
    "        # MSE\n",
    "        mse_phm = np.mean((y_test - pred_phm)**2)\n",
    "        #mse_fss = np.mean((y_test - pred_fss)**2)\n",
    "        mse_lasso = np.mean((y_test - pred_lasso)**2)\n",
    "        mse_pelasso = np.mean((y_test - pred_pelasso)**2)\n",
    "        mse_avg_best = np.mean((y_test - pred_avg_best)**2)\n",
    "        mse_csr = np.mean((y_test - pred_csr)**2)\n",
    "        mse_psgd = np.mean((y_test - pred_psgd)**2)\n",
    "        mse_bssf = np.mean((y_test - pred_bssf)**2)            \n",
    "\n",
    "        # Append Results\n",
    "        output_pred.append([y_test, pred_phm, pred_lasso, pred_pelasso, pred_avg_best, pred_csr, pred_psgd, pred_bssf])\n",
    "        output_mse.append([mse_phm, mse_lasso, mse_pelasso, mse_avg_best, mse_csr, mse_psgd, mse_bssf])\n",
    "        output_bestk.append([None, lasso_k, pelasso_k, avg_best_k, csr_k, psgd_k, bssf_k])\n",
    "        output_weights.append(bssf_weights)\n",
    "        output_cfmodels.append(cf_models)\n",
    "    \n",
    "    return output_pred, output_mse, output_bestk, output_weights, output_cfmodels, cf_descriptions, fmodel_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Frequency Distribution of BSSF Subset-Size (k)\n",
    "# Extract BSSF Subset-Size (k)\n",
    "bssf_k = [lst[-1] for lst in best_k]\n",
    "\n",
    "# Count the frequency of each element in bssf_k\n",
    "freq = Counter(bssf_k)\n",
    "\n",
    "# Create a bar plot for the frequency distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(freq.keys(), freq.values(), color='skyblue', width = 0.75)\n",
    "plt.xlabel('k', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.title(f'BSSF - Subset Size ({N} reps)', fontsize=16)\n",
    "plt.xlim(0, 10)\n",
    "plt.xticks(range(0, 11))\n",
    "plt.ylim(0, N)\n",
    "plt.yticks(range(0, N+1))\n",
    "#plt.gca().yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "### Plot selected Candidate Models\n",
    "# Sum over repetitions\n",
    "sum_bssf_weights = np.sum(bssf_weights, axis=0)\n",
    "\n",
    "# Get model names and frequencies\n",
    "model_names = cf_descriptions\n",
    "frequencies = [sum_bssf_weights[i] for i in range(len(model_names))]\n",
    "\n",
    "# Define color mapping\n",
    "group_colors = {\n",
    "    #'ELN': 'blue',\n",
    "    'BSS': 'skyblue',\n",
    "    #'LARS': 'darkblue',\n",
    "    #'CRR': 'green',\n",
    "    'TREE': 'lightgreen',\n",
    "    'TREEST': 'lightcoral',\n",
    "    # Add more ...\n",
    "}\n",
    "\n",
    "# Extract groups from model names and assign colors\n",
    "colors = []\n",
    "for name in model_names:\n",
    "    group = name.split('_')[0]\n",
    "    color = group_colors.get(group, 'gray')\n",
    "    colors.append(color)\n",
    "\n",
    "# Create a bar plot for the frequency distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(model_names, frequencies, color=colors, width=0.5)\n",
    "plt.xlabel('Candidate Models', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.title(f'BSSF - Selected Candidate Models ({N} reps)', fontsize=16)\n",
    "plt.ylim(0, N)\n",
    "plt.yticks(range(0, N+1))\n",
    "plt.gca().yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Create custom legend\n",
    "legend_patches = [mpatches.Patch(color=color, label=group) for group, color in group_colors.items()]\n",
    "plt.legend(handles=legend_patches, title='Candidate Models')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "### Relevant Predictors\n",
    "# Extract relevant predictors\n",
    "idx = relevant_predictor(cf_models, bssf_weights)\n",
    "list_idx = [idx for sublist in idx.values() for idx in sublist]\n",
    "\n",
    "# Count the frequency of each element in bssf_k\n",
    "freq = Counter(list_idx)\n",
    "\n",
    "# Create a bar plot for the frequency distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(freq.keys(), freq.values(), color='skyblue', width = 0.75)\n",
    "plt.xlabel('Predictor', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.title(f'Selected Predictors ({N} reps)', fontsize=16)\n",
    "plt.xlim(0, 200)\n",
    "#plt.xticks(range(0, 201))\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### File for Candidate Model Functions ######\n",
    "### Import\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import random_projection\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import Lars\n",
    "import statsmodels.api as sm\n",
    "from abess.linear import LinearRegression as abessLR\n",
    "#from itertools import combinations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
