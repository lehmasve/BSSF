{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-01-09\n"
     ]
    }
   ],
   "source": [
    "# Load Packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings \n",
    "\n",
    "import time\n",
    "\n",
    "#import multiprocess as mp\n",
    "from multiprocess import Pool\n",
    "\n",
    "#from functools import partial  \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from itertools import combinations\n",
    "from itertools import chain\n",
    "from itertools import product\n",
    "\n",
    "from statsmodels.tsa.tsatools import lagmat\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn import random_projection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "#from sklearn.linear_model import LarsCV\n",
    "from sklearn.linear_model import Lars\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import LassoCV\n",
    "#from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "from dimod import BinaryQuadraticModel\n",
    "from dwave.samplers import SimulatedAnnealingSampler\n",
    "#from dwave.samplers import SteepestDescentSolver\n",
    "#from dwave.preprocessing import roof_duality\n",
    "# from dwave.system import LeapHybridSampler\n",
    "# from dwave.system import DWaveSampler\n",
    "# from dwave.system import EmbeddingComposite\n",
    "# from dimod import ExactSolver\n",
    "# from dwave.samplers import TabuSampler\n",
    "# from dwave.samplers import TreeDecompositionSolver\n",
    "\n",
    "import gurobipy as gp\n",
    "from gurobi_optimods.qubo import solve_qubo\n",
    "gp.setParam('OutputFlag', 0)\n",
    "\n",
    "if os.name == 'nt':\n",
    "    import dill\n",
    "    dill.settings['recurse'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Path\n",
    "path  =  os.path.dirname(os.getcwd()) # os.path.dirname(os.getcwd()) #r'/Users/slehmann/Library/CloudStorage/Dropbox/QUBO'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate Data\n",
    "def sim_data(n_obs, n_preds, non_zero, p, rho, scenario, snr, random_state):\n",
    "    \n",
    "    \"\"\"\n",
    "    ...\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set Seed\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Simulating nonzero betas\n",
    "    b_nonzero = (-1) ** np.random.binomial(1, p, non_zero) * ((4 * np.log(n_obs) / np.sqrt(n_obs)) + np.random.standard_normal(non_zero))\n",
    "    \n",
    "    # Simulate all Betas\n",
    "    b = np.append(b_nonzero, np.repeat(0, n_preds - non_zero))\n",
    "    \n",
    "    # Simulate Covariance Matrix\n",
    "    if scenario == 1:\n",
    "        \n",
    "        # Set Covariance Matrix between Predictors\n",
    "        cov_mat = np.full((n_preds, n_preds), rho)\n",
    "        np.fill_diagonal(cov_mat, 1.0)\n",
    "        \n",
    "    if scenario == 2:\n",
    "        \n",
    "        # Set Covariance Matrix between Predictors\n",
    "        cov_mat = np.zeros((n_preds, n_preds))\n",
    "        cov_mat[:non_zero, :non_zero] = rho\n",
    "        np.fill_diagonal(cov_mat, 1.0)\n",
    "\n",
    "    # Simulate Predictor-Time-Series\n",
    "    X = np.random.multivariate_normal([0.0]*n_preds, cov_mat, n_obs)\n",
    "    pred_names = \"X\"+pd.Series(range(1, n_preds+1)).astype(str) \n",
    "    \n",
    "    # Simulate Noise\n",
    "    adj   =  np.sqrt((b.transpose() @ cov_mat @ b) / snr)\n",
    "    error =  np.random.standard_normal(n_obs)   \n",
    "\n",
    "    # Set Target Variable\n",
    "    y = X @ b + adj * error\n",
    "    \n",
    "    # Return\n",
    "    return(y, X, pred_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate Data\n",
    "def sim(n_obs, n_preds, b, p, r):\n",
    "    \n",
    "    \"\"\"\n",
    "    Simulate Data for Regression Problem\n",
    "    with pre-determined Covariance Matrix between Predictors\n",
    "    and pre-determined Coefficients\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set Seed\n",
    "    np.random.seed(r)\n",
    "    \n",
    "    # Set Covariance Matrix between Predictors\n",
    "    cov_mat = np.full((n_preds, n_preds), p)\n",
    "    np.fill_diagonal(cov_mat, 1.0)\n",
    "\n",
    "    # Simulate Predictor Time Series\n",
    "    X = np.random.multivariate_normal([0.0]*n_preds, cov_mat, n_obs)\n",
    "    pred_names = \"X\"+pd.Series(range(1, n_preds+1)).astype(str) #list(X.columns)\n",
    "\n",
    "    # Set Noise\n",
    "    noise  =  1.0\n",
    "    eps    =  np.random.normal(0.0, noise, n_obs)\n",
    "\n",
    "    # Set Coefficients\n",
    "    b_scl = np.sqrt(n_preds / np.sum(b)) * b * noise / np.sqrt(100)   \n",
    "\n",
    "    # Set Target Variable\n",
    "    y = X @ b_scl + eps\n",
    "    \n",
    "    # Return\n",
    "    return(y, X, pred_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create Lags\n",
    "def create_lags(y, X, mlags):\n",
    "    \n",
    "    \"\"\"\n",
    "    Add mlags lags of y to X\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add all lags from zero to maxlag\n",
    "    X = np.concatenate((lagmat(y, maxlag = mlags, use_pandas = True), X), axis = 1)\n",
    "    \n",
    "    # Return\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Pre-Process Data\n",
    "def prepro(y, X, t):\n",
    "    \n",
    "    \"\"\"\n",
    "    Split Data in Train and Predict Data and Standardize Data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Train Data\n",
    "    y_train  =  y[:t]\n",
    "    X_train  =  X[:t]\n",
    "\n",
    "    # Predict Data\n",
    "    y_pred  =  y[t]\n",
    "    X_pred  =  X[[t]]\n",
    "    \n",
    "    # Standardize Data\n",
    "    scaler  =  StandardScaler()   \n",
    "    X_train =  scaler.fit_transform(X_train)\n",
    "    X_pred  =  scaler.transform(X_pred)\n",
    "    \n",
    "    ## Add Constant\n",
    "    X_train =  sm.add_constant(X_train)\n",
    "    X_pred  =  sm.add_constant(X_pred, has_constant = 'add')\n",
    "    \n",
    "    return y_train, X_train, y_pred, X_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Complete) Subset Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return array of all subsets of length k\n",
    "def complete_sub(arr, k):\n",
    "    \n",
    "    \"\"\"\n",
    "    Elements are treated as unique based on their position, not on their value.\n",
    "    So if the input elements are unique, there will be no repeated values in each combination.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get all subsets of size k\n",
    "    subset = list(combinations(arr, k)) \n",
    "    \n",
    "    # Return \n",
    "    return subset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate number of models\n",
    "def n_models(K, k):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate number of models\n",
    "    \"\"\"\n",
    "    \n",
    "    return math.factorial(K) / (math.factorial(k) * math.factorial(K-k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to randomly select n_max items from array\n",
    "def random_select(arr, n_max, random_state):\n",
    "    \n",
    "    \"\"\"\n",
    "    ...\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set random state\n",
    "    random.seed(random_state)\n",
    "    \n",
    "    # Set upper Boundary\n",
    "    upper_bound  =  len(arr) if len(arr) < n_max else n_max\n",
    "    \n",
    "    # Randomly select items without repetition\n",
    "    rand_arr  =  random.sample(arr, k = upper_bound)\n",
    "    \n",
    "    # Return \n",
    "    return rand_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to produce Subset Regression Forecasts\n",
    "def ssf(y_train, X_train, X_pred, feature, mlags):\n",
    "    \n",
    "    # Subset Feature Space (incl. constant)\n",
    "    X_train_subset = X_train[:, list(range(0, mlags+1)) + list(feature)]\n",
    "    X_pred_subset  = X_pred[:, list(range(0, mlags+1)) + list(feature)]\n",
    "    \n",
    "    # Fit Model\n",
    "    model =  sm.OLS(y_train, X_train_subset) # LinearRegression() \n",
    "    regr  =  model.fit() # model.fit(X_train_subset, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    pred = regr.predict(X_pred_subset)\n",
    "    \n",
    "    return(pred[0], regr.params[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressed Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compressed Regression (Gaussian random projection)\n",
    "def cr_reg(y_train, X_train, X_pred, n_comp, mlags, ran_st):\n",
    "    \n",
    "    # Set up Random-Projection-Matrix\n",
    "    projector = random_projection.GaussianRandomProjection(n_components = n_comp, random_state = ran_st)\n",
    "    \n",
    "    # Transform\n",
    "    X_train_proj =  projector.fit_transform(X_train[:, (mlags+1):])\n",
    "    X_pred_proj  =  projector.fit_transform(X_pred[:,  (mlags+1):])\n",
    "\n",
    "    # Add Constant + Lags\n",
    "    rp_train =  np.concatenate([X_train[:, :(mlags+1)], X_train_proj], axis = 1)\n",
    "    rp_pred  =  np.concatenate([X_pred[:,  :(mlags+1)], X_pred_proj],  axis = 1)\n",
    "\n",
    "    # Fit Model\n",
    "    model  =  sm.OLS(y_train, rp_train) #LinearRegression()\n",
    "    regr   =  model.fit() # model.fit(rp_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    pred = regr.predict(rp_pred)\n",
    "    \n",
    "    return pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regression\n",
    "def dt_reg(y_train, X_train, X_pred, ran_st):\n",
    "    \n",
    "    # Set up Regressor Object \n",
    "    model = DecisionTreeRegressor(criterion = \"squared_error\",\n",
    "                                  max_depth = 20,\n",
    "                                  splitter  = \"random\",\n",
    "                                  random_state = ran_st)\n",
    "    \n",
    "    # Fit model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    pred = model.predict(X_pred)\n",
    "\n",
    "    # Return Prediction\n",
    "    return pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop Candidate Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all Candidate Models in one Function\n",
    "def candidate_models_t(y_, X_, t_, k_range_, cr_range_, rep_range_):\n",
    "    \n",
    "    ### Pre-Process Data ###\n",
    "    y_train, X_train, y_pred, X_pred = prepro(y_, X_, t_)\n",
    "    \n",
    "    ### Subset Forecasts ###\n",
    "    if np.sum(k_range_) == 0:\n",
    "        preds_ssf = np.array([]) \n",
    "    else: \n",
    "        feature_set       = list(chain(*list(map(lambda k: complete_sub(list(range(1, X_train.shape[1])), k), k_range_))))\n",
    "        preds_ssf, coeffs = zip(*list(map(lambda feature: ssf(y_train, X_train, X_pred, feature, 0), feature_set)))\n",
    "    \n",
    "    ### Compressed Regressions ###\n",
    "    if (np.sum(cr_range_) == 0) or (np.sum(rep_range_) == 0):\n",
    "        preds_cr = np.array([]) \n",
    "    else:\n",
    "        preds_cr = np.array(list(map(lambda z: cr_reg(y_train, X_train, X_pred, z[0], 0, z[1]), product(cr_range_, rep_range_))))\n",
    "            \n",
    "    ### Concatenate Predictions ###\n",
    "    cand_forecasts = np.concatenate([preds_ssf, preds_cr])\n",
    "    \n",
    "    return cand_forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all Candidate Models in Parallel\n",
    "def candidate_models(y, X, t_range, k_range, cr_range, rep_range, n_core):\n",
    "    \n",
    "    ### Create Candidate Models ###\n",
    "    if __name__ == '__main__':\n",
    "        pool_ = Pool(n_core)\n",
    "        cand_forecasts = np.array(pool_.map(lambda t: candidate_models_t(y, X, t, k_range, cr_range, rep_range), t_range))\n",
    "        pool_.close()\n",
    "        \n",
    "    # Return\n",
    "    return cand_forecasts\n",
    "                \n",
    "#f = partial(candidate_models, y_ = y, X_ = X, k_range_ = k_range, cr_range_ = cr_range, rep_range_ = rep_range)\n",
    "#with mp.Pool(5) as pool:\n",
    "#    cand_forecasts = np.array([result for result in pool.map(lambda t: f(t_ = t), range(init, n_obs))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AR-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoregressive Model\n",
    "def ar_mod(y_train, lags):\n",
    "\n",
    "    # Fit AR-Model\n",
    "    model = AutoReg(y_train, lags=lags).fit()\n",
    "    \n",
    "    # Prediction\n",
    "    pred = model.forecast(steps=1)\n",
    "\n",
    "    # Return Prediction\n",
    "    return pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Angle Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fit and predict LARS-Models\n",
    "def lars(y_train, cf_train, cf_pred, n_range):\n",
    "\n",
    "    # Set up Array\n",
    "    predictions = np.full(len(n_range), np.nan)\n",
    "    \n",
    "    # Init Counter\n",
    "    i = 0\n",
    "    \n",
    "    # Loop over Subset Size\n",
    "    for n in n_range:\n",
    "        \n",
    "        # Define Model\n",
    "        model = Lars(fit_intercept = True,\n",
    "                     fit_path = False,\n",
    "                     jitter = None,\n",
    "                     n_nonzero_coefs = n,\n",
    "                     random_state = 123)\n",
    "\n",
    "        # Fit Model\n",
    "        model.fit(cf_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        predictions[i] = model.predict(cf_pred)[0][0]\n",
    "        \n",
    "        # Update Counter\n",
    "        i += 1\n",
    "    \n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Stepwise Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform Forward Stepwise Selection\n",
    "def fss_n(y_train, cf_train, cf_pred, n):\n",
    "    \n",
    "        # Model\n",
    "        model = LinearRegression()\n",
    "    \n",
    "        # Sequential Forward Selection\n",
    "        sfs = SequentialFeatureSelector(model,\n",
    "                                        n_features_to_select = n,\n",
    "                                        direction = 'forward')\n",
    "    \n",
    "        # Select Features\n",
    "        active_set = sfs.fit(cf_train, y_train).get_support()\n",
    "    \n",
    "        # Fit Model\n",
    "        model.fit(cf_train[:, active_set], y_train)\n",
    "    \n",
    "        # Predict\n",
    "        pred = model.predict(cf_pred[:, active_set])[0]\n",
    "        \n",
    "        # Return\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform Forward Stepwise Selection in Parallel\n",
    "def fss(y_train, cf_train, cf_pred, n_range, n_core):\n",
    "    \n",
    "    # Parallelize over Subset Size\n",
    "    if __name__ == '__main__':\n",
    "        pool_ = Pool(n_core)\n",
    "        predictions = np.array(pool_.map(lambda n: fss_n(y_train, cf_train, cf_pred, n), n_range))\n",
    "        pool_.close()\n",
    "\n",
    "    # Return\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partially-Egalitarian Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fit and predict peLASSO-Models\n",
    "def peLASSO(y_train, cf_train, cf_pred, n_alpha, n_iter, cv_splits, cv_repeats):\n",
    "    \n",
    "    # No warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    ### Step 1: Select to zero\n",
    "    # Define Cross-Validation Method\n",
    "    cv = RepeatedKFold(n_splits = cv_splits,\n",
    "                       n_repeats = cv_repeats,\n",
    "                       random_state = 1)\n",
    "    \n",
    "    # Define Model\n",
    "    model_lasso = LassoCV(fit_intercept = True,\n",
    "                          n_alphas = n_alpha,\n",
    "                          max_iter = n_iter,\n",
    "                          cv = cv,\n",
    "                          n_jobs=-1)\n",
    "    \n",
    "    # Fit Model\n",
    "    model_lasso.fit(cf_train, y_train)\n",
    "    \n",
    "    # Get & select only active candidate models\n",
    "    active_cf_train = cf_train[:, model_lasso.coef_.astype(bool)]\n",
    "    active_cf_pred  = cf_pred[: , model_lasso.coef_.astype(bool)]\n",
    "\n",
    "    ### Step 2: Shrink towards equality\n",
    "    # Check if active candidate models exist\n",
    "    if active_cf_train.shape[1] > 0:\n",
    "        \n",
    "        mean_cf = active_cf_train.mean(axis = 1)\n",
    "    \n",
    "        # Define Cross-Validation Method\n",
    "        cv = RepeatedKFold(n_splits = cv_splits,\n",
    "                           n_repeats = cv_repeats,\n",
    "                           random_state = 1)\n",
    "    \n",
    "        # Define Model\n",
    "        model_elasso = LassoCV(fit_intercept = True,\n",
    "                               n_alphas = n_alpha,\n",
    "                               max_iter = n_iter,\n",
    "                               cv = cv,\n",
    "                               n_jobs=-1)\n",
    "    \n",
    "        # Fit Model\n",
    "        model_elasso.fit(active_cf_train, (y_train-mean_cf))\n",
    "    \n",
    "        # Predict\n",
    "        pred = model_elasso.predict(active_cf_pred)[0]\n",
    "        \n",
    "        #print(active_cf_pred)\n",
    "    \n",
    "    else:\n",
    "        print(\"No active candidate models\")\n",
    "        \n",
    "        # Set Prediction to mean\n",
    "        pred = y_train.mean()\n",
    "        \n",
    "    \n",
    "    # Return Prediction\n",
    "    return(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average-Best Forecast Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual-based average-best forecast combination\n",
    "def avg_best(y_train, cf_train, cf_pred, n_range):\n",
    "    \n",
    "    # Set up Array\n",
    "    predictions = np.full(len(n_range), np.nan)\n",
    "    \n",
    "    # Calculate Squared Errors\n",
    "    se = ([[value] for value in y_train] - cf_train) ** 2\n",
    "\n",
    "    # Mean-Squared-Error\n",
    "    mse = np.mean(se, axis = 0)\n",
    "\n",
    "    # Get indices of the average-best N candidate models\n",
    "    ind = np.argsort(mse)\n",
    "\n",
    "    # Init Counter\n",
    "    i = 0\n",
    "    \n",
    "    # Loop over Subset Size\n",
    "    for n in n_range:\n",
    "        \n",
    "        # Predict\n",
    "        pred = np.mean(cf_pred[:, ind[:n]])\n",
    "        \n",
    "        # Append Prediction\n",
    "        predictions[i] = pred\n",
    "        \n",
    "        # Update Counter\n",
    "        i += 1\n",
    "        \n",
    "    # Return\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Selection of Forecasts (D-Wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Selection of Forecasts\n",
    "def bssf(y_train, cf_train, cf_pred, alpha, n_sub, bssf_timeout, method):\n",
    "    \n",
    "    # Adapt X-Matrix\n",
    "    cf_train  =  cf_train / n_sub\n",
    "    cf_pred   =  cf_pred  / n_sub\n",
    "    \n",
    "    # Generate Q-Matrix\n",
    "    ivec      =  np.mat(np.ones(cf_train.shape[1])).transpose()\n",
    "    aux_mat   =  np.array(y_train.transpose() @ cf_train + alpha * n_sub)\n",
    "    Q         =  - 2 * np.diag(aux_mat) + cf_train.transpose() @ cf_train + alpha * ivec @ ivec.transpose()\n",
    "\n",
    "    ## Initialize BQM\n",
    "    #bqm  =  BinaryQuadraticModel('BINARY')\n",
    "    #bqm  =  bqm.from_qubo(Q)\n",
    "    #\n",
    "    ## Normalize\n",
    "    #bqm.normalize()\n",
    "    #\n",
    "    ## Preprocess (?)\n",
    "    ##roof_duality(bqm)    \n",
    "    #\n",
    "    ## Select Solver\n",
    "    #solver_qpu  =  SimulatedAnnealingSampler() #LeapHybridSampler() SimulatedAnnealingSampler() EmbeddingComposite(DWaveSampler())\n",
    "    ##solver_pp   =  SteepestDescentSolver()    #SteepestDescentSolver()\n",
    "    #\n",
    "    ## Submit for Solution\n",
    "    #sampleset  =  solver_qpu.sample(bqm, \n",
    "    #                                num_reads = n_times,\n",
    "    #                                #time_limit = 90,\n",
    "    #                                label = \"Best Subset Selection of Forecasts\",\n",
    "    #                                seed = 123) # f'Best Subset Selection of Forecasts{t}'\n",
    "    #\n",
    "    ### Postprocess Problem\n",
    "    ##sampleset_pp = solver_pp.sample(bqm,\n",
    "    ##                                initial_states = sampleset.lowest())\n",
    "    #\n",
    "    ## Get Solution\n",
    "    #solution    =  np.array(list(sampleset.first[0].values()))\n",
    "    \n",
    "    if method == \"qubo\":\n",
    "    \n",
    "        # Set up Model\n",
    "        model = gp.Model()\n",
    "        model.Params.TimeLimit = bssf_timeout\n",
    "        \n",
    "        # Decision Variables\n",
    "        b = model.addMVar(shape=Q.shape[0], vtype=gp.GRB.BINARY, name=\"b\")\n",
    "        \n",
    "        # Objective Function\n",
    "        model.setObjective(b @ Q @ b, gp.GRB.MINIMIZE)\n",
    "        \n",
    "        # Optimize\n",
    "        model.optimize()\n",
    "        solution = np.array(model.x)\n",
    "        \n",
    "    if method == \"qcbo\":\n",
    "        \n",
    "        # Set up Model\n",
    "        model = gp.Model()\n",
    "        model.params.timelimit = bssf_timeout\n",
    "\n",
    "        # Decision Variables\n",
    "        b = model.addMVar(shape=cf_train.shape[1], vtype=gp.GRB.BINARY, name=\"b\")\n",
    "        norm_0 = model.addVar(lb=n_sub, ub=n_sub, name=\"norm\")\n",
    "\n",
    "        # Objective Function\n",
    "        model.setObjective(b.T @ cf_train.T @ cf_train @ b\n",
    "                           - 2*y_train.T @ cf_train @ b\n",
    "                           + np.dot(y_train, y_train), gp.GRB.MINIMIZE)\n",
    "\n",
    "        # L0-Norm Constraint\n",
    "        model.addGenConstrNorm(norm_0, b, which=0, name=\"budget\")\n",
    "\n",
    "        # Optimize\n",
    "        model.optimize()\n",
    "        solution = np.array(model.x)[:-1]\n",
    "    \n",
    "    # Test Solution\n",
    "    if np.sum(solution) != n_sub:\n",
    "        print(f\"Warning: Number of selected features does not match --- {np.sum(solution)} instead of {n_sub}!\")\n",
    "    \n",
    "    # Prediction \n",
    "    pred = solution @ cf_pred.transpose()\n",
    "    \n",
    "    # Return \n",
    "    return(pred[0], solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs = 100\n",
    "init  =  50\n",
    "n_preds = 4\n",
    "b = 1\n",
    "bernoulli_p = 0.2\n",
    "rho = 0.5\n",
    "scenario = 1\n",
    "snr = 3 \n",
    "r = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolds = 2\n",
    "krepeats = 1\n",
    "k_range = [1, 2]\n",
    "cr_range = [1]\n",
    "rep_range = range(5)\n",
    "n_core = 1\n",
    "ran_st = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simulate Data ###\n",
    "y, X, pred_names = sim_data(n_obs, n_preds, b, bernoulli_p, rho, scenario, snr, r)\n",
    "\n",
    "### Create Candidate Models ###\n",
    "cand_forecasts = candidate_models(y, X, range(init, n_obs), k_range, cr_range, rep_range, n_core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.22498112e-01,  2.66514093e-02, -2.02284461e-02,\n",
       "        -2.38016593e-02,  2.20830563e-01,  2.18093790e-01,\n",
       "         2.27956356e-01,  4.69403908e-03,  1.53767655e-02,\n",
       "        -5.84781784e-03,  1.06022326e-01, -5.14908155e-02,\n",
       "        -4.30154655e-02,  9.36764933e-02, -8.90364084e-02],\n",
       "       [-4.79778224e-02, -6.95853328e-02, -2.43829477e-01,\n",
       "        -4.42537477e-01, -4.78686705e-02, -6.95719767e-02,\n",
       "         6.06128623e-02, -2.31681828e-01, -3.79339851e-01,\n",
       "        -3.80673698e-01, -4.47863327e-01,  2.07963589e-01,\n",
       "         1.04436848e-01,  5.21464512e-01, -4.92083866e-02],\n",
       "       [ 4.84182703e-01, -1.73668432e-01, -1.63966759e-01,\n",
       "         1.54506407e-01,  4.86681499e-01,  4.51990470e-01,\n",
       "         4.60800553e-01, -1.87892246e-01,  6.34529447e-02,\n",
       "        -5.02224790e-02,  2.51804805e-01,  1.00031148e-01,\n",
       "        -2.87307753e-01, -9.13246412e-02, -8.46176101e-02],\n",
       "       [ 1.14779557e-01, -1.82276288e-01,  2.48370986e-01,\n",
       "         4.36317479e-01,  1.12823421e-01,  1.49557875e-01,\n",
       "        -1.88941462e-02,  1.90639236e-01,  2.88022209e-01,\n",
       "         4.13627349e-01,  5.09830492e-01, -3.10166679e-01,\n",
       "        -2.17228442e-01, -7.68337020e-01, -7.18745184e-02],\n",
       "       [-3.19761226e-01,  1.87042952e-01,  1.00740587e-01,\n",
       "         1.34221112e-01, -3.13431013e-01, -2.87685290e-01,\n",
       "        -4.01648666e-01,  1.65092372e-01,  2.28809328e-01,\n",
       "         1.57413236e-01,  1.38012781e-01, -4.47665582e-01,\n",
       "        -1.16646475e-01, -4.31285782e-01, -9.19865800e-02],\n",
       "       [-1.28516701e-01,  1.83409202e-01, -6.94249211e-01,\n",
       "        -2.48165143e-01, -1.21086639e-01, -2.07783071e-01,\n",
       "        -7.85027507e-02, -5.72375701e-01, -8.45233328e-02,\n",
       "        -6.66072103e-01, -3.83446213e-01,  4.12624961e-02,\n",
       "        -4.55452686e-01,  2.58030176e-01, -1.45884197e-01],\n",
       "       [ 7.58570129e-01,  3.91675611e-01,  4.66074971e-01,\n",
       "         1.17218513e-01,  7.63298140e-01,  7.99139329e-01,\n",
       "         7.60075505e-01,  5.74178210e-01,  3.18559079e-01,\n",
       "         4.57019833e-01,  6.27896760e-01, -1.91316958e-01,\n",
       "         3.31825830e-01,  4.41447198e-01, -8.49562443e-02],\n",
       "       [-8.42944872e-03,  1.06267243e-01,  6.86839455e-01,\n",
       "         3.50750634e-01, -3.47368975e-03,  9.79376854e-02,\n",
       "        -1.23396487e-01,  6.76048934e-01,  3.57575791e-01,\n",
       "         7.32347233e-01,  5.79490837e-01, -5.14760551e-01,\n",
       "         2.40811936e-01, -5.44983184e-01, -3.42083019e-02],\n",
       "       [ 1.61620068e+00,  4.75869956e-01,  3.02481812e-01,\n",
       "         6.66981439e-01,  1.61273180e+00,  1.60868925e+00,\n",
       "         1.47292189e+00,  4.66115754e-01,  8.16237360e-01,\n",
       "         5.36795661e-01,  1.36935127e+00, -2.11394130e-01,\n",
       "        -2.36602076e-01,  1.07901851e-01, -1.40872940e-01],\n",
       "       [ 1.16876076e+00,  2.33615124e-01,  6.29711941e-01,\n",
       "         2.16650475e-01,  1.17055245e+00,  1.18607472e+00,\n",
       "         1.18871754e+00,  6.56553392e-01,  3.07272559e-01,\n",
       "         6.04037682e-01,  8.15858501e-01,  3.76318654e-02,\n",
       "         4.60329772e-01,  5.69953455e-01, -5.03595460e-02],\n",
       "       [-5.19026407e-01, -2.87826853e-01, -3.48203237e-03,\n",
       "        -3.71331338e-01, -5.23837825e-01, -5.07907670e-01,\n",
       "        -4.52062868e-01, -1.26912714e-01, -4.37357815e-01,\n",
       "        -1.74684368e-01, -5.18678820e-01,  8.04826364e-02,\n",
       "         2.27694082e-01,  6.85283993e-02, -2.48601796e-02],\n",
       "       [-5.69307606e-02,  5.41241024e-03, -1.31790588e-01,\n",
       "        -2.12391397e-01, -5.50580726e-02, -6.18594387e-02,\n",
       "        -9.92135363e-03, -9.72324696e-02, -1.46953384e-01,\n",
       "        -1.99287211e-01, -2.12501934e-01,  5.95245270e-02,\n",
       "         1.86300755e-02,  2.26834480e-01, -3.51230578e-02],\n",
       "       [ 6.49678789e-01, -8.23054316e-01, -3.54058920e-01,\n",
       "        -6.12013846e-01,  6.07280841e-01,  6.22676497e-01,\n",
       "         8.71413948e-01, -6.85169126e-01, -9.15694864e-01,\n",
       "        -5.72000812e-01, -5.37999044e-01,  9.06810924e-01,\n",
       "         1.87810245e-01,  9.92458071e-01, -6.50092667e-02],\n",
       "       [ 3.42838145e-01,  5.12826907e-01,  1.04014475e+00,\n",
       "         1.13460027e-01,  3.63348975e-01,  3.88380388e-01,\n",
       "         3.31503831e-01,  1.11973358e+00,  3.51921753e-01,\n",
       "         8.77085123e-01,  6.35832519e-01, -3.99226430e-01,\n",
       "         8.73099172e-01,  3.40885901e-01, -1.59587307e-02],\n",
       "       [ 1.61265561e+00,  4.55628882e-01,  9.33658431e-01,\n",
       "         5.57556822e-01,  1.61767904e+00,  1.62354758e+00,\n",
       "         1.56420943e+00,  9.90923565e-01,  6.68360840e-01,\n",
       "         1.00204797e+00,  1.37960727e+00, -1.13640783e-01,\n",
       "         5.22131614e-01,  4.87391311e-01, -1.62446489e-02],\n",
       "       [-4.99405032e-01, -3.05911677e-01, -3.83789907e-01,\n",
       "        -9.59567428e-02, -5.04309335e-01, -5.04900407e-01,\n",
       "        -5.07279606e-01, -4.49497706e-01, -2.30537226e-01,\n",
       "        -3.45120666e-01, -4.15939507e-01,  7.72368167e-02,\n",
       "        -3.06909747e-01, -3.44274672e-01,  1.50017284e-02],\n",
       "       [-8.66187274e-01,  2.80697256e-01, -2.69692271e-01,\n",
       "         2.00836648e-01, -8.59838841e-01, -8.66195973e-01,\n",
       "        -9.82258913e-01, -1.31382609e-01,  2.94497080e-01,\n",
       "        -1.12085066e-01, -1.40650746e-01, -4.68141088e-01,\n",
       "        -4.63658554e-01, -8.04017930e-01,  2.98765722e-02],\n",
       "       [-2.41604425e-01, -2.42576061e-01, -7.04572015e-02,\n",
       "        -4.73905570e-01, -2.41532161e-01, -2.41332844e-01,\n",
       "        -1.26317236e-01, -1.39289546e-01, -4.86515353e-01,\n",
       "        -2.68758799e-01, -5.40162682e-01,  2.63791194e-01,\n",
       "         2.93586579e-01,  4.52194054e-01, -2.94813904e-03],\n",
       "       [-1.34621920e+00,  6.82587165e-02, -8.40740231e-01,\n",
       "        -4.40100168e-01, -1.33312628e+00, -1.35322934e+00,\n",
       "        -1.33612859e+00, -6.98830214e-01, -3.08021152e-01,\n",
       "        -8.52321391e-01, -1.01419014e+00, -1.83240001e-01,\n",
       "        -5.25069148e-01, -3.44625144e-01, -1.49474166e-02],\n",
       "       [-1.06334000e+00, -3.43098752e-01, -3.55002864e-01,\n",
       "        -9.73686176e-01, -1.06830248e+00, -1.06231009e+00,\n",
       "        -9.45795162e-01, -4.16689755e-01, -9.35757720e-01,\n",
       "        -7.36944697e-01, -1.26519431e+00,  1.84624686e-01,\n",
       "         2.83217233e-01,  4.17219304e-01, -6.01196688e-02],\n",
       "       [-9.18605485e-01, -2.48255186e-01, -8.42710562e-01,\n",
       "        -1.33126455e-01, -9.20558277e-01, -9.29092726e-01,\n",
       "        -9.44996653e-01, -8.14338993e-01, -1.89491410e-01,\n",
       "        -6.65024855e-01, -6.53944925e-01, -1.47472460e-01,\n",
       "        -7.37627361e-01, -6.82612964e-01, -5.33105189e-02],\n",
       "       [ 5.24262744e-01, -1.79590368e-01,  1.92834291e-01,\n",
       "        -1.91067225e-01,  5.16255738e-01,  5.27047720e-01,\n",
       "         5.63097749e-01,  1.35001595e-01, -2.08072936e-01,\n",
       "         7.30446415e-02,  1.01828778e-01,  1.30002951e-01,\n",
       "         2.57340183e-01,  4.20800220e-01, -1.07995744e-01],\n",
       "       [-6.53256656e-01, -5.65354126e-02, -3.76798140e-01,\n",
       "        -4.98701245e-01, -6.47775426e-01, -6.56520992e-01,\n",
       "        -6.19020569e-01, -3.36032142e-01, -4.16675545e-01,\n",
       "        -5.15946667e-01, -6.74472921e-01, -6.30560152e-02,\n",
       "        -7.89399351e-02,  7.93623944e-02, -9.17236324e-02],\n",
       "       [ 4.02913467e-01, -1.63374119e-02, -3.22805047e-01,\n",
       "         2.67244208e-01,  4.03226160e-01,  3.88351839e-01,\n",
       "         3.71266202e-01, -2.73934432e-01,  2.39183369e-01,\n",
       "        -8.33830093e-02,  3.00017143e-01, -6.69664903e-02,\n",
       "        -4.92353369e-01, -2.31321671e-01, -9.14047510e-02],\n",
       "       [ 1.68805114e+00,  7.21712603e-01,  3.94136411e-01,\n",
       "         3.89866184e-01,  1.71567256e+00,  1.68382209e+00,\n",
       "         1.69508073e+00,  6.16616870e-01,  6.35143675e-01,\n",
       "         5.25618653e-01,  1.15740525e+00, -3.98324470e-02,\n",
       "         1.51078885e-01,  8.20638277e-01, -7.10964109e-02],\n",
       "       [ 8.50102870e-01, -1.95911861e-01,  7.05249105e-01,\n",
       "         1.81219744e-01,  8.29413238e-01,  8.61442697e-01,\n",
       "         8.55485074e-01,  5.31125503e-01,  6.41644906e-02,\n",
       "         6.32921810e-01,  6.26368247e-01,  5.09556796e-02,\n",
       "         4.60463629e-01,  2.29563583e-01, -1.04928134e-01],\n",
       "       [ 1.72055369e+00,  7.57398447e-01,  9.32164332e-01,\n",
       "         1.63537355e-01,  1.75444724e+00,  1.72940465e+00,\n",
       "         1.76582515e+00,  1.12589871e+00,  4.88732534e-01,\n",
       "         7.90418811e-01,  1.11665742e+00,  4.96575708e-02,\n",
       "         7.70980507e-01,  1.22326720e+00, -5.47442680e-02],\n",
       "       [ 1.26595005e-01, -5.29197101e-01, -2.36791965e-01,\n",
       "        -2.83749867e-01,  9.16064616e-02,  1.19435379e-01,\n",
       "         1.67495695e-01, -4.15438531e-01, -4.86552927e-01,\n",
       "        -3.18385436e-01, -3.23085272e-01,  3.16137823e-01,\n",
       "        -3.68561109e-03,  2.26178661e-01, -3.69600087e-02],\n",
       "       [ 1.17559692e+00,  1.50173503e-01, -6.05901834e-02,\n",
       "        -2.58009127e-01,  1.17257879e+00,  1.16515742e+00,\n",
       "         1.26032018e+00,  1.12182339e-02, -1.17547652e-01,\n",
       "        -1.71512190e-01,  1.93465358e-01,  4.55105531e-01,\n",
       "         2.45140122e-01,  1.14961467e+00, -1.45433060e-02],\n",
       "       [ 9.05902809e-01,  1.60658141e-01,  4.95768882e-01,\n",
       "         5.12335144e-01,  9.05161207e-01,  9.07351278e-01,\n",
       "         8.65649839e-01,  4.85084421e-01,  4.65427066e-01,\n",
       "         6.31626458e-01,  8.73732662e-01, -4.96919036e-02,\n",
       "         1.15345946e-01, -6.38675054e-03,  8.12521160e-03],\n",
       "       [-8.33213057e-01, -2.20843887e-01, -1.10407755e+00,\n",
       "        -2.06120980e-01, -8.37056359e-01, -8.46100277e-01,\n",
       "        -8.35653067e-01, -1.03628733e+00, -2.79502837e-01,\n",
       "        -9.59050610e-01, -8.06192018e-01,  1.11315919e-01,\n",
       "        -8.11356321e-01, -3.82808504e-01,  5.50239632e-02],\n",
       "       [-4.56104661e-01, -7.10777292e-02, -4.98670179e-01,\n",
       "        -1.00087041e+00, -4.56101593e-01, -4.55408304e-01,\n",
       "        -3.34569372e-01, -4.57017076e-01, -7.97047019e-01,\n",
       "        -8.86279208e-01, -1.10835896e+00,  4.27484837e-01,\n",
       "         2.99815848e-01,  9.92282967e-01,  1.68498535e-03],\n",
       "       [-5.92985627e-01,  4.86892672e-01,  4.97036619e-02,\n",
       "        -2.42112825e-01, -5.67895924e-01, -5.97270575e-01,\n",
       "        -5.75559707e-01,  2.40917952e-01,  9.21965295e-02,\n",
       "        -7.95331635e-02, -3.06219069e-01, -2.16090212e-01,\n",
       "         2.06108999e-01,  1.53156446e-01,  2.56538937e-02],\n",
       "       [ 2.23152661e-01, -1.42934535e-01,  4.92617514e-01,\n",
       "         9.71809577e-02,  2.14312683e-01,  2.16646172e-01,\n",
       "         2.19096015e-01,  3.58953111e-01, -1.05941689e-02,\n",
       "         4.26370098e-01,  2.60041437e-01,  1.11259349e-02,\n",
       "         3.65664692e-01,  1.20125864e-02,  3.41999265e-03],\n",
       "       [ 4.62570660e-01,  5.27589060e-01,  8.72613854e-02,\n",
       "        -7.76496665e-01,  4.82760389e-01,  4.64419300e-01,\n",
       "         6.35095426e-01,  2.87071648e-01, -3.00464628e-01,\n",
       "        -3.06938306e-01, -3.77113165e-01,  3.87804515e-01,\n",
       "         7.42526081e-01,  1.60691760e+00,  7.09166553e-03],\n",
       "       [ 8.16104085e-01,  4.92542018e-01,  3.30214848e-01,\n",
       "        -1.75288638e-01,  8.21376829e-01,  8.15803793e-01,\n",
       "         8.65039761e-01,  4.75879120e-01,  1.36230176e-01,\n",
       "         1.67268434e-01,  2.96099719e-01,  1.80412357e-01,\n",
       "         4.97222761e-01,  9.39304381e-01,  1.08149242e-02],\n",
       "       [-1.65593344e+00, -3.84314057e-01, -3.58334058e-01,\n",
       "        -5.76991442e-01, -1.65438134e+00, -1.65998008e+00,\n",
       "        -1.64471413e+00, -4.59530290e-01, -6.68369286e-01,\n",
       "        -5.68114668e-01, -1.18976689e+00, -1.19275736e-01,\n",
       "        -2.32874271e-02, -4.23438748e-01,  1.17401712e-03],\n",
       "       [ 7.59974898e-01,  5.77030457e-02,  7.29618727e-01,\n",
       "         2.95339934e-01,  7.60698699e-01,  7.48372546e-01,\n",
       "         7.53295824e-01,  6.50931599e-01,  2.68028518e-01,\n",
       "         7.08456800e-01,  7.21561134e-01, -4.70764467e-02,\n",
       "         4.18724634e-01,  1.41043813e-01, -4.15857358e-02],\n",
       "       [-2.49541827e-01, -4.62486424e-01,  1.74837926e-01,\n",
       "         4.21210935e-01, -2.45430532e-01, -2.56149313e-01,\n",
       "        -2.86679024e-01, -3.39933116e-02,  8.08824432e-02,\n",
       "         3.53735131e-01,  2.28908435e-01, -1.80099977e-01,\n",
       "        -1.96808437e-01, -8.07709390e-01, -1.65164673e-02],\n",
       "       [-1.17774144e-01,  5.72581189e-01,  3.61773637e-01,\n",
       "         4.36534425e-01, -1.12984979e-01, -1.31201876e-01,\n",
       "        -1.62382248e-01,  5.57641038e-01,  6.75734476e-01,\n",
       "         5.02329624e-01,  5.27062123e-01, -5.23948710e-01,\n",
       "        -3.27657575e-02, -4.13495228e-01,  4.95712882e-03],\n",
       "       [-1.21749485e-01,  3.60307722e-01, -3.87485098e-01,\n",
       "         3.01369008e-01, -9.99793858e-02, -1.18968827e-01,\n",
       "        -1.41251239e-01, -1.65152109e-01,  4.42543727e-01,\n",
       "        -1.38074044e-01,  1.48073772e-01, -2.14300009e-01,\n",
       "        -5.22089754e-01, -3.42838209e-01,  4.96493816e-02],\n",
       "       [-5.53638586e-01,  5.10500275e-01, -8.06088489e-02,\n",
       "         7.82579961e-01, -5.24591989e-01, -5.53921694e-01,\n",
       "        -6.15032391e-01,  1.57409000e-01,  8.97429210e-01,\n",
       "         3.37884851e-01,  5.16977885e-01, -6.94165428e-01,\n",
       "        -6.64565393e-01, -1.12471959e+00,  3.71860864e-02],\n",
       "       [ 3.31835478e-01,  3.74171946e-01, -5.48683347e-01,\n",
       "         4.24972585e-02,  3.43857882e-01,  3.34266741e-01,\n",
       "         3.34103839e-01, -3.13561660e-01,  2.54174312e-01,\n",
       "        -4.10772521e-01,  5.82706641e-02,  5.43611226e-02,\n",
       "        -4.42494181e-01,  2.20545695e-01, -2.11298414e-02],\n",
       "       [-5.86277217e-01, -5.17253098e-01, -6.35236326e-01,\n",
       "        -5.77759787e-01, -6.00942107e-01, -5.84410003e-01,\n",
       "        -5.53634147e-01, -7.67448994e-01, -7.31453278e-01,\n",
       "        -7.79017677e-01, -9.47249998e-01,  3.31617185e-01,\n",
       "        -1.56113435e-01,  1.50088245e-01, -1.84217528e-02],\n",
       "       [-1.64405302e-01, -9.98767124e-02, -1.30497316e+00,\n",
       "        -2.05716938e-01, -1.66336284e-01, -1.59625423e-01,\n",
       "        -1.53130412e-01, -1.14867415e+00, -2.05241599e-01,\n",
       "        -1.11918813e+00, -6.18617945e-01,  2.85361938e-01,\n",
       "        -9.21839846e-01,  2.94605985e-02, -2.24109058e-03],\n",
       "       [-2.49006665e-01, -2.95059541e-01, -7.65077024e-01,\n",
       "        -4.68633342e-01, -2.57187269e-01, -2.21930577e-01,\n",
       "        -2.16623191e-01, -7.74001000e-01, -5.16640447e-01,\n",
       "        -8.23735445e-01, -7.48227774e-01,  3.61675879e-01,\n",
       "        -3.13220747e-01,  2.80098069e-01, -4.62518779e-03],\n",
       "       [-6.69595079e-01,  1.55842508e-01,  3.85617183e-01,\n",
       "        -1.99107315e-01, -6.57214396e-01, -6.85669132e-01,\n",
       "        -6.69156481e-01,  4.02892937e-01, -5.24168082e-02,\n",
       "         1.94572811e-01, -2.21948645e-01, -3.10138048e-01,\n",
       "         3.69482916e-01, -1.09083124e-01, -5.53075659e-02],\n",
       "       [-8.72901685e-01, -4.25487993e-01, -7.51456181e-01,\n",
       "        -5.96833303e-01, -8.89843818e-01, -8.79517601e-01,\n",
       "        -8.47334670e-01, -8.22889199e-01, -6.87180059e-01,\n",
       "        -8.79761268e-01, -1.07363380e+00,  2.14608864e-01,\n",
       "        -2.72207149e-01,  1.69922373e-02, -2.09644058e-02],\n",
       "       [ 8.27217113e-01, -2.29747364e-01,  1.12586865e-01,\n",
       "        -3.05338468e-01,  8.01195895e-01,  8.23799944e-01,\n",
       "         8.59411542e-01, -6.55102331e-03, -3.50456717e-01,\n",
       "        -6.36804068e-02,  3.61546202e-02,  4.16414899e-01,\n",
       "         3.51404971e-01,  7.75225119e-01, -6.19987140e-02],\n",
       "       [-3.38895066e-01,  7.49252677e-02, -7.19622138e-01,\n",
       "         2.46934854e-01, -3.24415471e-01, -3.54810626e-01,\n",
       "        -3.53204353e-01, -5.53913013e-01,  2.36114129e-01,\n",
       "        -4.15082888e-01, -9.77957731e-02, -1.56002788e-01,\n",
       "        -7.93081445e-01, -5.56890467e-01,  3.13332083e-02]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand_forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.222498</td>\n",
       "      <td>0.026651</td>\n",
       "      <td>-0.020228</td>\n",
       "      <td>-0.023802</td>\n",
       "      <td>0.220831</td>\n",
       "      <td>0.218094</td>\n",
       "      <td>0.227956</td>\n",
       "      <td>0.004694</td>\n",
       "      <td>0.015377</td>\n",
       "      <td>-0.005848</td>\n",
       "      <td>0.106022</td>\n",
       "      <td>-0.051491</td>\n",
       "      <td>-0.043015</td>\n",
       "      <td>0.093676</td>\n",
       "      <td>-0.089036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.047978</td>\n",
       "      <td>-0.069585</td>\n",
       "      <td>-0.243829</td>\n",
       "      <td>-0.442537</td>\n",
       "      <td>-0.047869</td>\n",
       "      <td>-0.069572</td>\n",
       "      <td>0.060613</td>\n",
       "      <td>-0.231682</td>\n",
       "      <td>-0.379340</td>\n",
       "      <td>-0.380674</td>\n",
       "      <td>-0.447863</td>\n",
       "      <td>0.207964</td>\n",
       "      <td>0.104437</td>\n",
       "      <td>0.521465</td>\n",
       "      <td>-0.049208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.484183</td>\n",
       "      <td>-0.173668</td>\n",
       "      <td>-0.163967</td>\n",
       "      <td>0.154506</td>\n",
       "      <td>0.486681</td>\n",
       "      <td>0.451990</td>\n",
       "      <td>0.460801</td>\n",
       "      <td>-0.187892</td>\n",
       "      <td>0.063453</td>\n",
       "      <td>-0.050222</td>\n",
       "      <td>0.251805</td>\n",
       "      <td>0.100031</td>\n",
       "      <td>-0.287308</td>\n",
       "      <td>-0.091325</td>\n",
       "      <td>-0.084618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.114780</td>\n",
       "      <td>-0.182276</td>\n",
       "      <td>0.248371</td>\n",
       "      <td>0.436317</td>\n",
       "      <td>0.112823</td>\n",
       "      <td>0.149558</td>\n",
       "      <td>-0.018894</td>\n",
       "      <td>0.190639</td>\n",
       "      <td>0.288022</td>\n",
       "      <td>0.413627</td>\n",
       "      <td>0.509830</td>\n",
       "      <td>-0.310167</td>\n",
       "      <td>-0.217228</td>\n",
       "      <td>-0.768337</td>\n",
       "      <td>-0.071875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.319761</td>\n",
       "      <td>0.187043</td>\n",
       "      <td>0.100741</td>\n",
       "      <td>0.134221</td>\n",
       "      <td>-0.313431</td>\n",
       "      <td>-0.287685</td>\n",
       "      <td>-0.401649</td>\n",
       "      <td>0.165092</td>\n",
       "      <td>0.228809</td>\n",
       "      <td>0.157413</td>\n",
       "      <td>0.138013</td>\n",
       "      <td>-0.447666</td>\n",
       "      <td>-0.116646</td>\n",
       "      <td>-0.431286</td>\n",
       "      <td>-0.091987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.128517</td>\n",
       "      <td>0.183409</td>\n",
       "      <td>-0.694249</td>\n",
       "      <td>-0.248165</td>\n",
       "      <td>-0.121087</td>\n",
       "      <td>-0.207783</td>\n",
       "      <td>-0.078503</td>\n",
       "      <td>-0.572376</td>\n",
       "      <td>-0.084523</td>\n",
       "      <td>-0.666072</td>\n",
       "      <td>-0.383446</td>\n",
       "      <td>0.041262</td>\n",
       "      <td>-0.455453</td>\n",
       "      <td>0.258030</td>\n",
       "      <td>-0.145884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.758570</td>\n",
       "      <td>0.391676</td>\n",
       "      <td>0.466075</td>\n",
       "      <td>0.117219</td>\n",
       "      <td>0.763298</td>\n",
       "      <td>0.799139</td>\n",
       "      <td>0.760076</td>\n",
       "      <td>0.574178</td>\n",
       "      <td>0.318559</td>\n",
       "      <td>0.457020</td>\n",
       "      <td>0.627897</td>\n",
       "      <td>-0.191317</td>\n",
       "      <td>0.331826</td>\n",
       "      <td>0.441447</td>\n",
       "      <td>-0.084956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.008429</td>\n",
       "      <td>0.106267</td>\n",
       "      <td>0.686839</td>\n",
       "      <td>0.350751</td>\n",
       "      <td>-0.003474</td>\n",
       "      <td>0.097938</td>\n",
       "      <td>-0.123396</td>\n",
       "      <td>0.676049</td>\n",
       "      <td>0.357576</td>\n",
       "      <td>0.732347</td>\n",
       "      <td>0.579491</td>\n",
       "      <td>-0.514761</td>\n",
       "      <td>0.240812</td>\n",
       "      <td>-0.544983</td>\n",
       "      <td>-0.034208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.616201</td>\n",
       "      <td>0.475870</td>\n",
       "      <td>0.302482</td>\n",
       "      <td>0.666981</td>\n",
       "      <td>1.612732</td>\n",
       "      <td>1.608689</td>\n",
       "      <td>1.472922</td>\n",
       "      <td>0.466116</td>\n",
       "      <td>0.816237</td>\n",
       "      <td>0.536796</td>\n",
       "      <td>1.369351</td>\n",
       "      <td>-0.211394</td>\n",
       "      <td>-0.236602</td>\n",
       "      <td>0.107902</td>\n",
       "      <td>-0.140873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.168761</td>\n",
       "      <td>0.233615</td>\n",
       "      <td>0.629712</td>\n",
       "      <td>0.216650</td>\n",
       "      <td>1.170552</td>\n",
       "      <td>1.186075</td>\n",
       "      <td>1.188718</td>\n",
       "      <td>0.656553</td>\n",
       "      <td>0.307273</td>\n",
       "      <td>0.604038</td>\n",
       "      <td>0.815859</td>\n",
       "      <td>0.037632</td>\n",
       "      <td>0.460330</td>\n",
       "      <td>0.569953</td>\n",
       "      <td>-0.050360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.519026</td>\n",
       "      <td>-0.287827</td>\n",
       "      <td>-0.003482</td>\n",
       "      <td>-0.371331</td>\n",
       "      <td>-0.523838</td>\n",
       "      <td>-0.507908</td>\n",
       "      <td>-0.452063</td>\n",
       "      <td>-0.126913</td>\n",
       "      <td>-0.437358</td>\n",
       "      <td>-0.174684</td>\n",
       "      <td>-0.518679</td>\n",
       "      <td>0.080483</td>\n",
       "      <td>0.227694</td>\n",
       "      <td>0.068528</td>\n",
       "      <td>-0.024860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.056931</td>\n",
       "      <td>0.005412</td>\n",
       "      <td>-0.131791</td>\n",
       "      <td>-0.212391</td>\n",
       "      <td>-0.055058</td>\n",
       "      <td>-0.061859</td>\n",
       "      <td>-0.009921</td>\n",
       "      <td>-0.097232</td>\n",
       "      <td>-0.146953</td>\n",
       "      <td>-0.199287</td>\n",
       "      <td>-0.212502</td>\n",
       "      <td>0.059525</td>\n",
       "      <td>0.018630</td>\n",
       "      <td>0.226834</td>\n",
       "      <td>-0.035123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.649679</td>\n",
       "      <td>-0.823054</td>\n",
       "      <td>-0.354059</td>\n",
       "      <td>-0.612014</td>\n",
       "      <td>0.607281</td>\n",
       "      <td>0.622676</td>\n",
       "      <td>0.871414</td>\n",
       "      <td>-0.685169</td>\n",
       "      <td>-0.915695</td>\n",
       "      <td>-0.572001</td>\n",
       "      <td>-0.537999</td>\n",
       "      <td>0.906811</td>\n",
       "      <td>0.187810</td>\n",
       "      <td>0.992458</td>\n",
       "      <td>-0.065009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.342838</td>\n",
       "      <td>0.512827</td>\n",
       "      <td>1.040145</td>\n",
       "      <td>0.113460</td>\n",
       "      <td>0.363349</td>\n",
       "      <td>0.388380</td>\n",
       "      <td>0.331504</td>\n",
       "      <td>1.119734</td>\n",
       "      <td>0.351922</td>\n",
       "      <td>0.877085</td>\n",
       "      <td>0.635833</td>\n",
       "      <td>-0.399226</td>\n",
       "      <td>0.873099</td>\n",
       "      <td>0.340886</td>\n",
       "      <td>-0.015959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.612656</td>\n",
       "      <td>0.455629</td>\n",
       "      <td>0.933658</td>\n",
       "      <td>0.557557</td>\n",
       "      <td>1.617679</td>\n",
       "      <td>1.623548</td>\n",
       "      <td>1.564209</td>\n",
       "      <td>0.990924</td>\n",
       "      <td>0.668361</td>\n",
       "      <td>1.002048</td>\n",
       "      <td>1.379607</td>\n",
       "      <td>-0.113641</td>\n",
       "      <td>0.522132</td>\n",
       "      <td>0.487391</td>\n",
       "      <td>-0.016245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.499405</td>\n",
       "      <td>-0.305912</td>\n",
       "      <td>-0.383790</td>\n",
       "      <td>-0.095957</td>\n",
       "      <td>-0.504309</td>\n",
       "      <td>-0.504900</td>\n",
       "      <td>-0.507280</td>\n",
       "      <td>-0.449498</td>\n",
       "      <td>-0.230537</td>\n",
       "      <td>-0.345121</td>\n",
       "      <td>-0.415940</td>\n",
       "      <td>0.077237</td>\n",
       "      <td>-0.306910</td>\n",
       "      <td>-0.344275</td>\n",
       "      <td>0.015002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.866187</td>\n",
       "      <td>0.280697</td>\n",
       "      <td>-0.269692</td>\n",
       "      <td>0.200837</td>\n",
       "      <td>-0.859839</td>\n",
       "      <td>-0.866196</td>\n",
       "      <td>-0.982259</td>\n",
       "      <td>-0.131383</td>\n",
       "      <td>0.294497</td>\n",
       "      <td>-0.112085</td>\n",
       "      <td>-0.140651</td>\n",
       "      <td>-0.468141</td>\n",
       "      <td>-0.463659</td>\n",
       "      <td>-0.804018</td>\n",
       "      <td>0.029877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.241604</td>\n",
       "      <td>-0.242576</td>\n",
       "      <td>-0.070457</td>\n",
       "      <td>-0.473906</td>\n",
       "      <td>-0.241532</td>\n",
       "      <td>-0.241333</td>\n",
       "      <td>-0.126317</td>\n",
       "      <td>-0.139290</td>\n",
       "      <td>-0.486515</td>\n",
       "      <td>-0.268759</td>\n",
       "      <td>-0.540163</td>\n",
       "      <td>0.263791</td>\n",
       "      <td>0.293587</td>\n",
       "      <td>0.452194</td>\n",
       "      <td>-0.002948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.346219</td>\n",
       "      <td>0.068259</td>\n",
       "      <td>-0.840740</td>\n",
       "      <td>-0.440100</td>\n",
       "      <td>-1.333126</td>\n",
       "      <td>-1.353229</td>\n",
       "      <td>-1.336129</td>\n",
       "      <td>-0.698830</td>\n",
       "      <td>-0.308021</td>\n",
       "      <td>-0.852321</td>\n",
       "      <td>-1.014190</td>\n",
       "      <td>-0.183240</td>\n",
       "      <td>-0.525069</td>\n",
       "      <td>-0.344625</td>\n",
       "      <td>-0.014947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-1.063340</td>\n",
       "      <td>-0.343099</td>\n",
       "      <td>-0.355003</td>\n",
       "      <td>-0.973686</td>\n",
       "      <td>-1.068302</td>\n",
       "      <td>-1.062310</td>\n",
       "      <td>-0.945795</td>\n",
       "      <td>-0.416690</td>\n",
       "      <td>-0.935758</td>\n",
       "      <td>-0.736945</td>\n",
       "      <td>-1.265194</td>\n",
       "      <td>0.184625</td>\n",
       "      <td>0.283217</td>\n",
       "      <td>0.417219</td>\n",
       "      <td>-0.060120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.918605</td>\n",
       "      <td>-0.248255</td>\n",
       "      <td>-0.842711</td>\n",
       "      <td>-0.133126</td>\n",
       "      <td>-0.920558</td>\n",
       "      <td>-0.929093</td>\n",
       "      <td>-0.944997</td>\n",
       "      <td>-0.814339</td>\n",
       "      <td>-0.189491</td>\n",
       "      <td>-0.665025</td>\n",
       "      <td>-0.653945</td>\n",
       "      <td>-0.147472</td>\n",
       "      <td>-0.737627</td>\n",
       "      <td>-0.682613</td>\n",
       "      <td>-0.053311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.524263</td>\n",
       "      <td>-0.179590</td>\n",
       "      <td>0.192834</td>\n",
       "      <td>-0.191067</td>\n",
       "      <td>0.516256</td>\n",
       "      <td>0.527048</td>\n",
       "      <td>0.563098</td>\n",
       "      <td>0.135002</td>\n",
       "      <td>-0.208073</td>\n",
       "      <td>0.073045</td>\n",
       "      <td>0.101829</td>\n",
       "      <td>0.130003</td>\n",
       "      <td>0.257340</td>\n",
       "      <td>0.420800</td>\n",
       "      <td>-0.107996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.653257</td>\n",
       "      <td>-0.056535</td>\n",
       "      <td>-0.376798</td>\n",
       "      <td>-0.498701</td>\n",
       "      <td>-0.647775</td>\n",
       "      <td>-0.656521</td>\n",
       "      <td>-0.619021</td>\n",
       "      <td>-0.336032</td>\n",
       "      <td>-0.416676</td>\n",
       "      <td>-0.515947</td>\n",
       "      <td>-0.674473</td>\n",
       "      <td>-0.063056</td>\n",
       "      <td>-0.078940</td>\n",
       "      <td>0.079362</td>\n",
       "      <td>-0.091724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.402913</td>\n",
       "      <td>-0.016337</td>\n",
       "      <td>-0.322805</td>\n",
       "      <td>0.267244</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.388352</td>\n",
       "      <td>0.371266</td>\n",
       "      <td>-0.273934</td>\n",
       "      <td>0.239183</td>\n",
       "      <td>-0.083383</td>\n",
       "      <td>0.300017</td>\n",
       "      <td>-0.066966</td>\n",
       "      <td>-0.492353</td>\n",
       "      <td>-0.231322</td>\n",
       "      <td>-0.091405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.688051</td>\n",
       "      <td>0.721713</td>\n",
       "      <td>0.394136</td>\n",
       "      <td>0.389866</td>\n",
       "      <td>1.715673</td>\n",
       "      <td>1.683822</td>\n",
       "      <td>1.695081</td>\n",
       "      <td>0.616617</td>\n",
       "      <td>0.635144</td>\n",
       "      <td>0.525619</td>\n",
       "      <td>1.157405</td>\n",
       "      <td>-0.039832</td>\n",
       "      <td>0.151079</td>\n",
       "      <td>0.820638</td>\n",
       "      <td>-0.071096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.850103</td>\n",
       "      <td>-0.195912</td>\n",
       "      <td>0.705249</td>\n",
       "      <td>0.181220</td>\n",
       "      <td>0.829413</td>\n",
       "      <td>0.861443</td>\n",
       "      <td>0.855485</td>\n",
       "      <td>0.531126</td>\n",
       "      <td>0.064164</td>\n",
       "      <td>0.632922</td>\n",
       "      <td>0.626368</td>\n",
       "      <td>0.050956</td>\n",
       "      <td>0.460464</td>\n",
       "      <td>0.229564</td>\n",
       "      <td>-0.104928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.720554</td>\n",
       "      <td>0.757398</td>\n",
       "      <td>0.932164</td>\n",
       "      <td>0.163537</td>\n",
       "      <td>1.754447</td>\n",
       "      <td>1.729405</td>\n",
       "      <td>1.765825</td>\n",
       "      <td>1.125899</td>\n",
       "      <td>0.488733</td>\n",
       "      <td>0.790419</td>\n",
       "      <td>1.116657</td>\n",
       "      <td>0.049658</td>\n",
       "      <td>0.770981</td>\n",
       "      <td>1.223267</td>\n",
       "      <td>-0.054744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.126595</td>\n",
       "      <td>-0.529197</td>\n",
       "      <td>-0.236792</td>\n",
       "      <td>-0.283750</td>\n",
       "      <td>0.091606</td>\n",
       "      <td>0.119435</td>\n",
       "      <td>0.167496</td>\n",
       "      <td>-0.415439</td>\n",
       "      <td>-0.486553</td>\n",
       "      <td>-0.318385</td>\n",
       "      <td>-0.323085</td>\n",
       "      <td>0.316138</td>\n",
       "      <td>-0.003686</td>\n",
       "      <td>0.226179</td>\n",
       "      <td>-0.036960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.175597</td>\n",
       "      <td>0.150174</td>\n",
       "      <td>-0.060590</td>\n",
       "      <td>-0.258009</td>\n",
       "      <td>1.172579</td>\n",
       "      <td>1.165157</td>\n",
       "      <td>1.260320</td>\n",
       "      <td>0.011218</td>\n",
       "      <td>-0.117548</td>\n",
       "      <td>-0.171512</td>\n",
       "      <td>0.193465</td>\n",
       "      <td>0.455106</td>\n",
       "      <td>0.245140</td>\n",
       "      <td>1.149615</td>\n",
       "      <td>-0.014543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.905903</td>\n",
       "      <td>0.160658</td>\n",
       "      <td>0.495769</td>\n",
       "      <td>0.512335</td>\n",
       "      <td>0.905161</td>\n",
       "      <td>0.907351</td>\n",
       "      <td>0.865650</td>\n",
       "      <td>0.485084</td>\n",
       "      <td>0.465427</td>\n",
       "      <td>0.631626</td>\n",
       "      <td>0.873733</td>\n",
       "      <td>-0.049692</td>\n",
       "      <td>0.115346</td>\n",
       "      <td>-0.006387</td>\n",
       "      <td>0.008125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.833213</td>\n",
       "      <td>-0.220844</td>\n",
       "      <td>-1.104078</td>\n",
       "      <td>-0.206121</td>\n",
       "      <td>-0.837056</td>\n",
       "      <td>-0.846100</td>\n",
       "      <td>-0.835653</td>\n",
       "      <td>-1.036287</td>\n",
       "      <td>-0.279503</td>\n",
       "      <td>-0.959051</td>\n",
       "      <td>-0.806192</td>\n",
       "      <td>0.111316</td>\n",
       "      <td>-0.811356</td>\n",
       "      <td>-0.382809</td>\n",
       "      <td>0.055024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.456105</td>\n",
       "      <td>-0.071078</td>\n",
       "      <td>-0.498670</td>\n",
       "      <td>-1.000870</td>\n",
       "      <td>-0.456102</td>\n",
       "      <td>-0.455408</td>\n",
       "      <td>-0.334569</td>\n",
       "      <td>-0.457017</td>\n",
       "      <td>-0.797047</td>\n",
       "      <td>-0.886279</td>\n",
       "      <td>-1.108359</td>\n",
       "      <td>0.427485</td>\n",
       "      <td>0.299816</td>\n",
       "      <td>0.992283</td>\n",
       "      <td>0.001685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.592986</td>\n",
       "      <td>0.486893</td>\n",
       "      <td>0.049704</td>\n",
       "      <td>-0.242113</td>\n",
       "      <td>-0.567896</td>\n",
       "      <td>-0.597271</td>\n",
       "      <td>-0.575560</td>\n",
       "      <td>0.240918</td>\n",
       "      <td>0.092197</td>\n",
       "      <td>-0.079533</td>\n",
       "      <td>-0.306219</td>\n",
       "      <td>-0.216090</td>\n",
       "      <td>0.206109</td>\n",
       "      <td>0.153156</td>\n",
       "      <td>0.025654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.223153</td>\n",
       "      <td>-0.142935</td>\n",
       "      <td>0.492618</td>\n",
       "      <td>0.097181</td>\n",
       "      <td>0.214313</td>\n",
       "      <td>0.216646</td>\n",
       "      <td>0.219096</td>\n",
       "      <td>0.358953</td>\n",
       "      <td>-0.010594</td>\n",
       "      <td>0.426370</td>\n",
       "      <td>0.260041</td>\n",
       "      <td>0.011126</td>\n",
       "      <td>0.365665</td>\n",
       "      <td>0.012013</td>\n",
       "      <td>0.003420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.462571</td>\n",
       "      <td>0.527589</td>\n",
       "      <td>0.087261</td>\n",
       "      <td>-0.776497</td>\n",
       "      <td>0.482760</td>\n",
       "      <td>0.464419</td>\n",
       "      <td>0.635095</td>\n",
       "      <td>0.287072</td>\n",
       "      <td>-0.300465</td>\n",
       "      <td>-0.306938</td>\n",
       "      <td>-0.377113</td>\n",
       "      <td>0.387805</td>\n",
       "      <td>0.742526</td>\n",
       "      <td>1.606918</td>\n",
       "      <td>0.007092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.816104</td>\n",
       "      <td>0.492542</td>\n",
       "      <td>0.330215</td>\n",
       "      <td>-0.175289</td>\n",
       "      <td>0.821377</td>\n",
       "      <td>0.815804</td>\n",
       "      <td>0.865040</td>\n",
       "      <td>0.475879</td>\n",
       "      <td>0.136230</td>\n",
       "      <td>0.167268</td>\n",
       "      <td>0.296100</td>\n",
       "      <td>0.180412</td>\n",
       "      <td>0.497223</td>\n",
       "      <td>0.939304</td>\n",
       "      <td>0.010815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-1.655933</td>\n",
       "      <td>-0.384314</td>\n",
       "      <td>-0.358334</td>\n",
       "      <td>-0.576991</td>\n",
       "      <td>-1.654381</td>\n",
       "      <td>-1.659980</td>\n",
       "      <td>-1.644714</td>\n",
       "      <td>-0.459530</td>\n",
       "      <td>-0.668369</td>\n",
       "      <td>-0.568115</td>\n",
       "      <td>-1.189767</td>\n",
       "      <td>-0.119276</td>\n",
       "      <td>-0.023287</td>\n",
       "      <td>-0.423439</td>\n",
       "      <td>0.001174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.759975</td>\n",
       "      <td>0.057703</td>\n",
       "      <td>0.729619</td>\n",
       "      <td>0.295340</td>\n",
       "      <td>0.760699</td>\n",
       "      <td>0.748373</td>\n",
       "      <td>0.753296</td>\n",
       "      <td>0.650932</td>\n",
       "      <td>0.268029</td>\n",
       "      <td>0.708457</td>\n",
       "      <td>0.721561</td>\n",
       "      <td>-0.047076</td>\n",
       "      <td>0.418725</td>\n",
       "      <td>0.141044</td>\n",
       "      <td>-0.041586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.249542</td>\n",
       "      <td>-0.462486</td>\n",
       "      <td>0.174838</td>\n",
       "      <td>0.421211</td>\n",
       "      <td>-0.245431</td>\n",
       "      <td>-0.256149</td>\n",
       "      <td>-0.286679</td>\n",
       "      <td>-0.033993</td>\n",
       "      <td>0.080882</td>\n",
       "      <td>0.353735</td>\n",
       "      <td>0.228908</td>\n",
       "      <td>-0.180100</td>\n",
       "      <td>-0.196808</td>\n",
       "      <td>-0.807709</td>\n",
       "      <td>-0.016516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-0.117774</td>\n",
       "      <td>0.572581</td>\n",
       "      <td>0.361774</td>\n",
       "      <td>0.436534</td>\n",
       "      <td>-0.112985</td>\n",
       "      <td>-0.131202</td>\n",
       "      <td>-0.162382</td>\n",
       "      <td>0.557641</td>\n",
       "      <td>0.675734</td>\n",
       "      <td>0.502330</td>\n",
       "      <td>0.527062</td>\n",
       "      <td>-0.523949</td>\n",
       "      <td>-0.032766</td>\n",
       "      <td>-0.413495</td>\n",
       "      <td>0.004957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-0.121749</td>\n",
       "      <td>0.360308</td>\n",
       "      <td>-0.387485</td>\n",
       "      <td>0.301369</td>\n",
       "      <td>-0.099979</td>\n",
       "      <td>-0.118969</td>\n",
       "      <td>-0.141251</td>\n",
       "      <td>-0.165152</td>\n",
       "      <td>0.442544</td>\n",
       "      <td>-0.138074</td>\n",
       "      <td>0.148074</td>\n",
       "      <td>-0.214300</td>\n",
       "      <td>-0.522090</td>\n",
       "      <td>-0.342838</td>\n",
       "      <td>0.049649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.553639</td>\n",
       "      <td>0.510500</td>\n",
       "      <td>-0.080609</td>\n",
       "      <td>0.782580</td>\n",
       "      <td>-0.524592</td>\n",
       "      <td>-0.553922</td>\n",
       "      <td>-0.615032</td>\n",
       "      <td>0.157409</td>\n",
       "      <td>0.897429</td>\n",
       "      <td>0.337885</td>\n",
       "      <td>0.516978</td>\n",
       "      <td>-0.694165</td>\n",
       "      <td>-0.664565</td>\n",
       "      <td>-1.124720</td>\n",
       "      <td>0.037186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.331835</td>\n",
       "      <td>0.374172</td>\n",
       "      <td>-0.548683</td>\n",
       "      <td>0.042497</td>\n",
       "      <td>0.343858</td>\n",
       "      <td>0.334267</td>\n",
       "      <td>0.334104</td>\n",
       "      <td>-0.313562</td>\n",
       "      <td>0.254174</td>\n",
       "      <td>-0.410773</td>\n",
       "      <td>0.058271</td>\n",
       "      <td>0.054361</td>\n",
       "      <td>-0.442494</td>\n",
       "      <td>0.220546</td>\n",
       "      <td>-0.021130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-0.586277</td>\n",
       "      <td>-0.517253</td>\n",
       "      <td>-0.635236</td>\n",
       "      <td>-0.577760</td>\n",
       "      <td>-0.600942</td>\n",
       "      <td>-0.584410</td>\n",
       "      <td>-0.553634</td>\n",
       "      <td>-0.767449</td>\n",
       "      <td>-0.731453</td>\n",
       "      <td>-0.779018</td>\n",
       "      <td>-0.947250</td>\n",
       "      <td>0.331617</td>\n",
       "      <td>-0.156113</td>\n",
       "      <td>0.150088</td>\n",
       "      <td>-0.018422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-0.164405</td>\n",
       "      <td>-0.099877</td>\n",
       "      <td>-1.304973</td>\n",
       "      <td>-0.205717</td>\n",
       "      <td>-0.166336</td>\n",
       "      <td>-0.159625</td>\n",
       "      <td>-0.153130</td>\n",
       "      <td>-1.148674</td>\n",
       "      <td>-0.205242</td>\n",
       "      <td>-1.119188</td>\n",
       "      <td>-0.618618</td>\n",
       "      <td>0.285362</td>\n",
       "      <td>-0.921840</td>\n",
       "      <td>0.029461</td>\n",
       "      <td>-0.002241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.249007</td>\n",
       "      <td>-0.295060</td>\n",
       "      <td>-0.765077</td>\n",
       "      <td>-0.468633</td>\n",
       "      <td>-0.257187</td>\n",
       "      <td>-0.221931</td>\n",
       "      <td>-0.216623</td>\n",
       "      <td>-0.774001</td>\n",
       "      <td>-0.516640</td>\n",
       "      <td>-0.823735</td>\n",
       "      <td>-0.748228</td>\n",
       "      <td>0.361676</td>\n",
       "      <td>-0.313221</td>\n",
       "      <td>0.280098</td>\n",
       "      <td>-0.004625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-0.669595</td>\n",
       "      <td>0.155843</td>\n",
       "      <td>0.385617</td>\n",
       "      <td>-0.199107</td>\n",
       "      <td>-0.657214</td>\n",
       "      <td>-0.685669</td>\n",
       "      <td>-0.669156</td>\n",
       "      <td>0.402893</td>\n",
       "      <td>-0.052417</td>\n",
       "      <td>0.194573</td>\n",
       "      <td>-0.221949</td>\n",
       "      <td>-0.310138</td>\n",
       "      <td>0.369483</td>\n",
       "      <td>-0.109083</td>\n",
       "      <td>-0.055308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.872902</td>\n",
       "      <td>-0.425488</td>\n",
       "      <td>-0.751456</td>\n",
       "      <td>-0.596833</td>\n",
       "      <td>-0.889844</td>\n",
       "      <td>-0.879518</td>\n",
       "      <td>-0.847335</td>\n",
       "      <td>-0.822889</td>\n",
       "      <td>-0.687180</td>\n",
       "      <td>-0.879761</td>\n",
       "      <td>-1.073634</td>\n",
       "      <td>0.214609</td>\n",
       "      <td>-0.272207</td>\n",
       "      <td>0.016992</td>\n",
       "      <td>-0.020964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.827217</td>\n",
       "      <td>-0.229747</td>\n",
       "      <td>0.112587</td>\n",
       "      <td>-0.305338</td>\n",
       "      <td>0.801196</td>\n",
       "      <td>0.823800</td>\n",
       "      <td>0.859412</td>\n",
       "      <td>-0.006551</td>\n",
       "      <td>-0.350457</td>\n",
       "      <td>-0.063680</td>\n",
       "      <td>0.036155</td>\n",
       "      <td>0.416415</td>\n",
       "      <td>0.351405</td>\n",
       "      <td>0.775225</td>\n",
       "      <td>-0.061999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-0.338895</td>\n",
       "      <td>0.074925</td>\n",
       "      <td>-0.719622</td>\n",
       "      <td>0.246935</td>\n",
       "      <td>-0.324415</td>\n",
       "      <td>-0.354811</td>\n",
       "      <td>-0.353204</td>\n",
       "      <td>-0.553913</td>\n",
       "      <td>0.236114</td>\n",
       "      <td>-0.415083</td>\n",
       "      <td>-0.097796</td>\n",
       "      <td>-0.156003</td>\n",
       "      <td>-0.793081</td>\n",
       "      <td>-0.556890</td>\n",
       "      <td>0.031333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   0.222498  0.026651 -0.020228 -0.023802  0.220831  0.218094  0.227956   \n",
       "1  -0.047978 -0.069585 -0.243829 -0.442537 -0.047869 -0.069572  0.060613   \n",
       "2   0.484183 -0.173668 -0.163967  0.154506  0.486681  0.451990  0.460801   \n",
       "3   0.114780 -0.182276  0.248371  0.436317  0.112823  0.149558 -0.018894   \n",
       "4  -0.319761  0.187043  0.100741  0.134221 -0.313431 -0.287685 -0.401649   \n",
       "5  -0.128517  0.183409 -0.694249 -0.248165 -0.121087 -0.207783 -0.078503   \n",
       "6   0.758570  0.391676  0.466075  0.117219  0.763298  0.799139  0.760076   \n",
       "7  -0.008429  0.106267  0.686839  0.350751 -0.003474  0.097938 -0.123396   \n",
       "8   1.616201  0.475870  0.302482  0.666981  1.612732  1.608689  1.472922   \n",
       "9   1.168761  0.233615  0.629712  0.216650  1.170552  1.186075  1.188718   \n",
       "10 -0.519026 -0.287827 -0.003482 -0.371331 -0.523838 -0.507908 -0.452063   \n",
       "11 -0.056931  0.005412 -0.131791 -0.212391 -0.055058 -0.061859 -0.009921   \n",
       "12  0.649679 -0.823054 -0.354059 -0.612014  0.607281  0.622676  0.871414   \n",
       "13  0.342838  0.512827  1.040145  0.113460  0.363349  0.388380  0.331504   \n",
       "14  1.612656  0.455629  0.933658  0.557557  1.617679  1.623548  1.564209   \n",
       "15 -0.499405 -0.305912 -0.383790 -0.095957 -0.504309 -0.504900 -0.507280   \n",
       "16 -0.866187  0.280697 -0.269692  0.200837 -0.859839 -0.866196 -0.982259   \n",
       "17 -0.241604 -0.242576 -0.070457 -0.473906 -0.241532 -0.241333 -0.126317   \n",
       "18 -1.346219  0.068259 -0.840740 -0.440100 -1.333126 -1.353229 -1.336129   \n",
       "19 -1.063340 -0.343099 -0.355003 -0.973686 -1.068302 -1.062310 -0.945795   \n",
       "20 -0.918605 -0.248255 -0.842711 -0.133126 -0.920558 -0.929093 -0.944997   \n",
       "21  0.524263 -0.179590  0.192834 -0.191067  0.516256  0.527048  0.563098   \n",
       "22 -0.653257 -0.056535 -0.376798 -0.498701 -0.647775 -0.656521 -0.619021   \n",
       "23  0.402913 -0.016337 -0.322805  0.267244  0.403226  0.388352  0.371266   \n",
       "24  1.688051  0.721713  0.394136  0.389866  1.715673  1.683822  1.695081   \n",
       "25  0.850103 -0.195912  0.705249  0.181220  0.829413  0.861443  0.855485   \n",
       "26  1.720554  0.757398  0.932164  0.163537  1.754447  1.729405  1.765825   \n",
       "27  0.126595 -0.529197 -0.236792 -0.283750  0.091606  0.119435  0.167496   \n",
       "28  1.175597  0.150174 -0.060590 -0.258009  1.172579  1.165157  1.260320   \n",
       "29  0.905903  0.160658  0.495769  0.512335  0.905161  0.907351  0.865650   \n",
       "30 -0.833213 -0.220844 -1.104078 -0.206121 -0.837056 -0.846100 -0.835653   \n",
       "31 -0.456105 -0.071078 -0.498670 -1.000870 -0.456102 -0.455408 -0.334569   \n",
       "32 -0.592986  0.486893  0.049704 -0.242113 -0.567896 -0.597271 -0.575560   \n",
       "33  0.223153 -0.142935  0.492618  0.097181  0.214313  0.216646  0.219096   \n",
       "34  0.462571  0.527589  0.087261 -0.776497  0.482760  0.464419  0.635095   \n",
       "35  0.816104  0.492542  0.330215 -0.175289  0.821377  0.815804  0.865040   \n",
       "36 -1.655933 -0.384314 -0.358334 -0.576991 -1.654381 -1.659980 -1.644714   \n",
       "37  0.759975  0.057703  0.729619  0.295340  0.760699  0.748373  0.753296   \n",
       "38 -0.249542 -0.462486  0.174838  0.421211 -0.245431 -0.256149 -0.286679   \n",
       "39 -0.117774  0.572581  0.361774  0.436534 -0.112985 -0.131202 -0.162382   \n",
       "40 -0.121749  0.360308 -0.387485  0.301369 -0.099979 -0.118969 -0.141251   \n",
       "41 -0.553639  0.510500 -0.080609  0.782580 -0.524592 -0.553922 -0.615032   \n",
       "42  0.331835  0.374172 -0.548683  0.042497  0.343858  0.334267  0.334104   \n",
       "43 -0.586277 -0.517253 -0.635236 -0.577760 -0.600942 -0.584410 -0.553634   \n",
       "44 -0.164405 -0.099877 -1.304973 -0.205717 -0.166336 -0.159625 -0.153130   \n",
       "45 -0.249007 -0.295060 -0.765077 -0.468633 -0.257187 -0.221931 -0.216623   \n",
       "46 -0.669595  0.155843  0.385617 -0.199107 -0.657214 -0.685669 -0.669156   \n",
       "47 -0.872902 -0.425488 -0.751456 -0.596833 -0.889844 -0.879518 -0.847335   \n",
       "48  0.827217 -0.229747  0.112587 -0.305338  0.801196  0.823800  0.859412   \n",
       "49 -0.338895  0.074925 -0.719622  0.246935 -0.324415 -0.354811 -0.353204   \n",
       "\n",
       "          7         8         9         10        11        12        13  \\\n",
       "0   0.004694  0.015377 -0.005848  0.106022 -0.051491 -0.043015  0.093676   \n",
       "1  -0.231682 -0.379340 -0.380674 -0.447863  0.207964  0.104437  0.521465   \n",
       "2  -0.187892  0.063453 -0.050222  0.251805  0.100031 -0.287308 -0.091325   \n",
       "3   0.190639  0.288022  0.413627  0.509830 -0.310167 -0.217228 -0.768337   \n",
       "4   0.165092  0.228809  0.157413  0.138013 -0.447666 -0.116646 -0.431286   \n",
       "5  -0.572376 -0.084523 -0.666072 -0.383446  0.041262 -0.455453  0.258030   \n",
       "6   0.574178  0.318559  0.457020  0.627897 -0.191317  0.331826  0.441447   \n",
       "7   0.676049  0.357576  0.732347  0.579491 -0.514761  0.240812 -0.544983   \n",
       "8   0.466116  0.816237  0.536796  1.369351 -0.211394 -0.236602  0.107902   \n",
       "9   0.656553  0.307273  0.604038  0.815859  0.037632  0.460330  0.569953   \n",
       "10 -0.126913 -0.437358 -0.174684 -0.518679  0.080483  0.227694  0.068528   \n",
       "11 -0.097232 -0.146953 -0.199287 -0.212502  0.059525  0.018630  0.226834   \n",
       "12 -0.685169 -0.915695 -0.572001 -0.537999  0.906811  0.187810  0.992458   \n",
       "13  1.119734  0.351922  0.877085  0.635833 -0.399226  0.873099  0.340886   \n",
       "14  0.990924  0.668361  1.002048  1.379607 -0.113641  0.522132  0.487391   \n",
       "15 -0.449498 -0.230537 -0.345121 -0.415940  0.077237 -0.306910 -0.344275   \n",
       "16 -0.131383  0.294497 -0.112085 -0.140651 -0.468141 -0.463659 -0.804018   \n",
       "17 -0.139290 -0.486515 -0.268759 -0.540163  0.263791  0.293587  0.452194   \n",
       "18 -0.698830 -0.308021 -0.852321 -1.014190 -0.183240 -0.525069 -0.344625   \n",
       "19 -0.416690 -0.935758 -0.736945 -1.265194  0.184625  0.283217  0.417219   \n",
       "20 -0.814339 -0.189491 -0.665025 -0.653945 -0.147472 -0.737627 -0.682613   \n",
       "21  0.135002 -0.208073  0.073045  0.101829  0.130003  0.257340  0.420800   \n",
       "22 -0.336032 -0.416676 -0.515947 -0.674473 -0.063056 -0.078940  0.079362   \n",
       "23 -0.273934  0.239183 -0.083383  0.300017 -0.066966 -0.492353 -0.231322   \n",
       "24  0.616617  0.635144  0.525619  1.157405 -0.039832  0.151079  0.820638   \n",
       "25  0.531126  0.064164  0.632922  0.626368  0.050956  0.460464  0.229564   \n",
       "26  1.125899  0.488733  0.790419  1.116657  0.049658  0.770981  1.223267   \n",
       "27 -0.415439 -0.486553 -0.318385 -0.323085  0.316138 -0.003686  0.226179   \n",
       "28  0.011218 -0.117548 -0.171512  0.193465  0.455106  0.245140  1.149615   \n",
       "29  0.485084  0.465427  0.631626  0.873733 -0.049692  0.115346 -0.006387   \n",
       "30 -1.036287 -0.279503 -0.959051 -0.806192  0.111316 -0.811356 -0.382809   \n",
       "31 -0.457017 -0.797047 -0.886279 -1.108359  0.427485  0.299816  0.992283   \n",
       "32  0.240918  0.092197 -0.079533 -0.306219 -0.216090  0.206109  0.153156   \n",
       "33  0.358953 -0.010594  0.426370  0.260041  0.011126  0.365665  0.012013   \n",
       "34  0.287072 -0.300465 -0.306938 -0.377113  0.387805  0.742526  1.606918   \n",
       "35  0.475879  0.136230  0.167268  0.296100  0.180412  0.497223  0.939304   \n",
       "36 -0.459530 -0.668369 -0.568115 -1.189767 -0.119276 -0.023287 -0.423439   \n",
       "37  0.650932  0.268029  0.708457  0.721561 -0.047076  0.418725  0.141044   \n",
       "38 -0.033993  0.080882  0.353735  0.228908 -0.180100 -0.196808 -0.807709   \n",
       "39  0.557641  0.675734  0.502330  0.527062 -0.523949 -0.032766 -0.413495   \n",
       "40 -0.165152  0.442544 -0.138074  0.148074 -0.214300 -0.522090 -0.342838   \n",
       "41  0.157409  0.897429  0.337885  0.516978 -0.694165 -0.664565 -1.124720   \n",
       "42 -0.313562  0.254174 -0.410773  0.058271  0.054361 -0.442494  0.220546   \n",
       "43 -0.767449 -0.731453 -0.779018 -0.947250  0.331617 -0.156113  0.150088   \n",
       "44 -1.148674 -0.205242 -1.119188 -0.618618  0.285362 -0.921840  0.029461   \n",
       "45 -0.774001 -0.516640 -0.823735 -0.748228  0.361676 -0.313221  0.280098   \n",
       "46  0.402893 -0.052417  0.194573 -0.221949 -0.310138  0.369483 -0.109083   \n",
       "47 -0.822889 -0.687180 -0.879761 -1.073634  0.214609 -0.272207  0.016992   \n",
       "48 -0.006551 -0.350457 -0.063680  0.036155  0.416415  0.351405  0.775225   \n",
       "49 -0.553913  0.236114 -0.415083 -0.097796 -0.156003 -0.793081 -0.556890   \n",
       "\n",
       "          14  \n",
       "0  -0.089036  \n",
       "1  -0.049208  \n",
       "2  -0.084618  \n",
       "3  -0.071875  \n",
       "4  -0.091987  \n",
       "5  -0.145884  \n",
       "6  -0.084956  \n",
       "7  -0.034208  \n",
       "8  -0.140873  \n",
       "9  -0.050360  \n",
       "10 -0.024860  \n",
       "11 -0.035123  \n",
       "12 -0.065009  \n",
       "13 -0.015959  \n",
       "14 -0.016245  \n",
       "15  0.015002  \n",
       "16  0.029877  \n",
       "17 -0.002948  \n",
       "18 -0.014947  \n",
       "19 -0.060120  \n",
       "20 -0.053311  \n",
       "21 -0.107996  \n",
       "22 -0.091724  \n",
       "23 -0.091405  \n",
       "24 -0.071096  \n",
       "25 -0.104928  \n",
       "26 -0.054744  \n",
       "27 -0.036960  \n",
       "28 -0.014543  \n",
       "29  0.008125  \n",
       "30  0.055024  \n",
       "31  0.001685  \n",
       "32  0.025654  \n",
       "33  0.003420  \n",
       "34  0.007092  \n",
       "35  0.010815  \n",
       "36  0.001174  \n",
       "37 -0.041586  \n",
       "38 -0.016516  \n",
       "39  0.004957  \n",
       "40  0.049649  \n",
       "41  0.037186  \n",
       "42 -0.021130  \n",
       "43 -0.018422  \n",
       "44 -0.002241  \n",
       "45 -0.004625  \n",
       "46 -0.055308  \n",
       "47 -0.020964  \n",
       "48 -0.061999  \n",
       "49  0.031333  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cand_forecasts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [59:02<00:00, 354.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BSSF:        Avg. OOS-R2 for Scenario 0, SNR 0.3, Corr. 0.2 and Betas 2 is: [47.32 49.03 48.8  48.77 48.74]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 0, SNR 0.3, Corr. 0.2 and Betas 2 is: [11.06 18.58 24.36 29.11 33.17 36.67 39.69 42.27 44.44 46.21]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 1, SNR 0.3, Corr. 0.2 and Betas 2 is: [39.99 41.63 42.43 42.78 42.77]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 1, SNR 0.3, Corr. 0.2 and Betas 2 is: [ 8.38 15.59 21.73 26.87 31.09 34.46 37.04 38.88 40.06 40.63]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 0, SNR 0.5, Corr. 0.2 and Betas 2 is: [55.07 58.84 58.41 58.75 58.56]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 0, SNR 0.5, Corr. 0.2 and Betas 2 is: [13.98 23.32 30.39 36.14 41.   45.17 48.76 51.81 54.35 56.4 ]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 1, SNR 0.5, Corr. 0.2 and Betas 2 is: [49.13 51.73 54.44 53.8  54.24]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 1, SNR 0.5, Corr. 0.2 and Betas 2 is: [10.7  19.9  27.73 34.3  39.7  44.03 47.37 49.79 51.38 52.22]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 0, SNR 0.3, Corr. 0.5 and Betas 2 is: [53.74 56.78 56.79 56.38 55.95]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 0, SNR 0.3, Corr. 0.5 and Betas 2 is: [25.51 32.05 36.02 39.17 41.83 44.06 45.87 47.24 48.15 48.58]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 1, SNR 0.3, Corr. 0.5 and Betas 2 is: [40.82 43.7  42.54 42.61 42.63]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 1, SNR 0.3, Corr. 0.5 and Betas 2 is: [11.32 20.13 26.81 31.71 35.16 37.46 38.85 39.6  39.9  39.93]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 0, SNR 0.5, Corr. 0.5 and Betas 2 is: [64.62 67.66 68.16 67.81 67.52]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 0, SNR 0.5, Corr. 0.5 and Betas 2 is: [31.82 40.3  45.45 49.51 52.92 55.8  58.14 59.95 61.2  61.88]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 1, SNR 0.5, Corr. 0.5 and Betas 2 is: [50.56 56.24 55.56 55.18 55.42]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 1, SNR 0.5, Corr. 0.5 and Betas 2 is: [14.57 25.97 34.68 41.16 45.8  48.99 51.05 52.28 52.94 53.26]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 0, SNR 0.3, Corr. 0.8 and Betas 2 is: [51.06 52.43 51.74 51.2  50.12]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 0, SNR 0.3, Corr. 0.8 and Betas 2 is: [37.63 38.93 40.19 41.46 42.66 43.74 44.68 45.45 46.05 46.46]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 1, SNR 0.3, Corr. 0.8 and Betas 2 is: [38.94 41.39 41.15 42.29 42.21]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 1, SNR 0.3, Corr. 0.8 and Betas 2 is: [16.16 27.3  34.46 38.57 40.48 40.89 40.42 39.58 38.76 38.2 ]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 0, SNR 0.5, Corr. 0.8 and Betas 2 is: [64.38 66.94 65.57 65.11 64.12]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 0, SNR 0.5, Corr. 0.8 and Betas 2 is: [48.87 50.94 52.64 54.28 55.82 57.22 58.45 59.51 60.37 61.02]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 1, SNR 0.5, Corr. 0.8 and Betas 2 is: [55.12 55.79 57.15 56.64 56.61]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 1, SNR 0.5, Corr. 0.8 and Betas 2 is: [20.56 35.   44.59 50.44 53.57 54.83 54.96 54.57 54.12 53.92]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 0, SNR 0.3, Corr. 0.2 and Betas 5 is: [-58.32 -50.28 -52.14 -52.17 -51.01]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 0, SNR 0.3, Corr. 0.2 and Betas 5 is: [ -4.79  -8.93 -12.7  -16.47 -20.57 -25.24 -30.69 -37.08 -44.54 -53.19]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 1, SNR 0.3, Corr. 0.2 and Betas 5 is: [-13.05  -7.97  -9.85  -9.51  -9.25]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 1, SNR 0.3, Corr. 0.2 and Betas 5 is: [ 0.85  1.2   1.2   0.91  0.38 -0.39 -1.41 -2.71 -4.33 -6.33]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 0, SNR 0.5, Corr. 0.2 and Betas 5 is: [-56.92 -48.55 -52.99 -53.6  -53.48]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 0, SNR 0.5, Corr. 0.2 and Betas 5 is: [ -3.32  -6.46  -9.42 -12.55 -16.23 -20.74 -26.36 -33.29 -41.72 -51.83]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 1, SNR 0.5, Corr. 0.2 and Betas 5 is: [11.64 10.17  7.82  8.03  6.8 ]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 1, SNR 0.5, Corr. 0.2 and Betas 5 is: [ 3.54  6.3   8.45 10.12 11.34 12.12 12.44 12.25 11.48 10.07]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 0, SNR 0.3, Corr. 0.5 and Betas 5 is: [-12.18 -18.02 -19.47 -19.9  -19.56]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 0, SNR 0.3, Corr. 0.5 and Betas 5 is: [ -4.65  -8.68 -11.55 -14.31 -17.52 -21.5  -26.45 -32.52 -39.83 -48.49]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 1, SNR 0.3, Corr. 0.5 and Betas 5 is: [23.7  22.24 20.04 19.82 19.5 ]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 1, SNR 0.3, Corr. 0.5 and Betas 5 is: [ 0.57  1.95  4.32  7.37 10.7  13.94 16.8  19.08 20.62 21.31]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 0, SNR 0.5, Corr. 0.5 and Betas 5 is: [-7.01 -9.05 -9.33 -8.66 -8.84]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 0, SNR 0.5, Corr. 0.5 and Betas 5 is: [  0.38  -1.96  -3.34  -4.75  -6.81  -9.89 -14.24 -20.05 -27.45 -36.59]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 1, SNR 0.5, Corr. 0.5 and Betas 5 is: [38.14 33.23 33.97 33.21 32.64]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 1, SNR 0.5, Corr. 0.5 and Betas 5 is: [ 2.2   5.01  8.82 13.37 18.22 22.9  27.07 30.48 32.94 34.32]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 0, SNR 0.3, Corr. 0.8 and Betas 5 is: [-92.66 -32.82 -29.55 -30.23 -32.53]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 0, SNR 0.3, Corr. 0.8 and Betas 5 is: [  3.68  -1.37  -6.49 -12.14 -18.43 -25.37 -32.97 -41.23 -50.12 -59.65]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 1, SNR 0.3, Corr. 0.8 and Betas 5 is: [12.98 14.28 16.09 14.97 14.3 ]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 1, SNR 0.3, Corr. 0.8 and Betas 5 is: [ 2.81  3.47  4.42  5.96  7.84  9.77 11.59 13.2  14.58 15.68]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 0, SNR 0.5, Corr. 0.8 and Betas 5 is: [-82.6  -16.54 -17.95 -19.57 -19.67]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 0, SNR 0.5, Corr. 0.8 and Betas 5 is: [ 17.24  12.7    7.78   2.18  -4.21 -11.41 -19.42 -28.23 -37.82 -48.2 ]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 1, SNR 0.5, Corr. 0.8 and Betas 5 is: [33.24 26.06 24.05 23.06 23.12]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 1, SNR 0.5, Corr. 0.8 and Betas 5 is: [ 6.01  7.83  9.49 11.77 14.45 17.25 19.95 22.46 24.73 26.73]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 0, SNR 0.3, Corr. 0.2 and Betas 8 is: [-5.1   9.73 11.19 10.33 10.23]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 0, SNR 0.3, Corr. 0.2 and Betas 8 is: [ 6.74 10.07 11.8  12.69 13.11 13.23 13.19 13.05 12.85 12.62]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 1, SNR 0.3, Corr. 0.2 and Betas 8 is: [-0.29  9.74  9.4  11.39 12.37]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 1, SNR 0.3, Corr. 0.2 and Betas 8 is: [ 9.87 15.07 17.65 18.66 18.68 18.02 16.88 15.37 13.57 11.52]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 0, SNR 0.5, Corr. 0.2 and Betas 8 is: [16.39 17.92 19.96 19.2  20.59]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 0, SNR 0.5, Corr. 0.2 and Betas 8 is: [10.88 16.39 19.43 21.15 22.08 22.5  22.58 22.41 22.05 21.53]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 1, SNR 0.5, Corr. 0.2 and Betas 8 is: [ 5.19 19.88 19.21 20.65 21.68]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 1, SNR 0.5, Corr. 0.2 and Betas 8 is: [15.3  23.57 27.92 29.92 30.42 29.91 28.68 26.9  24.68 22.1 ]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 0, SNR 0.3, Corr. 0.5 and Betas 8 is: [ 4.63 24.23 24.04 23.69 23.93]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 0, SNR 0.3, Corr. 0.5 and Betas 8 is: [14.19 17.82 20.06 21.9  23.58 25.17 26.72 28.22 29.69 31.13]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 1, SNR 0.3, Corr. 0.5 and Betas 8 is: [23.55 26.35 26.6  27.58 27.92]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 1, SNR 0.3, Corr. 0.5 and Betas 8 is: [17.1  22.82 25.94 28.21 30.06 31.61 32.91 33.97 34.79 35.35]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 0, SNR 0.5, Corr. 0.5 and Betas 8 is: [34.86 32.65 32.85 33.21 32.42]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 0, SNR 0.5, Corr. 0.5 and Betas 8 is: [21.28 25.85 28.33 30.23 31.91 33.48 34.97 36.42 37.81 39.16]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 1, SNR 0.5, Corr. 0.5 and Betas 8 is: [43.58 38.47 39.35 39.42 39.63]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 1, SNR 0.5, Corr. 0.5 and Betas 8 is: [24.13 31.82 35.67 38.3  40.33 41.96 43.27 44.27 44.97 45.37]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 0, SNR 0.3, Corr. 0.8 and Betas 8 is: [24.71 30.47 29.44 28.67 28.62]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 0, SNR 0.3, Corr. 0.8 and Betas 8 is: [21.36 24.11 26.45 28.67 30.81 32.86 34.83 36.68 38.42 40.03]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 1, SNR 0.3, Corr. 0.8 and Betas 8 is: [12.17 29.82 30.96 31.25 32.44]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 1, SNR 0.3, Corr. 0.8 and Betas 8 is: [29.56 33.28 34.36 35.1  35.72 36.3  36.87 37.44 38.   38.55]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 0, SNR 0.5, Corr. 0.8 and Betas 8 is: [34.95 40.17 40.18 39.24 38.81]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 0, SNR 0.5, Corr. 0.8 and Betas 8 is: [30.52 33.36 35.7  37.91 40.02 42.03 43.93 45.71 47.35 48.85]%\n",
      "BSSF:        Avg. OOS-R2 for Scenario 1, SNR 0.5, Corr. 0.8 and Betas 8 is: [13.5  42.31 42.58 42.52 43.55]%\n",
      "CSR:         Avg. OOS-R2 for Scenario 1, SNR 0.5, Corr. 0.8 and Betas 8 is: [40.22 45.03 46.17 46.81 47.28 47.7  48.08 48.44 48.79 49.13]%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###### MC-Parameter ######\n",
    "# Number of MC-Runs\n",
    "n_mc   =  1000\n",
    "n_core =  25\n",
    "\n",
    "# Set Parameter\n",
    "n_obs       =  250\n",
    "n_preds     =  10\n",
    "init        =  50\n",
    "mlags       =  0\n",
    "b_range     =  [2, 5, 8]\n",
    "bernoulli_p =  0.2\n",
    "corr_range  =  [0.2, 0.5, 0.8]\n",
    "scenario_range = [1, 2]\n",
    "snr_range   =  [0.3, 0.5]\n",
    "\n",
    "###### Parameter Subset Forecasts ######\n",
    "# Subset Lengths\n",
    "k_range_ssf = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] \n",
    "\n",
    "# Upper Bound for Subset-Sizes\n",
    "n_max = 10000  \n",
    "\n",
    "# Number of Subset-Forecasts\n",
    "if np.sum(k_range_ssf) == 0:\n",
    "    n_sub  =  0\n",
    "else:\n",
    "    n_sub  =  int(sum([min(n_models(n_preds, k), n_max) for k in k_range_ssf]))\n",
    "\n",
    "###### Parameter Compressed Regressions ######\n",
    "# Number of Components for Compressed Regression\n",
    "k_range_cr  =  [0] #[1, 2, 3, 4] \n",
    "\n",
    "# Number of runs for each random projection\n",
    "rep_range_cr  =  [0] #range(0, 60) \n",
    "\n",
    "# Number of Compressed-Regression-Forecasts\n",
    "if (np.sum(k_range_cr) == 0) or (len(rep_range_cr) == 0):\n",
    "    n_cr = 0\n",
    "else: \n",
    "    n_cr  =  len(k_range_cr) * len(rep_range_cr)\n",
    "\n",
    "# ###### Parameter Decision Tree ######\n",
    "# dt_range  =  range(0, 5) \n",
    "# \n",
    "# # Number of Decision Trees\n",
    "# n_dt  =  len(dt_range)\n",
    "\n",
    "###### Parameter LARS ######\n",
    "k_range_lars = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "###### Parameter Forward Stepwise Selection ######\n",
    "k_range_fss = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "###### Parameter peLasso ######\n",
    "n_alpha        = 200\n",
    "n_iter_peL     = 1000\n",
    "cv_splits_peL  = 5\n",
    "cv_repeats_peL = 1\n",
    "\n",
    "###### Parameter Average-Best ######\n",
    "k_range_avg_best = [1, 10, 25, 50, 100, 1023]\n",
    "\n",
    "###### Parameter BSSF ######\n",
    "bssf_alpha   =  2500\n",
    "bssf_timeout =  3.0\n",
    "k_range_bssf =  [1, 5, 10, 25, 50, 100, 250, 500, 750, 1023] \n",
    "n_bssf       =  len(k_range_bssf)\n",
    "bssf_method  =  \"qcbo\"\n",
    "\n",
    "######## Objects ########\n",
    "# Set up Matrices for Results\n",
    "cand_forecasts   = np.full((len(range(init, n_obs)), (n_sub + n_cr)), np.nan)  \n",
    "\n",
    "benchmark        = np.full( len(scenario_range) * len(snr_range) * len(corr_range) * len(b_range) * n_mc, np.nan)\n",
    "se_benchmark     = np.full( len(scenario_range) * len(snr_range) * len(corr_range) * len(b_range) * n_mc, np.nan)\n",
    "\n",
    "cf_weights       = np.full((len(scenario_range) * len(snr_range) * len(corr_range) * len(b_range) * n_mc, n_bssf, (n_sub + n_cr)), np.nan)\n",
    "bssf_forecast    = np.full((len(scenario_range) * len(snr_range) * len(corr_range) * len(b_range) * n_mc, n_bssf), np.nan)\n",
    "se_bssf_forecast = np.full((len(scenario_range) * len(snr_range) * len(corr_range) * len(b_range) * n_mc, n_bssf), np.nan)\n",
    "\n",
    "csr_forecast     = np.full((len(scenario_range) * len(snr_range) * len(corr_range) * len(b_range) * n_mc, len(k_range_ssf)), np.nan)\n",
    "se_csr_forecast  = np.full((len(scenario_range) * len(snr_range) * len(corr_range) * len(b_range) * n_mc, len(k_range_ssf)), np.nan)\n",
    "\n",
    "#lars_forecast    = np.full((len(scenario_range) * len(snr_range) * len(corr_range) * len(b_range) * n_mc, len(k_range_lars)), np.nan)\n",
    "#se_lars_forecast = np.full((len(scenario_range) * len(snr_range) * len(corr_range) * len(b_range) * n_mc, len(k_range_lars)), np.nan)\n",
    "\n",
    "#fss_forecast    = np.full((len(scenario_range) * len(snr_range) * len(corr_range) * len(b_range) * n_mc, len(k_range_fss)), np.nan)\n",
    "#se_fss_forecast = np.full((len(scenario_range) * len(snr_range) * len(corr_range) * len(b_range) * n_mc, len(k_range_fss)), np.nan)\n",
    "\n",
    "#pelasso_forecast    = np.full( len(scenario_range) * len(snr_range) * len(corr_range) * len(b_range) * n_mc, np.nan)\n",
    "#se_pelasso_forecast = np.full( len(scenario_range) * len(snr_range) * len(corr_range) * len(b_range) * n_mc, np.nan)\n",
    "\n",
    "#avg_best_forecast    = np.full((len(scenario_range) * len(snr_range) * len(corr_range) * len(b_range) * n_mc, len(k_range_avg_best)), np.nan)\n",
    "#se_avg_best_forecast = np.full((len(scenario_range) * len(snr_range) * len(corr_range) * len(b_range) * n_mc, len(k_range_avg_best)), np.nan)\n",
    "\n",
    "###### Start ######\n",
    "# Loop over Monte-Carlo Runs\n",
    "i = 0\n",
    "program_starts = time.time()\n",
    "for r in tqdm(range(n_mc)):\n",
    "    \n",
    "    # Loop over Covariance-Scenario\n",
    "    for scenario in scenario_range:\n",
    "        \n",
    "        # Loop over Signal-to-Noise-Ratio\n",
    "        for snr in snr_range:\n",
    "    \n",
    "            # Loop over Covariance-Sets\n",
    "            for rho in corr_range:\n",
    "        \n",
    "                # Loop over Coefficient-Sets\n",
    "                for b in b_range:\n",
    "    \n",
    "                    ### Simulate Data ###\n",
    "                    y, X, pred_names = sim_data(n_obs, n_preds, b, bernoulli_p, rho, scenario, snr, r)\n",
    "\n",
    "                    ### Create Candidate Models ###\n",
    "                    cand_forecasts = candidate_models(y, X, range(init, n_obs), k_range_ssf, k_range_cr, rep_range_cr, n_core)\n",
    "\n",
    "                    ### Benchmark: PHM ###\n",
    "                    benchmark[i]    = y[:-1].mean()\n",
    "                    se_benchmark[i] = (y[-1] - benchmark[i]) ** 2\n",
    "\n",
    "                    ### Benchmark: Complete Subset Regression ###\n",
    "                    tmp_ = np.cumsum([0] + [len(list(combinations(range(n_preds), k))) for k in k_range_ssf])\n",
    "                    csr_forecast[i]     =  [np.mean(cand_forecasts[-1, :n_sub][tmp_[i]:tmp_[i+1]]) for i in range(len(tmp_)-1)]\n",
    "                    se_csr_forecast[i]  =  (y[-1] - csr_forecast[i]) ** 2\n",
    "\n",
    "                    ### Benchmark: LARS ###\n",
    "                    #lars_forecast[i]    = lars(y[init:-1], cand_forecasts[:-1], cand_forecasts[[-1]], k_range_lars)\n",
    "                    #se_lars_forecast[i] = (y[-1] - lars_forecast[i]) ** 2\n",
    "\n",
    "                    ### Benchmark: Forward Stepwise Selection ###\n",
    "                    #fss_forecast[i]    = fss(y[init:-1], cand_forecasts[:-1], cand_forecasts[[-1]], k_range_fss, n_core)\n",
    "                    #se_fss_forecast[i] = (y[-1] - fss_forecast[i]) ** 2\n",
    "\n",
    "                    ### Benchmark: peLASSO ###\n",
    "                    #pelasso_forecast[i]    = peLASSO(y[init:-1], cand_forecasts[:-1], cand_forecasts[[-1]], n_alpha, n_iter_peL, cv_splits_peL, cv_repeats_peL)\n",
    "                    #se_pelasso_forecast[i] = (y[-1] - pelasso_forecast[i]) ** 2\n",
    "\n",
    "                    ### Benchmark: Average-Best ###\n",
    "                    #avg_best_forecast[i]    = avg_best(y[init:-1], cand_forecasts[:-1], cand_forecasts[[-1]], k_range_avg_best)\n",
    "                    #se_avg_best_forecast[i] = (y[-1] - avg_best_forecast[i]) ** 2\n",
    "\n",
    "                    ### Best Selection of Forecast ###\n",
    "                    bssf_forecast[i], cf_weights[i] = zip(*list(map(lambda s: bssf(y[init:-1], cand_forecasts[:-1], cand_forecasts[[-1]], bssf_alpha, s, bssf_timeout, bssf_method), k_range_bssf)))\n",
    "                    se_bssf_forecast[i] = (y[-1] - bssf_forecast[i]) ** 2\n",
    "\n",
    "                    # Update index   \n",
    "                    i += 1\n",
    "# Time                \n",
    "program_ends = time.time()\n",
    "         \n",
    "# # Candidate-Model-Names\n",
    "ssf_names = [f\"SSF{k}_\" + \"_\".join(map(str, sub)) for k in k_range_ssf for sub in combinations(range(n_preds), k)]\n",
    "cr_names  = [f\"CR{n_comp}_{r}\" for n_comp in k_range_cr for r in rep_range_cr]\n",
    "\n",
    "### Evaluation ###\n",
    "# Set up Lenghts\n",
    "seq_1 = n_mc * len(scenario_range) * len(snr_range) * len(corr_range) * len(b_range)\n",
    "seq_2 = n_mc * len(scenario_range) * len(snr_range) * len(corr_range)\n",
    "seq_3 = n_mc * len(scenario_range) * len(snr_range)\n",
    "seq_4 = n_mc * len(scenario_range)\n",
    "\n",
    "# Loop over all combinations\n",
    "for b in range(len(b_range)):\n",
    "    for rho in range(len(corr_range)):\n",
    "        for snr in range(len(snr_range)):\n",
    "            for scenario in range(len(scenario_range)):\n",
    "    \n",
    "                # Calculate Forecast Combination Method Performances    \n",
    "                se_bssf      =  se_bssf_forecast[np.arange(b, seq_1, len(b_range))][np.arange(rho, seq_2, len(corr_range))][np.arange(snr, seq_3, len(snr_range))][np.arange(scenario, seq_4, len(scenario_range))]\n",
    "                se_csr       =  se_csr_forecast[ np.arange(b, seq_1, len(b_range))][np.arange(rho, seq_2, len(corr_range))][np.arange(snr, seq_3, len(snr_range))][np.arange(scenario, seq_4, len(scenario_range))]\n",
    "                #se_lars      =  se_lars_forecast[np.arange(b, seq_1, len(b_range))][np.arange(rho, seq_3, len(corr_range))][np.arange(snr, seq_3, len(snr_range))][np.arange(scenario, seq_4, len(scenario_range))]\n",
    "                #se_fss       =  se_fss_forecast[np.arange(b, seq_1, len(b_range))][np.arange(rho, seq_2, len(corr_range))][np.arange(snr, seq_3, len(snr_range))][np.arange(scenario, seq_4, len(scenario_range))]\n",
    "                #se_pelasso   =  se_pelasso_forecast[np.arange(b, seq_1, len(b_range))][np.arange(rho, seq_2, len(corr_range))][np.arange(snr, seq_3, len(snr_range))][np.arange(scenario, seq_4, len(scenario_range))]\n",
    "                #se_avg_best  =  se_avg_best_forecast[np.arange(b, seq_1, len(b_range))][np.arange(rho, seq_2, len(corr_range))][np.arange(snr, seq_3, len(snr_range))][np.arange(scenario, seq_4, len(scenario_range))]\n",
    "        \n",
    "                # Calculate Benchmark Performance\n",
    "                se_phm  = se_benchmark[np.arange(b, seq_1, len(b_range))][np.arange(rho, seq_2, len(corr_range))][np.arange(snr, seq_3, len(snr_range))][np.arange(scenario, seq_4, len(scenario_range))]\n",
    "                \n",
    "                # Create Rows\n",
    "                new_row_bbsf = { \"n_mc\": n_mc, \"n_obs\": n_obs, \"n_preds\": n_preds, \"init\": init, \"mlags\": mlags, \"rho\": corr_range[rho], \"scenario\": scenario_range[scenario], \"bernoulli_p\": bernoulli_p, \"snr\": snr_range[snr], \"b\": b_range[b], \"k_range_ssf\": k_range_ssf, \"k_range_cr\": k_range_cr, \"rep_range_cr\": rep_range_cr, \"k_range_lars\": k_range_lars, \"k_range_fss\": k_range_fss, \"n_alpha\": n_alpha, \"n_iter_peL\": n_iter_peL, \"cv_splits_peL\": cv_splits_peL, \"cv_repeats_peL\": cv_repeats_peL, \"k_range_avg_best\": k_range_avg_best, \"bssf_alpha\": bssf_alpha, \"bssf_timeout\": bssf_timeout, \"bssf_range\": k_range_bssf, \"error\": 0, \"time\" : np.floor((program_ends - program_starts) / 60), \"type\": \"BSSF\",        \"OOS-R2\": np.array2string(100 * (1 - sum(se_bssf) / sum(se_phm)), formatter={'float_kind':'{0:.2f}'.format}).replace('[', '').replace(']', '')}\n",
    "                new_row_csr  = { \"n_mc\": n_mc, \"n_obs\": n_obs, \"n_preds\": n_preds, \"init\": init, \"mlags\": mlags, \"rho\": corr_range[rho], \"scenario\": scenario_range[scenario], \"bernoulli_p\": bernoulli_p, \"snr\": snr_range[snr], \"b\": b_range[b], \"k_range_ssf\": k_range_ssf, \"k_range_cr\": k_range_cr, \"rep_range_cr\": rep_range_cr, \"k_range_lars\": k_range_lars, \"k_range_fss\": k_range_fss, \"n_alpha\": n_alpha, \"n_iter_peL\": n_iter_peL, \"cv_splits_peL\": cv_splits_peL, \"cv_repeats_peL\": cv_repeats_peL, \"k_range_avg_best\": k_range_avg_best, \"bssf_alpha\": bssf_alpha, \"bssf_timeout\": bssf_timeout, \"bssf_range\": k_range_bssf, \"error\": 0, \"time\" : np.floor((program_ends - program_starts) / 60), \"type\": \"CSR\",         \"OOS-R2\": np.array2string(100 * (1 - sum(se_csr) / sum(se_phm)), formatter={'float_kind':'{0:.2f}'.format}).replace('[', '').replace(']', '')}\n",
    "                #new_row_lars = { \"n_mc\": n_mc, \"n_obs\": n_obs, \"n_preds\": n_preds, \"init\": init, \"mlags\": mlags, \"rho\": corr_range[rho], \"scenario\": scenario_range[scenario], \"bernoulli_p\": bernoulli_p, \"snr\": snr_range[snr], \"b\": b_range[b], \"k_range_ssf\": k_range_ssf, \"k_range_cr\": k_range_cr, \"rep_range_cr\": rep_range_cr, \"k_range_lars\": k_range_lars, \"k_range_fss\": k_range_fss, \"n_alpha\": n_alpha, \"n_iter_peL\": n_iter_peL, \"cv_splits_peL\": cv_splits_peL, \"cv_repeats_peL\": cv_repeats_peL, \"k_range_avg_best\": k_range_avg_best, \"bssf_alpha\": bssf_alpha, \"bssf_timeout\": bssf_timeout, \"bssf_range\": k_range_bssf, \"error\": 0, \"time\" : np.floor((program_ends - program_starts) / 60), \"type\": \"LARS\",       \"OOS-R2\": np.array2string(100 * (1 - sum(se_lars) / sum(se_phm)), formatter={'float_kind':'{0:.2f}'.format}).replace('[', '').replace(']', '')}\n",
    "                #new_row_fss  = { \"n_mc\": n_mc, \"n_obs\": n_obs, \"n_preds\": n_preds, \"init\": init, \"mlags\": mlags, \"rho\": corr_range[rho], \"scenario\": scenario_range[scenario], \"bernoulli_p\": bernoulli_p, \"snr\": snr_range[snr], \"b\": b_range[b], \"k_range_ssf\": k_range_ssf, \"k_range_cr\": k_range_cr, \"rep_range_cr\": rep_range_cr, \"k_range_lars\": k_range_lars, \"k_range_fss\": k_range_fss, \"n_alpha\": n_alpha, \"n_iter_peL\": n_iter_peL, \"cv_splits_peL\": cv_splits_peL, \"cv_repeats_peL\": cv_repeats_peL, \"k_range_avg_best\": k_range_avg_best, \"bssf_alpha\": bssf_alpha, \"bssf_timeout\": bssf_timeout, \"bssf_range\": k_range_bssf, \"error\": 0, \"time\" : np.floor((program_ends - program_starts) / 60), \"type\": \"FSS\",        \"OOS-R2\": np.array2string(100 * (1 - sum(se_fss) / sum(se_phm)), formatter={'float_kind':'{0:.2f}'.format}).replace('[', '').replace(']', '')}\n",
    "                #new_row_peL  = { \"n_mc\": n_mc, \"n_obs\": n_obs, \"n_preds\": n_preds, \"init\": init, \"mlags\": mlags, \"rho\": corr_range[rho], \"scenario\": scenario_range[scenario], \"bernoulli_p\": bernoulli_p, \"snr\": snr_range[snr], \"b\": b_range[b], \"k_range_ssf\": k_range_ssf, \"k_range_cr\": k_range_cr, \"rep_range_cr\": rep_range_cr, \"k_range_lars\": k_range_lars, \"k_range_fss\": k_range_fss, \"n_alpha\": n_alpha, \"n_iter_peL\": n_iter_peL, \"cv_splits_peL\": cv_splits_peL, \"cv_repeats_peL\": cv_repeats_peL, \"k_range_avg_best\": k_range_avg_best, \"bssf_alpha\": bssf_alpha, \"bssf_timeout\": bssf_timeout, \"bssf_range\": k_range_bssf, \"error\": 0, \"time\" : np.floor((program_ends - program_starts) / 60), \"type\": \"peLASSO\",    \"OOS-R2\": np.array2string(100 * (1 - sum(se_pelasso) / sum(se_phm)), formatter={'float_kind':'{0:.2f}'.format}).replace('[', '').replace(']', '')}\n",
    "                #new_row_avgB = { \"n_mc\": n_mc, \"n_obs\": n_obs, \"n_preds\": n_preds, \"init\": init, \"mlags\": mlags, \"rho\": corr_range[rho], \"scenario\": scenario_range[scenario], \"bernoulli_p\": bernoulli_p, \"snr\": snr_range[snr], \"b\": b_range[b], \"k_range_ssf\": k_range_ssf, \"k_range_cr\": k_range_cr, \"rep_range_cr\": rep_range_cr, \"k_range_lars\": k_range_lars, \"k_range_fss\": k_range_fss, \"n_alpha\": n_alpha, \"n_iter_peL\": n_iter_peL, \"cv_splits_peL\": cv_splits_peL, \"cv_repeats_peL\": cv_repeats_peL, \"k_range_avg_best\": k_range_avg_best, \"bssf_alpha\": bssf_alpha, \"bssf_timeout\": bssf_timeout, \"bssf_range\": k_range_bssf, \"error\": 0, \"time\" : np.floor((program_ends - program_starts) / 60), \"type\": \"Avg_Best_N\", \"OOS-R2\": np.array2string(100 * (1 - sum(se_avg_best) / sum(se_phm)), formatter={'float_kind':'{0:.2f}'.format}).replace('[', '').replace(']', '')}\n",
    "\n",
    "                # Add Rows\n",
    "                new_rows = pd.DataFrame.from_dict([new_row_bbsf,\n",
    "                                                   new_row_csr,\n",
    "                                                   #new_row_lars,\n",
    "                                                   #new_row_fss,\n",
    "                                                   #new_row_peL,\n",
    "                                                   #new_row_avgB\n",
    "                                                   ])\n",
    "                \n",
    "                # Add to CSV\n",
    "                output_path = path + \"/Results/my_csv.csv\"\n",
    "                new_rows.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n",
    "                \n",
    "                # Print Results\n",
    "                print(f\"BSSF:        Avg. OOS-R2 for Scenario {scenario}, SNR {snr_range[snr]}, Corr. {corr_range[rho]} and Betas {b_range[b]} is: \" + str(np.round(100 * (1 - sum(se_bssf) / sum(se_phm)), 2)) + \"%\")\n",
    "                print(f\"CSR:         Avg. OOS-R2 for Scenario {scenario}, SNR {snr_range[snr]}, Corr. {corr_range[rho]} and Betas {b_range[b]} is: \" + str(np.round(100 * (1 - sum(se_csr)  / sum(se_phm)), 2)) + \"%\")\n",
    "                #print(f\"LARS:       Avg. OOS-R2 for Scenario {scenario}, SNR {snr_range[snr]}, Corr. {corr_range[rho]} and Betas {b_range[b]} is: \" + str(np.round(100 * (1 - sum(se_lars) / sum(se_phm)), 2)) + \"%\")\n",
    "                #print(f\"FSS:        Avg. OOS-R2 for Scenario {scenario}, SNR {snr_range[snr]}, Corr. {corr_range[rho]} and Betas {b_range[b]} is: \" + str(np.round(100 * (1 - sum(se_fss)  / sum(se_phm)), 2)) + \"%\")\n",
    "                #print(f\"peLASSO:    Avg. OOS-R2 for Scenario {scenario}, SNR {snr_range[snr]}, Corr. {corr_range[rho]} and Betas {b_range[b]} is: \" + str(np.round(100 * (1 - sum(se_pelasso)  / sum(se_phm)), 2)) + \"%\")\n",
    "                #print(f\"Avg-Best N: Avg. OOS-R2 for Scenario {scenario}, SNR {snr_range[snr]}, Corr. {corr_range[rho]} and Betas {b_range[b]} is: \" + str(np.round(100 * (1 - sum(se_avg_best) / sum(se_phm)), 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### MC-Parameter ######\n",
    "# Number of MC-Runs\n",
    "n_mc   =  10\n",
    "n_core =  6\n",
    "\n",
    "# Set Parameter\n",
    "n_obs       =  250\n",
    "n_preds     =  8\n",
    "init        =  50\n",
    "mlags       =  0\n",
    "corr_range  =  [0.0, 0.5, 0.95]\n",
    "b_range     =  np.array([[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                         [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                         [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]])\n",
    "\n",
    "###### Parameter Subset Forecasts ######\n",
    "# Subset Lengths\n",
    "k_range = [1, 2, 3, 4, 5, 6, 7, 8] \n",
    "\n",
    "# Upper Bound for Subset-Sizes\n",
    "n_max = 10000  \n",
    "\n",
    "# Number of Subset-Forecasts\n",
    "if np.sum(k_range) == 0:\n",
    "    n_sub  =  0\n",
    "else:\n",
    "    n_sub  =  int(sum([min(n_models(n_preds, k), n_max) for k in k_range]))\n",
    "\n",
    "###### Parameter Compressed Regressions ######\n",
    "# Number of Components for Compressed Regression\n",
    "cr_range  =  [0] #[1, 2, 3, 4] \n",
    "\n",
    "# Number of runs for each random projection\n",
    "rep_range  =  [0] #range(0, 60) \n",
    "\n",
    "# Number of Compressed-Regression-Forecasts\n",
    "if (np.sum(cr_range) == 0) or (len(rep_range) == 0):\n",
    "    n_cr = 0\n",
    "else: \n",
    "    n_cr  =  len(cr_range) * len(rep_range)\n",
    "\n",
    "# ###### Parameter Decision Tree ######\n",
    "# dt_range  =  range(0, 5) \n",
    "# \n",
    "# # Number of Decision Trees\n",
    "# n_dt  =  len(dt_range)\n",
    "\n",
    "###### Parameter LARS ######\n",
    "n_range_lars = [1, 10, 25, 50, 100, 255]\n",
    "\n",
    "###### Parameter Forward Stepwise Selection ######\n",
    "n_range_fss = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "###### Parameter peLasso ######\n",
    "n_alpha        = 200\n",
    "n_iter_peL     = 1000\n",
    "cv_splits_peL  = 4\n",
    "cv_repeats_peL = 1\n",
    "\n",
    "###### Parameter Average-Best ######\n",
    "n_range_avg_best = [1, 10, 25, 50, 100, 255]\n",
    "\n",
    "###### Parameter BSSF ######\n",
    "alpha        =  12.5\n",
    "bssf_timeout =  1\n",
    "bssf_range   =  [1, 10, 25, 50, 100, 255] \n",
    "n_bssf       =  len(bssf_range)\n",
    "\n",
    "######## Objects ########\n",
    "# Set up Matrices for Results\n",
    "cand_forecasts   = np.full((len(range(init, n_obs)), (n_sub + n_cr)), np.nan)  \n",
    "\n",
    "benchmark        = np.full( len(corr_range) * len(b_range) * n_mc, np.nan)\n",
    "se_benchmark     = np.full( len(corr_range) * len(b_range) * n_mc, np.nan)\n",
    "\n",
    "cf_weights       = np.full((len(corr_range) * len(b_range) * n_mc, n_bssf, (n_sub + n_cr)), np.nan)\n",
    "bssf_forecast    = np.full((len(corr_range) * len(b_range) * n_mc, n_bssf), np.nan)\n",
    "se_bssf_forecast = np.full((len(corr_range) * len(b_range) * n_mc, n_bssf), np.nan)\n",
    "\n",
    "csr_forecast     = np.full((len(corr_range) * len(b_range) * n_mc, len(k_range)), np.nan)\n",
    "se_csr_forecast  = np.full((len(corr_range) * len(b_range) * n_mc, len(k_range)), np.nan)\n",
    "\n",
    "lars_forecast    = np.full((len(corr_range) * len(b_range) * n_mc, len(n_range_lars)), np.nan)\n",
    "se_lars_forecast = np.full((len(corr_range) * len(b_range) * n_mc, len(n_range_lars)), np.nan)\n",
    "\n",
    "fss_forecast    = np.full((len(corr_range) * len(b_range) * n_mc, len(n_range_fss)), np.nan)\n",
    "se_fss_forecast = np.full((len(corr_range) * len(b_range) * n_mc, len(n_range_fss)), np.nan)\n",
    "\n",
    "pelasso_forecast    = np.full( len(corr_range) * len(b_range) * n_mc, np.nan)\n",
    "se_pelasso_forecast = np.full( len(corr_range) * len(b_range) * n_mc, np.nan)\n",
    "\n",
    "avg_best_forecast    = np.full((len(corr_range) * len(b_range) * n_mc, len(n_range_avg_best)), np.nan)\n",
    "se_avg_best_forecast = np.full((len(corr_range) * len(b_range) * n_mc, len(n_range_avg_best)), np.nan)\n",
    "\n",
    "###### Start ######\n",
    "# Loop over Monte-Carlo Runs\n",
    "i = 0\n",
    "for r in tqdm(range(n_mc)):\n",
    "    \n",
    "    # Loop over Covariance-Sets\n",
    "    for p in corr_range:\n",
    "        \n",
    "        # Loop over Coefficient-Sets\n",
    "        for b in b_range:\n",
    "    \n",
    "            ### Simulate Data ###\n",
    "            y, X, pred_names = sim(n_obs, n_preds, b, p, r)\n",
    "            \n",
    "            ### Create Candidate Models ###\n",
    "            cand_forecasts = candidate_models(y, X, range(init, n_obs), k_range, cr_range, rep_range, n_core)\n",
    "            \n",
    "            #print(f\"Computing Covariance {p} and Coefficients {b}\")\n",
    "            \n",
    "            ### Benchmark: PHM ###\n",
    "            benchmark[i]    = y[:-1].mean()\n",
    "            se_benchmark[i] = (y[-1] - benchmark[i]) ** 2\n",
    "                \n",
    "            ### Benchmark: Complete Subset Regression ###\n",
    "            tmp_ = np.cumsum([0] + [len(list(combinations(range(n_preds), k))) for k in k_range])\n",
    "            csr_forecast[i]     =  [np.mean(cand_forecasts[-1, :n_sub][tmp_[i]:tmp_[i+1]]) for i in range(len(tmp_)-1)]\n",
    "            se_csr_forecast[i]  =  (y[-1] - csr_forecast[i]) ** 2\n",
    "            \n",
    "            ### Benchmark: LARS ###\n",
    "            #lars_forecast[i]    = lars(y[init:-1], cand_forecasts[:-1], cand_forecasts[[-1]], n_range_lars)\n",
    "            #se_lars_forecast[i] = (y[-1] - lars_forecast[i]) ** 2\n",
    "            \n",
    "            ### Benchmark: Forward Stepwise Selection ###\n",
    "            #fss_forecast[i]    = fss(y[init:-1], cand_forecasts[:-1], cand_forecasts[[-1]], n_range_fss, n_core)\n",
    "            #se_fss_forecast[i] = (y[-1] - fss_forecast[i]) ** 2\n",
    "            \n",
    "            ### Benchmark: peLASSO ###\n",
    "            #pelasso_forecast[i]    = peLASSO(y[init:-1], cand_forecasts[:-1], cand_forecasts[[-1]], n_alpha, n_iter_peL, cv_splits_peL, cv_repeats_peL)\n",
    "            #se_pelasso_forecast[i] = (y[-1] - pelasso_forecast[i]) ** 2\n",
    "            \n",
    "            ### Benchmark: Average-Best ###\n",
    "            #avg_best_forecast[i]    = avg_best(y[init:-1], cand_forecasts[:-1], cand_forecasts[[-1]], n_range_avg_best)\n",
    "            #se_avg_best_forecast[i] = (y[-1] - avg_best_forecast[i]) ** 2\n",
    "\n",
    "            ### Best Selection of Forecast ###\n",
    "            bssf_forecast[i], cf_weights[i] = zip(*list(map(lambda s: bssf(y[init:-1], cand_forecasts[:-1], cand_forecasts[[-1]], alpha, s, n_times), bssf_range)))\n",
    "            se_bssf_forecast[i] = (y[-1] - bssf_forecast[i]) ** 2\n",
    "             \n",
    "            # Update index   \n",
    "            i += 1\n",
    "            \n",
    "# # Candidate-Model-Names\n",
    "ssf_names = [f\"SSF{k}_\" + \"_\".join(map(str, sub)) for k in k_range for sub in combinations(range(n_preds), k)]\n",
    "cr_names  = [f\"CR{n_comp}_{r}\" for n_comp in cr_range for r in rep_range]\n",
    "\n",
    "### Evaluation ###\n",
    "for b in range(len(b_range)):\n",
    "    for p in range(len(corr_range)):\n",
    "    \n",
    "        # Calculate Forecast Combination Method Performances    \n",
    "        se_bssf      =  se_bssf_forecast[np.arange(b, n_mc * len(corr_range) * len(b_range), len(b_range))][np.arange(p, n_mc * len(corr_range), len(corr_range))]\n",
    "        se_csr       =  se_csr_forecast[np.arange(b, n_mc * len(corr_range) * len(b_range), len(b_range))][np.arange(p, n_mc * len(corr_range), len(corr_range))]\n",
    "        #se_lars      =  se_lars_forecast[np.arange(b, n_mc * len(corr_range) * len(b_range), len(b_range))][np.arange(p, n_mc * len(corr_range), len(corr_range))]\n",
    "        #se_fss       =  se_fss_forecast[np.arange(b, n_mc * len(corr_range) * len(b_range), len(b_range))][np.arange(p, n_mc * len(corr_range), len(corr_range))]\n",
    "        #se_pelasso   =  se_pelasso_forecast[np.arange(b, n_mc * len(corr_range) * len(b_range), len(b_range))][np.arange(p, n_mc * len(corr_range), len(corr_range))]\n",
    "        #se_avg_best  =  se_avg_best_forecast[np.arange(b, n_mc * len(corr_range) * len(b_range), len(b_range))][np.arange(p, n_mc * len(corr_range), len(corr_range))]\n",
    "\n",
    "        # Calculate Benchmark Performance\n",
    "        se_phm  = se_benchmark[np.arange(b, n_mc * len(corr_range) * len(b_range), len(b_range))][np.arange(p, n_mc * len(corr_range), len(corr_range))]\n",
    "        \n",
    "        # Print Results\n",
    "        print(f\"BSSF:       Avg. OOS-R2 for Corr. {corr_range[p]} and Betas {b_range[b]} is: \" + str(np.round(100 * (1 - sum(se_bssf) / sum(se_phm)), 2)) + \"%\")\n",
    "        print(f\"CSR:        Avg. OOS-R2 for Corr. {corr_range[p]} and Betas {b_range[b]} is: \" + str(np.round(100 * (1 - sum(se_csr)  / sum(se_phm)), 2)) + \"%\")\n",
    "        #print(f\"LARS:       Avg. OOS-R2 for Corr. {corr_range[p]} and Betas {b_range[b]} is: \" + str(np.round(100 * (1 - sum(se_lars) / sum(se_phm)), 2)) + \"%\")\n",
    "        #print(f\"FSS:        Avg. OOS-R2 for Corr. {corr_range[p]} and Betas {b_range[b]} is: \" + str(np.round(100 * (1 - sum(se_fss)  / sum(se_phm)), 2)) + \"%\")\n",
    "        #print(f\"peLASSO:    Avg. OOS-R2 for Corr. {corr_range[p]} and Betas {b_range[b]} is: \" + str(np.round(100 * (1 - sum(se_pelasso)  / sum(se_phm)), 2)) + \"%\")\n",
    "        #print(f\"Avg-Best N: Avg. OOS-R2 for Corr. {corr_range[p]} and Betas {b_range[b]} is: \" + str(np.round(100 * (1 - sum(se_avg_best) / sum(se_phm)), 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSSF:       Avg. OOS-R2 for Corr. 0.0 and Betas [1. 0. 0. 0. 0. 0. 0. 0.] is: [5.3  5.15 5.24 5.32 5.43 4.8 ]%\n",
    "CSR:        Avg. OOS-R2 for Corr. 0.0 and Betas [1. 0. 0. 0. 0. 0. 0. 0.] is: [1.73 3.09 4.11 4.78 5.12 5.12 4.78 4.09]%\n",
    "LARS:       Avg. OOS-R2 for Corr. 0.0 and Betas [1. 0. 0. 0. 0. 0. 0. 0.] is: [ 2.07000000e+000 -3.79000000e+000 -9.96590000e+002 -3.57842000e+004 -5.30253757e+007 -1.88807783e+132]%\n",
    "FSS:        Avg. OOS-R2 for Corr. 0.0 and Betas [1. 0. 0. 0. 0. 0. 0. 0.] is: [ 2.37  1.91  1.3   1.06  0.37 -0.16 -0.25 -0.18 -0.27 -0.72]%\n",
    "peLASSO:    Avg. OOS-R2 for Corr. 0.0 and Betas [1. 0. 0. 0. 0. 0. 0. 0.] is: -0.83%\n",
    "Avg-Best N: Avg. OOS-R2 for Corr. 0.0 and Betas [1. 0. 0. 0. 0. 0. 0. 0.] is: [5.3  5.29 5.39 5.34 5.44 4.8 ]%\n",
    "BSSF:       Avg. OOS-R2 for Corr. 0.5 and Betas [1. 0. 0. 0. 0. 0. 0. 0.] is: [7.72 7.61 7.65 7.66 7.7  7.08]%\n",
    "CSR:        Avg. OOS-R2 for Corr. 0.5 and Betas [1. 0. 0. 0. 0. 0. 0. 0.] is: [4.06 5.47 6.41 7.09 7.52 7.72 7.66 7.35]%\n",
    "LARS:       Avg. OOS-R2 for Corr. 0.5 and Betas [1. 0. 0. 0. 0. 0. 0. 0.] is: [ 2.66000000e+000 -1.35000000e+000 -4.59200000e+002 -1.55664300e+004 -4.68720454e+006 -6.82237413e+198]%\n",
    "FSS:        Avg. OOS-R2 for Corr. 0.5 and Betas [1. 0. 0. 0. 0. 0. 0. 0.] is: [ 4.52  4.83  3.08  1.97  1.28  0.63  0.07 -1.   -1.32 -2.09]%\n",
    "peLASSO:    Avg. OOS-R2 for Corr. 0.5 and Betas [1. 0. 0. 0. 0. 0. 0. 0.] is: -1.95%\n",
    "Avg-Best N: Avg. OOS-R2 for Corr. 0.5 and Betas [1. 0. 0. 0. 0. 0. 0. 0.] is: [7.72 7.75 7.7  7.84 7.82 7.08]%\n",
    "BSSF:       Avg. OOS-R2 for Corr. 0.95 and Betas [1. 0. 0. 0. 0. 0. 0. 0.] is: [6.91 7.7  7.76 7.86 7.95 7.97]%\n",
    "CSR:        Avg. OOS-R2 for Corr. 0.95 and Betas [1. 0. 0. 0. 0. 0. 0. 0.] is: [7.77 7.95 8.02 7.98 7.81 7.53 7.12 6.59]%\n",
    "LARS:       Avg. OOS-R2 for Corr. 0.95 and Betas [1. 0. 0. 0. 0. 0. 0. 0.] is: [ 2.55000000e+00 -1.77000000e+00 -4.39920000e+02 -2.42853800e+04 -4.45249327e+15            -inf]%\n",
    "FSS:        Avg. OOS-R2 for Corr. 0.95 and Betas [1. 0. 0. 0. 0. 0. 0. 0.] is: [ 5.41  3.26  1.83  1.68  1.27  0.83  0.69  1.44  0.42 -0.41]%\n",
    "peLASSO:    Avg. OOS-R2 for Corr. 0.95 and Betas [1. 0. 0. 0. 0. 0. 0. 0.] is: -3.45%\n",
    "Avg-Best N: Avg. OOS-R2 for Corr. 0.95 and Betas [1. 0. 0. 0. 0. 0. 0. 0.] is: [6.91 7.31 7.62 7.76 7.93 7.97]%\n",
    "\n",
    "BSSF:       Avg. OOS-R2 for Corr. 0.0 and Betas [1. 1. 1. 1. 0. 0. 0. 0.] is: [5.87 6.36 6.36 6.44 6.54 6.18]%\n",
    "CSR:        Avg. OOS-R2 for Corr. 0.0 and Betas [1. 1. 1. 1. 0. 0. 0. 0.] is: [2.05 3.75 5.13 6.17 6.88 7.25 7.29 6.99]%\n",
    "LARS:       Avg. OOS-R2 for Corr. 0.0 and Betas [1. 1. 1. 1. 0. 0. 0. 0.] is: [ 2.52000000e+000 -1.06000000e+001 -5.83570000e+002 -1.73518900e+004 -8.37694114e+007 -3.82112811e+163]%\n",
    "FSS:        Avg. OOS-R2 for Corr. 0.0 and Betas [1. 1. 1. 1. 0. 0. 0. 0.] is: [3.76 3.67 3.52 3.34 3.54 3.07 2.32 2.43 2.04 2.19]%\n",
    "peLASSO:    Avg. OOS-R2 for Corr. 0.0 and Betas [1. 1. 1. 1. 0. 0. 0. 0.] is: -2.13%\n",
    "Avg-Best N: Avg. OOS-R2 for Corr. 0.0 and Betas [1. 1. 1. 1. 0. 0. 0. 0.] is: [5.87 6.08 5.95 6.   6.32 6.18]%\n",
    "BSSF:       Avg. OOS-R2 for Corr. 0.5 and Betas [1. 1. 1. 1. 0. 0. 0. 0.] is: [14.27 15.61 15.74 15.91 16.08 16.4 ]%\n",
    "CSR:        Avg. OOS-R2 for Corr. 0.5 and Betas [1. 1. 1. 1. 0. 0. 0. 0.] is: [12.92 15.28 16.13 16.49 16.57 16.44 16.13 15.64]%\n",
    "LARS:       Avg. OOS-R2 for Corr. 0.5 and Betas [1. 1. 1. 1. 0. 0. 0. 0.] is: [ 5.54000000e+000 -7.40000000e+000 -1.85594000e+003 -7.03743600e+004 -9.77012471e+014 -6.10886863e+267]%\n",
    "FSS:        Avg. OOS-R2 for Corr. 0.5 and Betas [1. 1. 1. 1. 0. 0. 0. 0.] is: [12.86 12.05 11.95 11.76 10.65  9.94  9.11  8.54  8.4   8.15]%\n",
    "peLASSO:    Avg. OOS-R2 for Corr. 0.5 and Betas [1. 1. 1. 1. 0. 0. 0. 0.] is: -1.45%\n",
    "Avg-Best N: Avg. OOS-R2 for Corr. 0.5 and Betas [1. 1. 1. 1. 0. 0. 0. 0.] is: [14.27 15.4  15.79 15.84 16.08 16.4 ]%\n",
    "BSSF:       Avg. OOS-R2 for Corr. 0.95 and Betas [1. 1. 1. 1. 0. 0. 0. 0.] is: [23.45 24.72 24.82 24.87 24.93 25.1 ]%\n",
    "CSR:        Avg. OOS-R2 for Corr. 0.95 and Betas [1. 1. 1. 1. 0. 0. 0. 0.] is: [25.07 25.21 25.2  25.1  24.91 24.63 24.25 23.77]%\n",
    "LARS:       Avg. OOS-R2 for Corr. 0.95 and Betas [1. 1. 1. 1. 0. 0. 0. 0.] is: [ 7.72000000e+000 -7.37000000e+000 -4.14030000e+003 -3.77355250e+005 -5.00717015e+013 -1.08530823e+304]%\n",
    "FSS:        Avg. OOS-R2 for Corr. 0.95 and Betas [1. 1. 1. 1. 0. 0. 0. 0.] is: [22.37 21.16 20.79 19.99 19.41 19.21 18.77 17.56 16.95 17.16]%\n",
    "peLASSO:    Avg. OOS-R2 for Corr. 0.95 and Betas [1. 1. 1. 1. 0. 0. 0. 0.] is: -1.81%\n",
    "Avg-Best N: Avg. OOS-R2 for Corr. 0.95 and Betas [1. 1. 1. 1. 0. 0. 0. 0.] is: [23.45 24.42 24.6  24.73 24.83 25.1 ]%\n",
    "\n",
    "BSSF:       Avg. OOS-R2 for Corr. 0.0 and Betas [1. 1. 1. 1. 1. 1. 1. 1.] is: [2.83 4.57 4.71 4.93 5.15 5.4 ]%\n",
    "CSR:        Avg. OOS-R2 for Corr. 0.0 and Betas [1. 1. 1. 1. 1. 1. 1. 1.] is: [1.82 3.33 4.51 5.38 5.94 6.19 6.12 5.73]%\n",
    "LARS:       Avg. OOS-R2 for Corr. 0.0 and Betas [1. 1. 1. 1. 1. 1. 1. 1.] is: [ 1.89000000e+000 -9.83000000e+000 -4.75880000e+002 -1.50787200e+004 -9.58904251e+006 -7.54728041e+147]%\n",
    "FSS:        Avg. OOS-R2 for Corr. 0.0 and Betas [1. 1. 1. 1. 1. 1. 1. 1.] is: [ 2.23  0.88  0.61  0.52  0.76  0.28  0.09 -0.04 -0.7  -0.22]%\n",
    "peLASSO:    Avg. OOS-R2 for Corr. 0.0 and Betas [1. 1. 1. 1. 1. 1. 1. 1.] is: -3.02%\n",
    "Avg-Best N: Avg. OOS-R2 for Corr. 0.0 and Betas [1. 1. 1. 1. 1. 1. 1. 1.] is: [2.83 3.68 4.15 4.34 4.8  5.4 ]%\n",
    "BSSF:       Avg. OOS-R2 for Corr. 0.5 and Betas [1. 1. 1. 1. 1. 1. 1. 1.] is: [25.71 26.31 26.52 26.74 27.05 27.57]%\n",
    "CSR:        Avg. OOS-R2 for Corr. 0.5 and Betas [1. 1. 1. 1. 1. 1. 1. 1.] is: [22.5  26.26 27.38 27.74 27.77 27.61 27.31 26.89]%\n",
    "LARS:       Avg. OOS-R2 for Corr. 0.5 and Betas [1. 1. 1. 1. 1. 1. 1. 1.] is: [ 8.47000000e+000 -6.66000000e+000 -3.59007000e+003 -3.30016220e+005 -1.26080654e+012 -2.23377050e+203]%\n",
    "FSS:        Avg. OOS-R2 for Corr. 0.5 and Betas [1. 1. 1. 1. 1. 1. 1. 1.] is: [24.15 23.91 22.67 23.14 23.11 23.4  23.01 23.16 22.43 22.45]%\n",
    "peLASSO:    Avg. OOS-R2 for Corr. 0.5 and Betas [1. 1. 1. 1. 1. 1. 1. 1.] is: 0.44%\n",
    "Avg-Best N: Avg. OOS-R2 for Corr. 0.5 and Betas [1. 1. 1. 1. 1. 1. 1. 1.] is: [25.71 26.69 26.84 26.79 27.02 27.57]%\n",
    "BSSF:       Avg. OOS-R2 for Corr. 0.95 and Betas [1. 1. 1. 1. 1. 1. 1. 1.] is: [38.32 39.43 39.56 39.58 39.65 39.82]%\n",
    "CSR:        Avg. OOS-R2 for Corr. 0.95 and Betas [1. 1. 1. 1. 1. 1. 1. 1.] is: [39.81 39.94 39.92 39.83 39.66 39.42 39.1  38.71]%\n",
    "LARS:       Avg. OOS-R2 for Corr. 0.95 and Betas [1. 1. 1. 1. 1. 1. 1. 1.] is: [ 1.15800000e+001 -7.48900000e+001 -1.15969600e+004 -9.39080260e+005 -9.88798732e+010 -5.78881317e+202]%\n",
    "FSS:        Avg. OOS-R2 for Corr. 0.95 and Betas [1. 1. 1. 1. 1. 1. 1. 1.] is: [37.28 36.41 36.08 35.96 35.32 35.15 34.85 35.04 34.14 33.78]%\n",
    "peLASSO:    Avg. OOS-R2 for Corr. 0.95 and Betas [1. 1. 1. 1. 1. 1. 1. 1.] is: -0.08%\n",
    "Avg-Best N: Avg. OOS-R2 for Corr. 0.95 and Betas [1. 1. 1. 1. 1. 1. 1. 1.] is: [38.32 39.1  39.37 39.44 39.57 39.82]%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up DataFrame\n",
    "dataframe_plot = pd.DataFrame()\n",
    "\n",
    "# Create DataFrame\n",
    "for b in range(len(b_range)):\n",
    "    for p in range(len(corr_range)):\n",
    "        \n",
    "        # Subset Weights\n",
    "        chosen_cm = cf_weights[np.arange(b, n_mc * len(corr_range) * len(b_range), len(b_range))][np.arange(p, n_mc * len(corr_range), len(corr_range))]\n",
    "\n",
    "        # Aggregated\n",
    "        chosen_cm = np.sum(chosen_cm, axis = 0)\n",
    "\n",
    "        # Replace Zero with NaN\n",
    "        chosen_cm[chosen_cm == 0] = np.nan\n",
    "        chosen_cm_agg = chosen_cm.copy()\n",
    "\n",
    "        # Set to One\n",
    "        chosen_cm[chosen_cm > 1 ] = 1\n",
    "\n",
    "        # Adapt Column-Values\n",
    "        chosen_cm = chosen_cm * np.arange(1, chosen_cm.shape[1]+1)\n",
    "\n",
    "        # Create DataFrame\n",
    "        chosen_cm = pd.DataFrame(chosen_cm, index = [f\"K={k}\" for k in bssf_range], columns = [*ssf_names, *cr_names])\n",
    "        chosen_cm_agg = pd.DataFrame(chosen_cm_agg, index = [f\"K={k}\" for k in bssf_range], columns = [*ssf_names, *cr_names])\n",
    "\n",
    "        # Index\n",
    "        chosen_cm = chosen_cm.reset_index(names=\"INDEX\")\n",
    "        chosen_cm_agg = chosen_cm_agg.reset_index(names=\"INDEX\")\n",
    "\n",
    "        # Melt Data\n",
    "        chosen_cm = chosen_cm.melt(id_vars = 'INDEX', var_name = 'Candidate_Model', value_name = 'Value')\n",
    "        chosen_cm_agg = chosen_cm_agg.melt(id_vars = 'INDEX', var_name = 'Candidate_Model', value_name = 'Weight')\n",
    "\n",
    "        # Concatenate\n",
    "        chosen_cm = pd.concat([chosen_cm, chosen_cm_agg])\n",
    "        \n",
    "        # Transform Candidate Model Names\n",
    "        chosen_cm['Candidate_Model'] = chosen_cm['Candidate_Model'].str.split('_').str[0]\n",
    "        \n",
    "        # Add Column for Correlation\n",
    "        chosen_cm['Correlation'] = corr_range[p] \n",
    "        \n",
    "        # Add Column for Betas\n",
    "        chosen_cm['Betas'] = str(b_range[b])\n",
    "        \n",
    "        # Append\n",
    "        dataframe_plot = pd.concat([dataframe_plot, chosen_cm])\n",
    "        \n",
    "# Plot Theme\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "# Plot Data\n",
    "g = sns.relplot(\n",
    "    data = dataframe_plot,\n",
    "    y = 'Value', x = 'INDEX',\n",
    "    hue = \"Candidate_Model\", size = \"Weight\", \n",
    "    col = \"Betas\", row = \"Correlation\",\n",
    "    sizes = (3, 75), height = 5.0, aspect = 1.5,\n",
    "    alpha = 0.75, palette = \"muted\",\n",
    "    #legend = True\n",
    "    )\n",
    "\n",
    "# Legend\n",
    "#g._legend.remove()\n",
    "#h, l = g.ax.get_legend_handles_labels()\n",
    "#g.ax.legend(h[0:13], l[0:13], bbox_to_anchor=(1.0, 0.75), loc=2, fontsize=10, frameon=False)\n",
    "\n",
    "# Title & Axis\n",
    "g.set(xlabel='Combination Size',\n",
    "      ylabel='Candidate Models')\n",
    "      #title=f\"Selected Candidate Models: \\n Correlation {corr_range[p]} & Betas {b_range[b]}\")\n",
    "\n",
    "# Margins\n",
    "#g.ax.margins(x = 0.05, y = 0)\n",
    "\n",
    "# Set number of ticks for y-axis\n",
    "idx = [0, 8, 36, 92, 162, 218, 246, 255, 315, 375, 435]\n",
    "#g.ax.set_yticks(idx)\n",
    "\n",
    "# Set ticks labels for x-axis\n",
    "#g.ax.set_yticklabels([string.split(\"_\")[0] for string in [[[*ssf_names, *cr_names]][0][i] for i in idx]], rotation='horizontal')\n",
    "\n",
    "## iterate over axes of FacetGrid\n",
    "for ax in g.axes.flatten():\n",
    "    ax.set_yticks(idx)\n",
    "    ax.set_yticklabels([string.split(\"_\")[0] for string in [[[*ssf_names, *cr_names]][0][i] for i in idx]], rotation='horizontal')\n",
    "\n",
    "# Tick-Label Size\n",
    "g.set_yticklabels(size = 8)\n",
    "g.set_xticklabels(size = 10)\n",
    "\n",
    "# Add Horizontal Lines\n",
    "#for i in idx:\n",
    "#    g.ax.axhline(y=i, color='r', linestyle='--', lw = 0.2)\n",
    "\n",
    "# Rotate x-axis labels\n",
    "#for label in g.ax.get_xticklabels():\n",
    "#    label.set_rotation(90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(len(b_range)):\n",
    "    for p in range(len(corr_range)):\n",
    "        \n",
    "        # Subset Weights\n",
    "        chosen_cm = cf_weights[np.arange(b, n_mc * len(corr_range) * len(b_range), len(b_range))][np.arange(p, n_mc * len(corr_range), len(corr_range))]\n",
    "\n",
    "        # Aggregated\n",
    "        chosen_cm = np.sum(chosen_cm, axis = 0)\n",
    "\n",
    "        # Replace Zero with NaN\n",
    "        chosen_cm[chosen_cm == 0] = np.nan\n",
    "        chosen_cm_agg = chosen_cm.copy()\n",
    "\n",
    "        # Set to One\n",
    "        chosen_cm[chosen_cm > 1 ] = 1\n",
    "\n",
    "        # Adapt Column-Values\n",
    "        chosen_cm = chosen_cm * np.arange(1, chosen_cm.shape[1]+1)\n",
    "\n",
    "        # Create DataFrame\n",
    "        chosen_cm = pd.DataFrame(chosen_cm, index = [f\"K={k}\" for k in bssf_range], columns = [*ssf_names, *cr_names])\n",
    "        chosen_cm_agg = pd.DataFrame(chosen_cm_agg, index = [f\"K={k}\" for k in bssf_range], columns = [*ssf_names, *cr_names])\n",
    "\n",
    "        # Index\n",
    "        chosen_cm = chosen_cm.reset_index(names=\"INDEX\")\n",
    "        chosen_cm_agg = chosen_cm_agg.reset_index(names=\"INDEX\")\n",
    "\n",
    "        # Melt Data\n",
    "        chosen_cm = chosen_cm.melt(id_vars = 'INDEX', var_name = 'Candidate_Model', value_name = 'Value')\n",
    "        chosen_cm_agg = chosen_cm_agg.melt(id_vars = 'INDEX', var_name = 'Candidate_Model', value_name = 'Weight')\n",
    "\n",
    "        # Concatenate\n",
    "        chosen_cm = pd.concat([chosen_cm, chosen_cm_agg])\n",
    "\n",
    "        # Transform Candidate Model Names\n",
    "        chosen_cm['Candidate_Model'] = chosen_cm['Candidate_Model'].str.split('_').str[0]\n",
    "        #chosen_cm['Candidate_Model'] = chosen_cm['Candidate_Model'].str.startswith(\"SSF\").replace({True: \"SSF\", False: \"CR\"})\n",
    "\n",
    "        # Plot Theme\n",
    "        sns.set_theme(style=\"ticks\")\n",
    "\n",
    "        # Draw each cell as a scatter point with varying size and color\n",
    "        g = sns.relplot(\n",
    "            data = chosen_cm,\n",
    "            y = 'Value', x = 'INDEX', hue = \"Candidate_Model\", \n",
    "            size = \"Weight\", sizes = (3, 75),\n",
    "            height = 6.5, alpha = 0.75, palette=\"muted\",\n",
    "            #legend = True\n",
    "            )\n",
    "\n",
    "        # Legend\n",
    "        g._legend.remove()\n",
    "        h, l = g.ax.get_legend_handles_labels()\n",
    "        g.ax.legend(h[0:13], l[0:13], bbox_to_anchor=(1.0, 0.75), loc=2, fontsize=10, frameon=False)\n",
    "\n",
    "        # Title & Axis\n",
    "        g.set(xlabel='Combination Size',\n",
    "              ylabel='Candidate Models',\n",
    "              title=f\"Selected Candidate Models: \\n Correlation {corr_range[p]} & Betas {b_range[b]}\")\n",
    "\n",
    "        # Margins\n",
    "        g.ax.margins(x = 0.05, y = 0)\n",
    "\n",
    "        # Set number of ticks for y-axis\n",
    "        idx = [0, 8, 36, 92, 162, 218, 246, 255, 315, 375, 435]\n",
    "        g.ax.set_yticks(idx)\n",
    "\n",
    "        # Set ticks labels for x-axis\n",
    "        g.ax.set_yticklabels([string.split(\"_\")[0] for string in [[[*ssf_names, *cr_names]][0][i] for i in idx]], rotation='horizontal')\n",
    "\n",
    "        # Tick-Label Size\n",
    "        g.set_yticklabels(size = 8)\n",
    "        g.set_xticklabels(size = 10)\n",
    "\n",
    "        # Add Horizontal Lines\n",
    "        #for i in idx:\n",
    "        #    g.ax.axhline(y=i, color='r', linestyle='--', lw = 0.2)\n",
    "\n",
    "        # Rotate x-axis labels\n",
    "        for label in g.ax.get_xticklabels():\n",
    "            label.set_rotation(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Plot\n",
    "fig, ax = plt.subplots(1,1) \n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10)\n",
    "\n",
    "# Plot \n",
    "colors = {'SSF':'blue', 'CR':'green'}\n",
    "ax.scatter(x = chosen_cm['INDEX'], y = chosen_cm['Weight'], c=chosen_cm['Candidate_Model'].map(colors), s = 1)\n",
    "#ax.plot(chosen_cm['INDEX'], chosen_cm.iloc[:, 1:], marker = \"o\", lw = 0, ms = 4)\n",
    "\n",
    "# Add title and axis names\n",
    "plt.title('Selected Candidate Models')\n",
    "plt.ylabel('Candidate Models')\n",
    "plt.xlabel('Combination Size')\n",
    "\n",
    "# Legend\n",
    "#plt.legend(loc = \"upper right\")\n",
    "\n",
    "# Margins\n",
    "plt.margins(x=0.10, y=0)\n",
    "\n",
    "# Set number of ticks for x-axis\n",
    "idx = [0, 8, 36, 92, 162, 218, 246, 255, 315, 375, 435]\n",
    "ax.set_yticks(idx)\n",
    "\n",
    "# Set ticks labels for x-axis\n",
    "ax.set_yticklabels([[[*ssf_names, *cr_names]][0][i] for i in idx], rotation='horizontal', fontsize=6)\n",
    "\n",
    "# Add horizontal lines\n",
    "for i in idx:\n",
    "    plt.axhline(y=i, color='r', linestyle='--', lw = 0.2)\n",
    "\n",
    "# Show Plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot: Welches K hat was ausgewählt\n",
    "### Benchmark: Complete Subset Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(len(b_range)):\n",
    "    for p in range(len(corr_range)):\n",
    "        \n",
    "        se_bssf = se_bssf_forecast[np.arange(b, n_mc * len(corr_range) * len(b_range), len(b_range))][np.arange(p, n_mc * len(corr_range), len(corr_range))]\n",
    "        se_csr  = se_csr_forecast[np.arange(b, n_mc * len(corr_range) * len(b_range), len(b_range))][np.arange(p, n_mc * len(corr_range), len(corr_range))]\n",
    "        se_phm  = se_benchmark[np.arange(b, n_mc * len(corr_range) * len(b_range), len(b_range))][np.arange(p, n_mc * len(corr_range), len(corr_range))]\n",
    "        \n",
    "        print(f\"BSSF: Avg. OOS-R2 for Corr. {corr_range[p]} and Betas {b_range[b]} is:\" + str(np.round(100 * (1 - sum(se_bssf) / sum(se_phm)), 2)) + \"%\")\n",
    "        print(f\"CSR:  Avg. OOS-R2 for Corr. {corr_range[p]} and Betas {b_range[b]} is:\" + str(np.round(100 * (1 - sum(se_csr) / sum(se_phm)), 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = benchmark[np.arange(0, n_mc * len(corr_range) * len(b_range), len(b_range))]\n",
    "b2 = benchmark[np.arange(1, n_mc * len(corr_range) * len(b_range), len(b_range))]\n",
    "\n",
    "b1_p1 = b1[np.arange(0, n_mc * len(corr_range), len(corr_range))]\n",
    "b1_p2 = b1[np.arange(1, n_mc * len(corr_range), len(corr_range))]\n",
    "b1_p3 = b1[np.arange(2, n_mc * len(corr_range), len(corr_range))]\n",
    "\n",
    "b2_p1 = b2[np.arange(0, n_mc * len(corr_range), len(corr_range))]\n",
    "b2_p2 = b2[np.arange(1, n_mc * len(corr_range), len(corr_range))]\n",
    "b2_p3 = b2[np.arange(2, n_mc * len(corr_range), len(corr_range))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Goyal Welch Data\n",
    "data  =  pd.read_csv(path + r'/Data/PredictorData2022.xlsx - Quarterly.csv', thousands=',')\n",
    "\n",
    "# Equity Premium\n",
    "data['equity_premium'] = data['CRSP_SPvw'] - data['Rfree']\n",
    "\n",
    "# Dividend Price Ratio \n",
    "data['dp'] = np.log(data['D12']) - np.log(data['Index'])\n",
    "\n",
    "# Dividend Yield \n",
    "data['dy'] = np.log(data['D12'])- np.log(data['Index'].shift(1))\n",
    "\n",
    "# Earnings Price Ratio \n",
    "data['ep'] = np.log(data['E12']) - np.log(data['Index'])\n",
    "\n",
    "# Dividend Payout Ratio \n",
    "data['dpayr'] = np.log(data['D12']) - np.log(data['E12'])\n",
    "\n",
    "# Book to Market Ratio\n",
    "data['bmr'] = data['b/m']\n",
    "\n",
    "# # Net Equity Expansion\n",
    "data['ntis'] = data['ntis']\n",
    "\n",
    "# Treasury Bill Rate\n",
    "data['tbl'] = data['tbl']\n",
    "\n",
    "# Long Term Rate\n",
    "data['ltr'] = data['ltr']\n",
    "\n",
    "# Term Spread \n",
    "data['tsp'] = data['lty'] - data['tbl']\n",
    "\n",
    "# Default Return Spread \n",
    "data['dfr'] = data['corpr'] - data['ltr']\n",
    "\n",
    "# Inflation\n",
    "data['infl'] = data['infl']\n",
    "\n",
    "# Investment of Capital Ratio\n",
    "data['ik']  = data['ik']\n",
    "\n",
    "# Default Yield Spread\n",
    "data['dfy'] = data['BAA'] - data['AAA']\n",
    "\n",
    "# Realized Volatility\n",
    "data['rvol'] = data['svar']\n",
    "\n",
    "# reorganize the dataframe\n",
    "data = data[['yyyyq', \"equity_premium\", \"dp\", \"dy\", \"ep\", \"dpayr\", \"bmr\", \"ntis\", \"tbl\", \"ltr\", \"tsp\", \"dfr\", \"infl\", \"ik\"]]\n",
    "\n",
    "# Convert Date\n",
    "data['yyyyq'] = data['yyyyq'].astype(str)\n",
    "data['yyyyq'] = data.apply(lambda x: x['yyyyq'][:4]+'-Q'+x['yyyyq'][4:], axis=1)\n",
    "data['yyyyq'] = pd.to_datetime(data['yyyyq'])\n",
    "\n",
    "# Resetting the index\n",
    "data.set_index('yyyyq', inplace=True)\n",
    "data.index = data.index.to_period('Q')\n",
    "\n",
    "# Lag all Predictors\n",
    "data.iloc[:,1:]  =  data.iloc[:,1:].shift(1)\n",
    "\n",
    "# Drop Na\n",
    "data = data.loc[\"1946Q1\":, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Set Seed ######\n",
    "#random.seed(123)\n",
    "\n",
    "###### Data ######\n",
    "# Set Target Variable\n",
    "y  =  data.loc[:, [\"equity_premium\"]]\n",
    "X  =  data.drop(\"equity_premium\", axis = 1)\n",
    "\n",
    "# Get Predictor Names\n",
    "pred_names = list(X.columns)\n",
    "\n",
    "# Number of AR-Terms to include\n",
    "mlags =  2\n",
    "\n",
    "# Create Lags\n",
    "X  =  create_lags(y, X, mlags)\n",
    "\n",
    "# Drop Missing Values\n",
    "y  =  y.loc[\"1947Q2\":, ] #y[mlags:]\n",
    "X  =  X.loc[\"1947Q2\":, ] #X[mlags:]\n",
    "\n",
    "# Check NA\n",
    "any(X.isna().any())\n",
    "\n",
    "###### Parameter Subset Forecasts\n",
    "# Subset Lengths\n",
    "k_range = [1, 2, 3] # [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "\n",
    "# Upper Bound for Subset-Sizes\n",
    "n_max = 10000  # 20000\n",
    "\n",
    "# Number of Subset-Forecasts\n",
    "n_sub  =  int(sum([min(n_models((X.shape[1]-mlags), k), n_max) for k in k_range]))\n",
    "\n",
    "###### Parameter Compressed Regressions ######\n",
    "# Number of Components for Compressed Regression\n",
    "cr_range  =  [1, 2, 3] # [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100]\n",
    "\n",
    "# Number of runs for each random projection\n",
    "rep_range  =  range(0, 100) # 10000\n",
    "\n",
    "# Number of Compressed-Regression-Forecasts\n",
    "n_cr  =  len(cr_range) * len(rep_range)\n",
    "\n",
    "# ###### Parameter Decision Tree ######\n",
    "# dt_range  =  range(0, 5) # 300000\n",
    "# \n",
    "# # Number of Decision Trees\n",
    "# n_dt  =  len(dt_range)\n",
    "\n",
    "###### Parameter BSSF ######\n",
    "alpha       =  0.5\n",
    "n_times     =  50\n",
    "bssf_range  =  [1, 2, 3] # range(1, 5)\n",
    "n_bssf      =  len(bssf_range)\n",
    "\n",
    "### General Parameter ######\n",
    "# Initial Training-Period\n",
    "init       =  4 * 50 #4 * 10\n",
    "\n",
    "# Total Length\n",
    "total =  len(y) \n",
    "\n",
    "# Set up Matrices for Results\n",
    "cand_forecasts  =  np.full((total, (n_sub + n_cr)), np.nan)     #np.full((total, (n_sub + n_cr + n_dt)), np.nan)\n",
    "cf_weights      =  np.full((total, (n_sub + n_cr)), np.nan)\n",
    "benchmark       =  np.full(total, np.nan)\n",
    "bssf_forecast   =  np.full(total, np.nan)\n",
    "bssf_opt        =  np.full(total, np.nan)\n",
    "sse_bssf        =  np.zeros(n_bssf)\n",
    "\n",
    "###### Start ######\n",
    "# Loop over Time\n",
    "for t in tqdm(range(init, total)):\n",
    "        \n",
    "    # Pre-Process Data\n",
    "    y_train, X_train, y_pred, X_pred = prepro(y, X, t)\n",
    "    \n",
    "    ### Benchmark: AR(X) Model\n",
    "    pred          =  ar_mod(y_train, lags = mlags)\n",
    "    benchmark[t]  =  pred.iloc[0]\n",
    "    \n",
    "    ### Subset Forecasts\n",
    "    # Set up List to store Subset-Forecasts\n",
    "    preds_ssf =  np.full(n_sub, np.nan)\n",
    "    idx_sub   =  0\n",
    "    \n",
    "    # Loop over Subset Size \n",
    "    for k in k_range:\n",
    "    \n",
    "        # Get all possible Subset of length k\n",
    "        col_idx   =  list(range(mlags+1, X_train.shape[1]))\n",
    "        subs_idx  =  complete_sub(col_idx, k)\n",
    "\n",
    "        # Randomly select n_upper Subsets\n",
    "        feature_set  =  subs_idx #random_select(subs_idx, n_max, random_state = 123)\n",
    "\n",
    "        # Loop over Subsets\n",
    "        for feature in feature_set:\n",
    "\n",
    "            # Compute Subset-Regression-Forecast\n",
    "            pred  =  ssf(y_train, X_train, X_pred, feature, mlags)\n",
    "            preds_ssf[idx_sub] = pred\n",
    "            idx_sub += 1\n",
    "            \n",
    "    ### Compressed Regressions\n",
    "    # Set up List to store Compressed-Regression-Forecasts\n",
    "    preds_cr = np.full(n_cr, np.nan)\n",
    "    idx_cr   = 0\n",
    "    \n",
    "    # Loop over number of Components\n",
    "    for n_comp in cr_range:\n",
    "\n",
    "        # Loop over n repetitions\n",
    "        for r in rep_range:\n",
    "        \n",
    "            # Compute Compressed-Regression-Forecasts\n",
    "            pred  =  cr_reg(y_train, X_train, X_pred, n_comp, mlags, r)\n",
    "            preds_cr[idx_cr] = pred\n",
    "            idx_cr += 1\n",
    "            \n",
    "    # ### Decision Tree Regressions\n",
    "    # # Set up Matrix to store Decision-Tree-Forecasts\n",
    "    # preds_dt   = np.full(n_dt, np.nan)\n",
    "    # \n",
    "    # # Loop over number of Components\n",
    "    # for idx_dt, r in enumerate(dt_range):\n",
    "    #     \n",
    "    #     # Compute Decision-Tree-Forecasts\n",
    "    #     pred  =  dt_reg(y_train, X_train, X_pred, r)\n",
    "    #     preds_dt[idx_dt] = pred[0]\n",
    "\n",
    "    # Append Results\n",
    "    cand_forecasts[t][:n_sub]             =  preds_ssf \n",
    "    cand_forecasts[t][n_sub:(n_sub+n_cr)] =  preds_cr\n",
    "    #cand_forecasts[t][(n_sub+n_cr):]      =  preds_dt\n",
    "\n",
    "    ### Best Selection of Forecast\n",
    "    if t > init:\n",
    "    \n",
    "        # Set up Matrix to store Forecasts\n",
    "        bssf_forecasts  =  np.full(n_bssf, np.nan)\n",
    "        bssf_weights    =  np.zeros([n_bssf, n_sub + n_cr]) \n",
    "           \n",
    "        # Get \"best\" Subset-Size until now (lowest Sum of Squared Errors)\n",
    "        s_opt  =  np.argmin(sse_bssf)\n",
    "    \n",
    "        # Loop over Subset Sizes\n",
    "        for idx_bssf, s in enumerate(bssf_range):\n",
    "    \n",
    "            # Compute Best-Subset-Selection-of-Forecasts\n",
    "            pred  =  bssf(y_train[init:], cand_forecasts[init:t], cand_forecasts[t], alpha, s, n_times)\n",
    "            bssf_forecasts[idx_bssf]  =  pred[0]\n",
    "            bssf_weights[idx_bssf]    =  pred[1]\n",
    "    \n",
    "            # Compute Sum of Squared Errors\n",
    "            sse_bssf[idx_bssf] =  sse_bssf[idx_bssf] + (y_pred.iloc[0,0] - pred[0]) ** 2\n",
    "    \n",
    "        # Select Forecast \n",
    "        bssf_forecast[t] =  bssf_forecasts[s_opt]\n",
    "        cf_weights[t]    =  bssf_weights[s_opt]\n",
    "        bssf_opt[t]      =  bssf_range[s_opt]\n",
    "        \n",
    "# Candidate-Model-Names\n",
    "ssf_names = [f\"SSF{k}_\" + \"_\".join(map(str, sub)) for k in k_range for sub in combinations(range(len(pred_names)), k)]\n",
    "cr_names  = [f\"CR{n_comp}_{r}\" for n_comp in cr_range for r in rep_range]\n",
    "#dt_names = [f\"DT_{idx_dt}\" for idx_dt in dt_range]\n",
    "        \n",
    "# Convert Results to DataFrame\n",
    "cand_forecasts  =  pd.DataFrame(cand_forecasts, index = y.index, columns = [*ssf_names, *cr_names]) #, *dt_names])\n",
    "benchmark       =  pd.DataFrame(benchmark,      index = y.index, columns = [\"AR\"])\n",
    "bssf_forecast   =  pd.DataFrame(bssf_forecast,  index = y.index, columns = [\"BSSF\"])\n",
    "cf_weights      =  pd.DataFrame(cf_weights,     index = y.index, columns = [*ssf_names, *cr_names]) #, *dt_names])\n",
    "bssf_opt        =  pd.DataFrame(bssf_opt,     index = y.index, columns = [\"Subset_Size\"])\n",
    "\n",
    "# Cut off initial Training-Period\n",
    "sub_y              =  y.iloc[init:].copy()\n",
    "sub_cand_forecasts =  cand_forecasts.iloc[init:].copy()\n",
    "sub_benchmark      =  benchmark.iloc[init:].copy()\n",
    "sub_bssf_forecast  =  bssf_forecast.iloc[init:].copy()\n",
    "sub_cf_weights     =  cf_weights.iloc[init:].copy()\n",
    "sub_bssf_opt       =  bssf_opt.iloc[init:].copy()\n",
    "\n",
    "# OOS-Period\n",
    "oos_start  =  \"1999Q4\"\n",
    "oos_end    =  \"2022Q4\" \n",
    "oos_y             =  sub_y.loc[oos_start:oos_end].copy()\n",
    "oos_cand_forecast =  sub_cand_forecasts.loc[oos_start:oos_end].copy()\n",
    "oos_benchmark     =  sub_benchmark.loc[oos_start:oos_end].copy()\n",
    "oos_bssf_forecast =  sub_bssf_forecast.loc[oos_start:oos_end].copy()\n",
    "oos_cf_weights    =  sub_cf_weights.loc[oos_start:oos_end].copy()\n",
    "oos_bssf_opt      =  sub_bssf_opt.loc[oos_start:oos_end].copy()\n",
    "\n",
    "# Evaluation\n",
    "np.sum((oos_y.iloc[:,0] - oos_bssf_forecast.iloc[:,0]) ** 2) / np.sum((oos_y.iloc[:,0] - oos_benchmark.iloc[:,0]) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Zero with NaN\n",
    "oos_cf_weights.replace({0:np.nan}, inplace=True)\n",
    "\n",
    "# Adapt Column-Values\n",
    "vec = list(range(1, oos_cf_weights.shape[1]+1))\n",
    "tmp = oos_cf_weights * vec\n",
    "\n",
    "# Dates\n",
    "tmp = tmp.reset_index(names=\"date\")\n",
    "\n",
    "# Plot \n",
    "# tmp.plot(x='date', y = tmp.columns[1:],\n",
    "#          figsize=(10, 5), legend=False,\n",
    "#          marker=\"o\", ms = 1, \n",
    "#          title=\"Selected Candidate Models\", ylabel=\"Selected Candidate Models\")\n",
    "#          #yticks = (np.arange(98), list(tmp.columns[1:])))\n",
    "\n",
    "tmp_long = pd.melt(tmp, id_vars = \"date\")\n",
    "tmp_long['variable'] = tmp_long['variable'].str.startswith(\"SSF\").replace({True: \"SSF\", False: \"CR\"})\n",
    "tmp_long.set_index(\"date\", inplace = True)\n",
    "tmp_long.groupby(\"variable\")[\"value\"].plot(legend=True, figsize = (10, 5),\n",
    "                                           marker=\"o\", ms = 2, lw = 0,\n",
    "                                           ylim = [-1, cand_forecasts.shape[1]+1],\n",
    "                                           title=\"Selected Candidate Models\", ylabel=\"Selected Candidate Models\")\n",
    "plt.show()\n",
    "\n",
    "# Subset Size\n",
    "oos_bssf_opt.plot(figsize=(10, 5), legend=False, \n",
    "                  color = \"black\", marker=\"o\", ms = 1, lw = 0,\n",
    "                  title = \"Subset Size\", xlabel=\"date\", ylabel=\"Selected Subset Size\",\n",
    "                  ylim  =  [min(bssf_range)-0.5, max(bssf_range)+0.5],\n",
    "                  yticks = np.arange(min(bssf_range), max(bssf_range)+1, step=1.0))\n",
    "plt.show()\n",
    "\n",
    "# CSSED\n",
    "cssed = np.cumsum(((oos_y.iloc[:,0] - oos_benchmark.iloc[:,0]) ** 2) - ((oos_y.iloc[:,0] - oos_bssf_forecast.iloc[:,0]) ** 2))\n",
    "cssed.plot(figsize=(10, 5),\n",
    "            xlabel = \"date\", ylabel = \"CSSED\", title = \"Cumulated Sum of Squared Error Differences\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### MC-Parameter ######\n",
    "# Number of MC-Runs\n",
    "n_mc  =  2\n",
    "\n",
    "# Set Parameter\n",
    "n_obs       =  100\n",
    "n_preds     =  8\n",
    "init        =  50\n",
    "mlags       =  0\n",
    "corr_range  =  [0.5, 0.95]\n",
    "b_range     =  np.array([[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]])\n",
    "\n",
    "###### Parameter Subset Forecasts ######\n",
    "# Subset Lengths\n",
    "k_range = [1, 2, 3, 4, 5, 6, 7, 8] \n",
    "\n",
    "# Upper Bound for Subset-Sizes\n",
    "n_max = 10000  \n",
    "\n",
    "# Number of Subset-Forecasts\n",
    "n_sub  =  int(sum([min(n_models(n_preds, k), n_max) for k in k_range]))\n",
    "\n",
    "###### Parameter Compressed Regressions ######\n",
    "# Number of Components for Compressed Regression\n",
    "cr_range  =  [1, 2] \n",
    "\n",
    "# Number of runs for each random projection\n",
    "rep_range  =  range(0, 50) \n",
    "\n",
    "# Number of Compressed-Regression-Forecasts\n",
    "n_cr  =  len(cr_range) * len(rep_range)\n",
    "\n",
    "# ###### Parameter Decision Tree ######\n",
    "# dt_range  =  range(0, 5) \n",
    "# \n",
    "# # Number of Decision Trees\n",
    "# n_dt  =  len(dt_range)\n",
    "\n",
    "###### Parameter BSSF ######\n",
    "alpha       =  10.0\n",
    "n_times     =  1\n",
    "bssf_range  =  [1, 2, 3] \n",
    "n_bssf      =  len(bssf_range)\n",
    "\n",
    "######## Objects ########\n",
    "# Set up Matrices for Results\n",
    "cand_forecasts   = np.full((len(range(init, n_obs)), (n_sub + n_cr)), np.nan)     \n",
    "benchmark        = np.full( len(corr_range) * len(b_range) * n_mc, np.nan)\n",
    "cf_weights       = np.full((len(corr_range) * len(b_range) * n_mc, n_bssf, (n_sub + n_cr)), np.nan)\n",
    "bssf_forecast    = np.full((len(corr_range) * len(b_range) * n_mc, n_bssf), np.nan)\n",
    "csr_forecast     = np.full((len(corr_range) * len(b_range) * n_mc, len(k_range)), np.nan)\n",
    "se_benchmark     = np.full( len(corr_range) * len(b_range) * n_mc, np.nan)\n",
    "se_bssf_forecast = np.full((len(corr_range) * len(b_range) * n_mc, n_bssf), np.nan)\n",
    "se_csr_forecast  = np.full((len(corr_range) * len(b_range) * n_mc, len(k_range)), np.nan)\n",
    "\n",
    "###### Start ######\n",
    "# Loop over Monte-Carlo Runs\n",
    "i = 0\n",
    "for r in tqdm(range(n_mc)):\n",
    "    \n",
    "    # Loop over Covariance-Sets\n",
    "    for p in corr_range:\n",
    "        \n",
    "        # Loop over Coefficient-Sets\n",
    "        for b in b_range:\n",
    "    \n",
    "            ### Simulate Data ###\n",
    "            y, X, pred_names = sim(n_obs, n_preds, b, p, r)\n",
    "            \n",
    "            ### Benchmark: PHM ###\n",
    "            benchmark[i]    = y.iloc[:-1].mean().iloc[0]\n",
    "            se_benchmark[i] = (y.iloc[-1,0] - benchmark[i]) ** 2\n",
    "\n",
    "            # Loop over t / Create Candidate Models\n",
    "            for t in range(init, n_obs):\n",
    "            \n",
    "                ### Pre-Process Data ###\n",
    "                y_train, X_train, y_pred, X_pred = prepro(y, X, t)\n",
    "\n",
    "                ### Subset Forecasts ###\n",
    "                feature_set  =  list(chain(*list(map(lambda k: complete_sub(list(range(1, X_train.shape[1])), k), k_range))))\n",
    "                preds_ssf    =  np.array(list(map(lambda feature: ssf(y_train, X_train, X_pred, feature, 0), feature_set)))\n",
    "            \n",
    "                ## Set up List to store Subset-Forecasts\n",
    "                #preds_ssf = np.full(n_sub, np.nan)\n",
    "                #idx_sub   = 0\n",
    "                #\n",
    "                ## Loop over Subset Size \n",
    "                #for k in k_range:\n",
    "                #\n",
    "                #    # Get all possible Subsets of length k\n",
    "                #    col_idx  = list(range(1, X_train.shape[1]))\n",
    "                #    subs_idx = complete_sub(col_idx, k)\n",
    "                #\n",
    "                #    # Randomly select n_upper Subsets\n",
    "                #    feature_set  =  subs_idx #random_select(subs_idx, n_max, random_state = 123)\n",
    "                #\n",
    "                #    # Loop over Subsets\n",
    "                #    for feature in feature_set:\n",
    "                #    \n",
    "                #        # Compute Subset-Regression-Forecast\n",
    "                #        pred  =  ssf(y_train, X_train, X_pred, feature, 0)\n",
    "                #        preds_ssf[idx_sub] = pred\n",
    "                #        idx_sub += 1\n",
    "\n",
    "                ### Compressed Regressions ###\n",
    "                preds_cr = np.array(list(chain(*[list(map(lambda rep: cr_reg(y_train, X_train, X_pred, n_comp, 0, rep), rep_range)) for n_comp in cr_range])))\n",
    "                \n",
    "                # # Set up List to store Compressed-Regression-Forecasts\n",
    "                # preds_cr   = np.full(n_cr, np.nan)\n",
    "                # idx_cr     = 0\n",
    "                # \n",
    "                # # Loop over number of Components\n",
    "                # for n_comp in cr_range:\n",
    "                # \n",
    "                #     # Loop over n repetitions\n",
    "                #     for rep in rep_range:\n",
    "                #     \n",
    "                #         # Compute Compressed-Regression-Forecasts\n",
    "                #         pred  =  cr_reg(y_train, X_train, X_pred, n_comp, 0, rep)\n",
    "                #         preds_cr[idx_cr] = pred\n",
    "                #         idx_cr += 1\n",
    "\n",
    "                # ### Decision Tree Regressions\n",
    "                # preds_dt = np.array(list(map(lambda r: dt_reg(y_train, X_train, X_pred, r), dt_range)))\n",
    "                \n",
    "                # # Set up Matrix to store Decision-Tree-Forecasts\n",
    "                # preds_dt   = np.full(n_dt, np.nan)\n",
    "                # \n",
    "                # # Loop over number of Components\n",
    "                # for idx_dt, r in enumerate(dt_range):\n",
    "                #     \n",
    "                #     # Compute Decision-Tree-Forecasts\n",
    "                #     pred  =  dt_reg(y_train, X_train, X_pred, r)\n",
    "                #     preds_dt[idx_dt] = pred[0]\n",
    "\n",
    "                # Append Results\n",
    "                cand_forecasts[t-init][:n_sub]             =  preds_ssf \n",
    "                cand_forecasts[t-init][n_sub:(n_sub+n_cr)] =  preds_cr\n",
    "                #cand_forecasts[t-init][(n_sub+n_cr):]     =  preds_dt\n",
    "                \n",
    "            ### Benchmark: Complete Subset Regression ###\n",
    "            tmp_ = np.cumsum([0] + [len(list(combinations(range(n_preds), k))) for k in k_range])\n",
    "            csr_forecast[i]     =  [np.mean(preds_ssf[tmp_[i]:tmp_[i+1]]) for i in range(len(tmp_)-1)]\n",
    "            se_csr_forecast[i]  =  (y_pred.iloc[0,0] - csr_forecast[i]) ** 2\n",
    "\n",
    "            ### Best Selection of Forecast ###\n",
    "            bssf_forecast[i], cf_weights[i] = zip(*list(map(lambda s: bssf(y_train[init:], cand_forecasts[:-1], cand_forecasts[-1], alpha, s, n_times), bssf_range)))\n",
    "            se_bssf_forecast[i] = (y_pred.values[0] - bssf_forecast[i]) ** 2\n",
    "            \n",
    "            # # Set up Matrix to store Forecasts\n",
    "            # kssf_forecasts  =  np.full(n_bssf, np.nan)\n",
    "            # kssf_weights    =  np.zeros([n_bssf, n_sub + n_cr]) \n",
    "\n",
    "            # # Loop over Subset Sizes\n",
    "            # for idx_bssf, s in enumerate(bssf_range):\n",
    "            #     \n",
    "            #     # Compute Best-Subset-Selection-of-Forecasts\n",
    "            #     pred = bssf(y_train[init:], cand_forecasts[:-1], cand_forecasts[-1], alpha, s, n_times)\n",
    "            #     bssf_forecast[i][idx_bssf] = pred[0]\n",
    "            #     cf_weights[i][idx_bssf]    = pred[1]\n",
    "            #     se_bssf_forecast[i][idx_bssf] = (y_pred.iloc[0,0] - pred[0]) ** 2\n",
    "             \n",
    "            # Update index   \n",
    "            i += 1\n",
    "            \n",
    "# # Candidate-Model-Names\n",
    "ssf_names = [f\"SSF{k}_\" + \"_\".join(map(str, sub)) for k in k_range for sub in combinations(range(n_preds), k)]\n",
    "cr_names  = [f\"CR{n_comp}_{r}\" for n_comp in cr_range for r in rep_range]\n",
    "\n",
    "### Evaluation ###\n",
    "for b in range(len(b_range)):\n",
    "    for p in range(len(corr_range)):\n",
    "        \n",
    "        se_bssf = se_bssf_forecast[np.arange(b, n_mc * len(corr_range) * len(b_range), len(b_range))][np.arange(p, n_mc * len(corr_range), len(corr_range))]\n",
    "        se_csr  = se_csr_forecast[np.arange(b, n_mc * len(corr_range) * len(b_range), len(b_range))][np.arange(p, n_mc * len(corr_range), len(corr_range))]\n",
    "        se_phm  = se_benchmark[np.arange(b, n_mc * len(corr_range) * len(b_range), len(b_range))][np.arange(p, n_mc * len(corr_range), len(corr_range))]\n",
    "        \n",
    "        print(f\"BSSF: Avg. OOS-R2 for Corr. {corr_range[p]} and Betas {b_range[b]} is: \" + str(np.round(100 * (1 - sum(se_bssf) / sum(se_phm)), 2)) + \"%\")\n",
    "        print(f\"CSR:  Avg. OOS-R2 for Corr. {corr_range[p]} and Betas {b_range[b]} is: \" + str(np.round(100 * (1 - sum(se_csr) / sum(se_phm)), 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Fred-MD-Data stationary\n",
    "def transform_tcode(data):\n",
    "    \n",
    "    # Get Transformation-Code\n",
    "    tcode = data[0]\n",
    "    \n",
    "    # Get Data\n",
    "    data = data[1:]\n",
    "\n",
    "    if tcode == 1:\n",
    "        output = data\n",
    "    elif tcode == 2:\n",
    "        output = data - np.roll(data, 1)\n",
    "    elif tcode == 3:\n",
    "        output = (data - np.roll(data, 1)) - (np.roll(data, 1) - np.roll(data, 2))\n",
    "    elif tcode == 4:\n",
    "        output = np.log(data)\n",
    "    elif tcode == 5:\n",
    "        output = np.log(data) - np.roll(np.log(data), 1)\n",
    "    elif tcode == 6:\n",
    "        output = (np.log(data) - np.roll(np.log(data), 1)) - (np.roll(np.log(data), 1) - np.roll(np.log(data), 2))\n",
    "    else:\n",
    "        output = (data / np.roll(data, 1) - 1) - (np.roll(data, 1) / np.roll(data, 2) - 1)\n",
    "\n",
    "    return np.concatenate(([tcode], output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "x_dataset  =  pd.read_csv(path + r'/fred_md_202306.csv')\n",
    "\n",
    "# Drop Variables with too many missing values\n",
    "x_dataset  =  x_dataset.drop([\"PERMIT\", \"PERMITNE\", \"PERMITMW\", \"PERMITS\",\n",
    "                              \"PERMITW\", \"ACOGNO\", \"ANDENOx\", \"CP3Mx\",\n",
    "                              \"COMPAPFFx\", \"TWEXAFEGSMTHx\", \"UMCSENTx\", \"VIXCLSx\"],\n",
    "                              axis=1)\n",
    "\n",
    "# Transform remaining Columns\n",
    "x_dataset.iloc[:, 1:]  =  x_dataset.iloc[:,1:].apply(lambda x: transform_tcode(x))\n",
    "\n",
    "# Drop First Row with Transformation-Code\n",
    "x_dataset  =  x_dataset.iloc[1:,:]\n",
    "\n",
    "# Lag Data\n",
    "x_dataset.iloc[:,1:]  =  x_dataset.iloc[:,1:].shift(1)\n",
    "\n",
    "# Convert Date\n",
    "x_dataset['sasdate']  =  pd.to_datetime(x_dataset['sasdate'])\n",
    "\n",
    "# Filter Data\n",
    "x_dataset  =  x_dataset[(x_dataset['sasdate'] >= '1959-04-01') & (x_dataset['sasdate'] <= '2023-03-01')]\n",
    "\n",
    "# Resetting the index\n",
    "x_dataset.set_index('sasdate', inplace=True)\n",
    "x_dataset.index = x_dataset.index.to_period('M')\n",
    "\n",
    "# Load Data\n",
    "y_dataset  =  pd.read_csv(path + r'/fred_md_202306.csv')\n",
    "\n",
    "# Select and Rename Variables\n",
    "y_dataset  =  y_dataset.loc[:, [\"sasdate\", \"CPIAUCSL\", \"INDPRO\", \"UNRATE\"]]\n",
    "y_dataset  =  y_dataset.rename(columns={'CPIAUCSL': 'CPIAUCSL_h1', 'INDPRO': 'INDPRO_h1', 'UNRATE': 'UNRATE_h1'})\n",
    "\n",
    "# Transform Variables\n",
    "y_dataset[[\"CPIAUCSL_h1\"]]  =  y_dataset[[\"CPIAUCSL_h1\"]].apply(lambda x: 4 * 100 * (np.log(x) - np.roll(np.log(x), 1)))\n",
    "y_dataset[[\"INDPRO_h1\"]]    =  y_dataset[[\"INDPRO_h1\"]].apply(lambda x: 4 * 100 * (np.log(x) - np.roll(np.log(x), 1)))\n",
    "y_dataset[[\"UNRATE_h1\"]]    =  y_dataset[[\"UNRATE_h1\"]]\n",
    "\n",
    "# Drop First Row with Transformation-Code\n",
    "y_dataset  =  y_dataset.iloc[1:,:]\n",
    "\n",
    "# Convert Date\n",
    "y_dataset['sasdate']  =  pd.to_datetime(y_dataset['sasdate'])\n",
    "\n",
    "# Filter Data\n",
    "y_dataset  =  y_dataset[(y_dataset['sasdate'] >= '1959-04-01') & (y_dataset['sasdate'] <= '2023-03-01')]\n",
    "\n",
    "# Resetting the index\n",
    "y_dataset.set_index('sasdate', inplace=True)\n",
    "y_dataset.index = y_dataset.index.to_period('M')\n",
    "\n",
    "# Set Target Variable\n",
    "y  =  y_dataset.loc[:, [\"CPIAUCSL_h1\"]]\n",
    "X  =  x_dataset.drop(\"CPIAUCSL\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Selection of Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Selection of Forecasts\n",
    "def bssf(Y_train, X_train, X_pred, alpha, n_sub, n_times):\n",
    "    \n",
    "    # Adapt X-Matrix\n",
    "    X_train  =  X_train / n_sub\n",
    "    \n",
    "    # Generate Q-Matrix\n",
    "    ivec      =  np.mat(np.ones(X_train.shape[1])).transpose()\n",
    "    aux_mat   =  np.array(Y_train.transpose() @ X_train + alpha * n_sub)\n",
    "    diag_mat  =  np.diag(aux_mat[0])\n",
    "    Q         =  - 2 * diag_mat + X_train.transpose() @ X_train + alpha * ivec @ ivec.transpose()\n",
    "\n",
    "    # Initialize BQM\n",
    "    bqm  =  BinaryQuadraticModel('BINARY')\n",
    "    bqm  =  bqm.from_qubo(Q)\n",
    "    \n",
    "    # Solve\n",
    "    solver     =  SimulatedAnnealingSampler()\n",
    "    #solver     =  SteepestDescentSolver()\n",
    "    #solver     =  TabuSampler()\n",
    "    #solver     =  TreeDecompositionSolver()\n",
    "\n",
    "    sampleset  =  solver.sample(bqm, num_reads = n_times)\n",
    "    solution   =  list(sampleset.first[0].values())\n",
    "    \n",
    "    # Prediction \n",
    "    pred       = solution @ X_pred\n",
    "    \n",
    "    # Return \n",
    "    return(pred, solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Series-Cross-Validation to Tune Parameter k\n",
    "def cv_ts(Y, X, splits, k_seq, alpha, n_times):\n",
    "\n",
    "    # Set up TS-Split\n",
    "    tscv    =  TimeSeriesSplit(n_splits = splits)\n",
    "    \n",
    "    # Set up Result-Matrix\n",
    "    cv_res  =  np.zeros((splits, len(k_seq)))\n",
    "\n",
    "    # Loop over Train-Test-Splits\n",
    "    for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "\n",
    "        # Split Data\n",
    "        X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "        Y_train, Y_test = Y.iloc[train_index],   Y.iloc[test_index]\n",
    "\n",
    "        # Cross-Validation k\n",
    "        for k in k_seq:\n",
    "\n",
    "            # Selected Predictors\n",
    "            solution    =  bssf(Y_train, X_train, X_pred, alpha, k, n_times)[1]\n",
    "\n",
    "            # Prediction\n",
    "            prediction  =  solution @ X_test.transpose()\n",
    "\n",
    "            # MSE\n",
    "            cv_res[i, k-1]  =  np.mean((Y_test.squeeze() - prediction) ** 2)\n",
    "\n",
    "            # Select k with smalltest average MSE\n",
    "            k  =  cv_res.mean(axis=0).argmin() + 1\n",
    "            \n",
    "    # Return \n",
    "    return(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate Forecasts\n",
    "cand_forecasts  =  results\n",
    "\n",
    "# Target Variable\n",
    "target_var  =  y_dataset.loc[:, [\"CPIAUCSL_h1\"]]\n",
    "\n",
    "# Get Dates\n",
    "dates  =  cand_forecasts.index.values\n",
    "\n",
    "# Match Time Frames\n",
    "target_var  =  target_var.loc[dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameter\n",
    "alpha    =  1\n",
    "n_mods   =  cand_forecasts.shape[1]\n",
    "\n",
    "# Set Vector & Matrices\n",
    "X     =  cand_forecasts.copy()\n",
    "Y     =  target_var.copy()\n",
    "\n",
    "# Set Time Parameter\n",
    "init    =  int(12 * 5)\n",
    "final   =  len(Y)\n",
    "\n",
    "# Set up Empty Array\n",
    "predictions  =  np.zeros(final)\n",
    "predictions.fill(np.nan)\n",
    "\n",
    "# Loop\n",
    "for t in tqdm(range(init, final)):\n",
    "    \n",
    "    # Train Data\n",
    "    X_train  =  X.iloc[:t, ]\n",
    "    Y_train  =  Y.iloc[:t, ]\n",
    "    \n",
    "    # Prediction Data\n",
    "    X_pred   =  X.iloc[t, ]\n",
    "    \n",
    "    # Cross-Validation\n",
    "    splits   =  5\n",
    "    n_times  =  500\n",
    "    k_seq    =  [1, 2, 3, 4, 5]\n",
    "    k_opt    =  cv_ts(Y_train, X_train, splits, k_seq, alpha, n_times)\n",
    "    \n",
    "    # Prediction \n",
    "    n_times  =  500\n",
    "    predictions[t]  =  bssf(Y_train, X_train, X_pred, alpha, k_opt, n_times)[0]\n",
    "\n",
    "# Convert to Pandas Series\n",
    "predictions  =  pd.Series(predictions, name = \"qubo\", index = Y.index).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Target Variable\n",
    "target_var      =  pyreadr.read_r(path + '/Data/Results/Target_Var/target_var.RDS')[None]\n",
    "\n",
    "# Load all Candidate Forecasts\n",
    "cand_forecasts  =  pd.DataFrame()\n",
    "files           =  os.scandir(path + '/Data/Results/Candidate_Forecasts')\n",
    "\n",
    "# Loop\n",
    "for file in files:\n",
    "    if (file.path.endswith(\".RDS\")):\n",
    "        aux  =  pyreadr.read_r(file)[None]\n",
    "        cand_forecasts  =  pd.concat([cand_forecasts, aux], axis = 1)\n",
    "        \n",
    "# Drop Na\n",
    "cand_forecasts  =  cand_forecasts.dropna()\n",
    "\n",
    "# Get Dates\n",
    "dates           =  cand_forecasts.index.values\n",
    "\n",
    "# Match Time Frames\n",
    "target_var      =  target_var.loc[dates]\n",
    "\n",
    "# Dimensions\n",
    "print(cand_forecasts.shape)\n",
    "print(target_var.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Q-Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Selection of Forecasts\n",
    "def bssf(Y_train, X_train, X_pred, alpha, n_sub, n_times):\n",
    "    \n",
    "    # Adapt X-Matrix\n",
    "    X_train  =  X_train / n_sub\n",
    "    \n",
    "    # Generate Q-Matrix\n",
    "    ivec      =  np.mat(np.ones(X_train.shape[1])).transpose()\n",
    "    aux_mat   =  np.array(Y_train.transpose() @ X_train + alpha * n_sub)\n",
    "    diag_mat  =  np.diag(aux_mat[0])\n",
    "    Q         =  - 2 * diag_mat + X_train.transpose() @ X_train + alpha * ivec @ ivec.transpose()\n",
    "\n",
    "    # Initialize BQM\n",
    "    bqm  =  BinaryQuadraticModel('BINARY')\n",
    "    bqm  =  bqm.from_qubo(Q)\n",
    "    \n",
    "    # Solve\n",
    "    solver     =  SimulatedAnnealingSampler()\n",
    "    #solver     =  SteepestDescentSolver()\n",
    "    #solver     =  TabuSampler()\n",
    "    #solver     =  TreeDecompositionSolver()\n",
    "\n",
    "    sampleset  =  solver.sample(bqm, num_reads = n_times)\n",
    "    solution   =  list(sampleset.first[0].values())\n",
    "    \n",
    "    # Prediction \n",
    "    pred       = solution @ X_pred\n",
    "    \n",
    "    # Return \n",
    "    return(pred, solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Series-Cross-Validation to Tune Parameter k\n",
    "def cv_ts(Y, X, splits, k_seq, alpha, n_times):\n",
    "\n",
    "    # Set up TS-Split\n",
    "    tscv    =  TimeSeriesSplit(n_splits = splits)\n",
    "    \n",
    "    # Set up Result-Matrix\n",
    "    cv_res  =  np.zeros((splits, len(k_seq)))\n",
    "\n",
    "    # Loop over Train-Test-Splits\n",
    "    for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "\n",
    "        # Split Data\n",
    "        X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "        Y_train, Y_test = Y.iloc[train_index],   Y.iloc[test_index]\n",
    "\n",
    "        # Cross-Validation k\n",
    "        for k in k_seq:\n",
    "\n",
    "            # Selected Predictors\n",
    "            solution    =  bssf(Y_train, X_train, X_pred, alpha, k, n_times)[1]\n",
    "\n",
    "            # Prediction\n",
    "            prediction  =  solution @ X_test.transpose()\n",
    "\n",
    "            # MSE\n",
    "            cv_res[i, k-1]  =  np.mean((Y_test.squeeze() - prediction) ** 2)\n",
    "\n",
    "            # Select k with smalltest average MSE\n",
    "            k  =  cv_res.mean(axis=0).argmin() + 1\n",
    "            \n",
    "    # Return \n",
    "    return(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameter\n",
    "alpha    =  1\n",
    "n_mods   =  cand_forecasts.shape[1]\n",
    "\n",
    "# Set Vector & Matrices\n",
    "X     =  cand_forecasts.copy()\n",
    "Y     =  target_var.copy()\n",
    "\n",
    "# Set Time Parameter\n",
    "init    =  int(12 * 5)\n",
    "final   =  len(Y)\n",
    "\n",
    "# Set up Empty Array\n",
    "predictions  =  np.zeros(final)\n",
    "predictions.fill(np.nan)\n",
    "\n",
    "# Loop\n",
    "for t in range(init, final):\n",
    "    \n",
    "    # Train Data\n",
    "    X_train  =  X.iloc[:t, ]\n",
    "    Y_train  =  Y.iloc[:t, ]\n",
    "    \n",
    "    # Prediction Data\n",
    "    X_pred   =  X.iloc[t, ]\n",
    "    \n",
    "    # Cross-Validation\n",
    "    splits   =  5\n",
    "    n_times  =  500\n",
    "    k_seq    =  [1, 2, 3, 4, 5]\n",
    "    k        =  cv_ts(Y_train, X_train, splits, k_seq, alpha, n_times)\n",
    "    \n",
    "    # Prediction \n",
    "    n_times  =  500\n",
    "    predictions[t]  =  bssf(Y_train, X_train, X_pred, alpha, k, n_times)[0]\n",
    "\n",
    "# Convert to Pandas Series\n",
    "predictions  =  pd.Series(predictions, name = \"qubo\", index = Y.index).to_frame()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Eval-Function (OOS-R2)\n",
    "def oos_r2(observation, prediction, benchmark):\n",
    "    \n",
    "    # Squared Error Model\n",
    "    se1  =  (observation - prediction) ** 2\n",
    "    \n",
    "    # Squared Error Benchmark\n",
    "    se2  =  (observation - benchmark) ** 2\n",
    "    \n",
    "    # Out-of-Sample R2\n",
    "    oos_r2  =  (1 - sum(se1) / sum(se2)) * 100\n",
    "    \n",
    "    # Return \n",
    "    return(oos_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set OOS-Period\n",
    "eval_start  =  \"1974-12-01\"\n",
    "eval_end    =  \"2020-12-01\"\n",
    "\n",
    "# Keep only OOS-Period\n",
    "oos_target_var      =  target_var.loc[eval_start:eval_end].squeeze()\n",
    "oos_benchmark       =  cand_forecasts[eval_start:eval_end][\"pred_hist_mean\"]\n",
    "oos_bssf            =  predictions.loc[eval_start:eval_end].squeeze()\n",
    "oos_cand_forecasts  =  cand_forecasts[eval_start:eval_end]\n",
    "\n",
    "# Evaluate Best Subset Selection of Forecasts\n",
    "oos_r2(oos_target_var, oos_bssf, oos_benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Candidate Models\n",
    "eval_cand_mods  =  oos_cand_forecasts.apply(lambda x: oos_r2(oos_target_var, x, oos_benchmark), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_cand_mods.sort_values(ascending = False).to_frame(\"OOS-R2\").head(n = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set OOS-Period\n",
    "eval_start  =  \"1974-12-01\"\n",
    "eval_end    =  \"2020-12-01\"\n",
    "\n",
    "# Keep only OOS-Period\n",
    "oos_target_var      =  target_var.loc[eval_start:eval_end].squeeze()\n",
    "oos_benchmark       =  cand_forecasts[eval_start:eval_end][\"pred_hist_mean\"]\n",
    "oos_cand_forecasts  =  cand_forecasts[eval_start:eval_end]\n",
    "\n",
    "# Evaluate Candidate Models\n",
    "eval_cand_mods  =  oos_cand_forecasts.apply(lambda x: oos_r2(oos_target_var, x, oos_benchmark), axis = 0)\n",
    "\n",
    "# Show Results\n",
    "print(eval_cand_mods.filter(like = \"XGB\"))\n",
    "print(eval_cand_mods.filter(like = \"GBM\"))\n",
    "print(eval_cand_mods.filter(like = \"pcr\"))\n",
    "print(eval_cand_mods.filter(like = \"glm\"), n =)\n",
    "#eval_cand_mods.sort_values(ascending = False).to_frame(\"OOS-R2\").head(n = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BQM\n",
    "qubo  =  { (i,j) : Q.iloc[i,j] for i in range(0, 11) for j in range(0, 11) }\n",
    "bqm   =  BinaryQuadraticModel('BINARY')\n",
    "bqm   =  bqm.from_qubo(Q)\n",
    "\n",
    "# Initialize BQM\n",
    "bqm = BinaryQuadraticModel('BINARY')\n",
    "\n",
    "# Add Linear Coefficients\n",
    "for i in range(0,11):\n",
    "    lin_coef  =  Q.iloc[i,i]\n",
    "    bqm.add_linear(i, lin_coef)\n",
    "    \n",
    "# Add Quadratic Coefficients\n",
    "for i in range(0,11):\n",
    "    for j in range(0,11):\n",
    "        if i != j:\n",
    "            quad_coef  =  Q.iloc[i,j]\n",
    "            bqm.add_quadratic(i, j, quad_coef)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
